Automatically generated by Mendeley Desktop 1.17.12
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@book{Neuendorf2017a,
abstract = {Content analysis is one of the most important but complex research methodologies in the social sciences. In this thoroughly updated Second Edition of The Content Analysis Guidebook, author Kimberly Neuendorf draws on examples from across numerous disciplines to clarify the complicated aspects of content analysis through step-by-step instruction and practical advice. Throughout the book, the author also describes a wide range of innovative content analysis projects from both academia and commercial research that provide readers with a deeper understanding of the research process and its many real-world applications.},
author = {Skalski, Paul D. and Neuendorf, Kimberly A. and Cajigas, Julie A.},
booktitle = {Content Anal. Guideb.},
file = {:home/ankur218/master-thesis/thesis-references/SkalskiNeuendorfCajigas17.pdf:pdf},
isbn = {9781412979474},
pages = {201--242},
title = {{Content Analysis in the Interactive Media Age}},
url = {https://books.google.com/books?hl=en{\&}lr={\&}id=nMA5DQAAQBAJ{\&}oi=fnd{\&}pg=PP1{\&}dq=content+analysis+{\&}ots=pGMqtbhs7s{\&}sig=z7-zmb{\_}2cfnz9UJClqg3k4dWL6A{\%}0Ahttp://academic.csuohio.edu/kneuendorf/SkalskiVitae/SkalskiNeuendorfCajigas17.pdf},
year = {2017}
}
@article{Bhat2017,
author = {Bhat, Manoj and Shumaiev, Klym and Biesdorf, Andreas and Hohenstein, Uwe and Matthes, Florian},
doi = {10.1007/978-3-319-65831-5_10},
file = {:home/ankur218/master-thesis/thesis-references/Bh17a.pdf:pdf},
isbn = {978-3-319-65830-8},
keywords = {design decisions,machine learning,software architecture},
pages = {138--154},
title = {{Automatic Extraction of Design Decisions from Issue Management Systems: A Machine Learning Based Approach}},
url = {http://link.springer.com/10.1007/978-3-319-65831-5{\_}10},
year = {2017}
}
@article{Kunz1970,
abstract = {Issue-Based Information Systems (IBIS) are meant to support coordination and planning of political decision processes. IBIS guides the identification, structuring, and settling of issues raised by problem-solving groups, and provides information pertinent to the discourse. It is linked to conventional documentation systems but also activates other sources. Elements of the system are topics, issues, questions of fact, positions, arguments, and model problems. The logic of issues, the subsystems of IBIS, and their rules of operation are outlined. Three manually operated versions of IBIS are in experimental operation by governmental agencies; computerization of system operations is in preparation.},
author = {Kunz, Werner and Rittel, Horst W.J.},
doi = {10.4324/9780203851586},
file = {:home/ankur218/master-thesis/thesis-references/10.1.1.134.1741.pdf:pdf},
isbn = {0203851587},
journal = {Universe Des. Horst Rittel's Theor. Des. Plan.},
number = {131},
pages = {181--185},
title = {{Issues as elements of information systems}},
volume = {9780203851586},
year = {1970}
}
@article{Panichella2014,
abstract = {Written communications recorded through channels such as mailing lists or issue trackers, but also code co-changes, have been used to identify emerging collaborations in software projects. Also, such data has been used to identify the relation between developers' roles in communication networks and source code changes, or to identify mentors aiding newcomers to evolve the software project. However, results of such analyses may be different depending on the communication channel being mined. This paper investigates how collaboration links vary and complement each other when they are identified through data from three different kinds of communication channels, i.e., mailing lists, issue trackers, and IRC chat logs. Also, the study investigates how such links overlap with links mined from code changes, and how the use of different sources would influence (i) the identification of project mentors, and (ii) the presence of a correlation between the social role of a developer and her changes. Results of a study conducted on seven open source projects indicate that the overlap of communication links between the various sources is relatively low, and that the application of networks obtained from different sources may lead to different results.},
author = {Panichella, Sebastiano and Bavota, Gabriele and {Di Penta}, Massimiliano and Canfora, Gerardo and Antoniol, Giuliano},
doi = {10.1109/ICSME.2014.47},
file = {:home/ankur218/master-thesis/thesis-references/How{\_}Developers{\_}Collaborations.pdf:pdf},
isbn = {9780769553030},
issn = {1063-6773},
journal = {Proc. - 30th Int. Conf. Softw. Maint. Evol. ICSME 2014},
keywords = {Developer Social Network,Developers,Empirical Study},
pages = {251--260},
title = {{How developers' collaborations identified from different sources tell us about code changes}},
year = {2014}
}
@article{Pedregosa2012,
abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
archivePrefix = {arXiv},
arxivId = {1201.0490},
author = {Pedregosa, Fabian and Varoquaux, Ga{\"{e}}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, {\'{E}}douard},
doi = {10.1007/s13398-014-0173-7.2},
eprint = {1201.0490},
file = {:home/ankur218/master-thesis/thesis-references/pedregosa11a.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
journal = {J. Mach. Learn. Res.},
pages = {2825--2830},
pmid = {1000044560},
title = {{Scikit-learn: Machine Learning in Python}},
url = {http://dl.acm.org/citation.cfm?id=2078195{\%}5Cnhttp://arxiv.org/abs/1201.0490},
volume = {12},
year = {2012}
}
@misc{Porter,
author = {Porter, M F},
file = {:home/ankur218/master-thesis/thesis-references/Porter-1980.pdf:pdf},
title = {{An algorithm for suffix stripping}},
year = {1980}
}
@article{Guzman2017a,
abstract = {See, stats, and : https : / / www . researchgate. net / publication / 319041301 A : Mining Requirements Conference CITATIONS 0 READS 16 3 , including : Emitza University 24 SEE All . The . Abstract—Twitter is one of the most popular social networks . Previous research found that users employ Twitter to communi - cate about software applications via short messages , commonly referred to as tweets , and that these tweets can be useful for requirements engineering and software evolution . However , due to their large number—in the range of thousands per day for popular applications—a manual analysis is unfeasible . In this work we present ALERTme , an approach to automati - cally classify , group and rank tweets about software applications . We apply machine learning techniques for automatically classify - ing tweets requesting improvements , topic modeling for grouping semantically related tweets and a weighted function for ranking tweets according to specific attributes , such as content category , sentiment and number of retweets . We ran our approach on 68 , 108 collected tweets from three software applications and compared its results against software practitioners ' judgement . Our results show that ALERTme is an effective approach for filtering , summarizing and ranking tweets about software applications . ALERTme enables the exploitation of Twitter as a feedback channel for information relevant to software evolution , including end - user requirements .},
author = {Guzman, Emitza and Ibrahim, Mohamed and Glinz, Martin},
doi = {10.1109/RE.2017.88},
file = {:home/ankur218/master-thesis/thesis-references/A Little Bird Told Me.pdf:pdf},
isbn = {9781538631911},
journal = {Proc. - 2017 IEEE 25th Int. Requir. Eng. Conf. RE 2017},
keywords = {Twitter,requirements elicitation,software evolution,text mining,user feedback},
number = {2},
pages = {11--20},
title = {{A Little Bird Told Me: Mining Tweets for Requirements and Software Evolution}},
year = {2017}
}
@article{Ball2011,
abstract = {Gesture recognition is an important aspect of interpersonal social interaction. Developing a similar capacity in a robot will improve human-robot interaction. Various unsupervised clustering methods applied to clustering a set of dynamic human arm gestures are compared. Unsupervised cluster- ing is important in gesture recognition as it imposes no a priori bound on the set of gestures. Results are compared using v-measure, a metric that allows differential weighting between clustering homogeneity and completeness. Experi- ments show that the best clustering method depends on the desired balance between homogeneity and completeness.},
author = {Ball, Adrian and Rye, David and Ramos, Fabio and Velonaki, Mari},
doi = {10.1145/1957656.1957686},
file = {:home/ankur218/master-thesis/thesis-references/06281249.pdf:pdf},
isbn = {9781450305617},
journal = {Proc. 6th Int. Conf. Human-robot Interact. - HRI '11},
keywords = {1,2 spectral clustering,development of a similarity,gesture recognition,spectral clustering requires the,unsupervised clustering,v-measure},
pages = {111},
title = {{A comparison of unsupervised learning algorithms for gesture clustering}},
url = {http://portal.acm.org/citation.cfm?doid=1957656.1957686},
year = {2011}
}
@article{Thesis,
author = {Thesis, Master},
file = {:home/ankur218/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thesis - Unknown - Mining of Rationales from Issue Trackers Results.pdf:pdf},
number = {1},
pages = {1--3},
title = {{Mining of Rationales from Issue Trackers Results :}}
}
@article{Pagano2011,
abstract = {We report on an exploratory study, which aims at understanding how software developers use social media compared to conventional development infrastructures. We analyzed the blogging and the committing behavior of 1,100 developers in four large open source communities. We observed that these communities intensively use blogs with one new entry about every 8 hours. A blog entry includes 14 times more words than a commit message. When analyzing the content of the blogs, we found that most popular topics represent high-level concepts such as functional requirements and domain concepts. Source code related topics are covered in less than 15{\%} of the posts. Our results also show that developers are more likely to blog after corrective engineering and management activities than after forward engineering and re-engineering activities. Our findings call for a hypothesis-driven research to further understand the role of social media in software engineering and integrate it into development processes and tools.},
author = {Pagano, Dennis and Maalej, Walid},
doi = {10.1145/1985441.1985461},
file = {:home/ankur218/master-thesis/thesis-references/How Do Developers Blog{\_}An Exploratory Study.pdf:pdf},
isbn = {9781450305747},
issn = {02705257},
journal = {Proc. MSR},
keywords = {blogs,data mining,open source,social software},
pages = {123--132},
title = {{How do developers blog?}},
year = {2011}
}
@article{Ghorpade2012,
abstract = {The internet revolution has brought about a new way of expressing an individual's opinion. It has become a medium through which people openly express their views on various subjects. These opinions contain useful information which can be utilized in many sectors which require constant customer feedback. Analysis of the opinion and it's classification into different sentiment classes is gradually emerging as a key factor in decision making. There has been extensive research on automatic text analysis for sentiments such as sentiment classifiers, affect analysis, automatic survey analysis, opinion extraction, or recommender systems. These methods typically try to extract the overall sentiment revealed in a sentence or document, either positive or negative, or somewhere in between. However, a drawback of these methods is that the information can be degraded, especially in texts where a loss of information can also occur. The proposed method attempts to overcome the problem of the loss of text information by using well trained training sets. Also, recommendation of a product or request for a product as per the user's requirements have achieved with the proposed method.},
author = {Ghorpade, Tushar and Ragha, Lata},
doi = {10.1109/ICCICT.2012.6398136},
file = {:home/ankur218/master-thesis/thesis-references/06398136.pdf:pdf},
isbn = {9781457720789},
journal = {Proc. - 2012 Int. Conf. Commun. Inf. Comput. Technol. ICCICT 2012},
keywords = {machine learning,naive bayes classification,natural language processing,online traveller reviews,ontology,sentiment analysis},
pages = {1--5},
title = {{Featured based sentiment classification for hotel reviews using NLP and Bayesian classification}},
year = {2012}
}
@article{Zou2017,
author = {Zou, Jie and Xu, Ling and Yang, Mengning and Yan, Meng and Yang, Dan and Zhang, Xiaohong},
doi = {10.1109/ICSS.2016.16},
file = {:home/ankur218/master-thesis/thesis-references/08057393.pdf:pdf},
isbn = {9781509027279},
issn = {21653828},
journal = {Proc. Int. Conf. Serv. Sci. ICSS},
keywords = {duplicate bug reports detection,execution information,topic model,vector space model},
pages = {60--65},
title = {{Duplication Detection for Software Bug Reports based on Topic Model}},
year = {2017}
}
@article{Murgia2016,
author = {Murgia, Alessandro and Destefanis, Giuseppe and Tourani, Parastou and Tonelli, Roberto and Marchesi, Michele and Adams, Bram},
doi = {10.1145/2901739.2903505},
file = {:home/ankur218/master-thesis/thesis-references/The Emotional Side of Software Developers in JIRA.pdf:pdf},
isbn = {9781450341868},
keywords = {a,ective anal-,issue reports,mining software repositories},
number = {October},
pages = {1--5},
title = {{The Emotional Side of Software Developers in JIRA The Emotional Side of Software Developers in JIRA}},
year = {2016}
}
@article{Rojas1996,
abstract = {5 Unsupervised Learning and Clustering Algorithms 5.1 Competitive learning The perceptron learning algorithm is an example of supervised learning. This kind of approach does not seem very plausible from the biologist's point of view, since a teacher is needed to accept or reject the output and adjust the network weights if necessary. Some researchers have proposed alternative learning methods in which the network parameters are determined as a result of a self-organizing process. In unsupervised learning corrections to the net-work weights are not performed by an external agent, because in many cases we do not even know what solution we should expect from the network. The network itself decides what output is best for a given input and reorganizes accordingly. We will make a distinction between two classes of unsupervised learning: reinforcement and competitive learning. In the first method each input pro-duces a reinforcement of the network weights in such a way as to enhance the reproduction of the desired output. Hebbian learning is an example of a rein-forcement rule that can be applied in this case. In competitive learning, the elements of the network compete with each other for the " right " to provide the output associated with an input vector. Only one element is allowed to answer the query and this element simultaneously inhibits all other competitors. This chapter deals with competitive learning. We will show that we can conceive of this learning method as a generalization of the linear separation methods discussed in the previous two chapters. 5.1.1 Generalization of the perceptron problem A single perceptron divides input space into two disjoint half-spaces. However, as we already mentioned in Chap. 3, the relative number of linearly separable Boolean functions in relation to the total number of Boolean functions con-verges to zero as the dimension of the input increases without bound. There-R. Rojas: Neural Networks, Springer-Verlag, Berlin, 1996 102 5 Unsupervised Learning and Clustering Algorithms fore we would like to implement some of those not linearly separable functions using not a single perceptron but a collection of computing elements. P N Fig. 5.1. The two sets of vectors P and N Figure 5.1 shows a two-dimensional problem involving two sets of vectors, denoted respectively P and N . The set P consists of a more or less compact bundle of vectors. The set N consists of vectors clustered around two different regions of space. cluster A cluster B cluster C w 1 w 2 w 3 Fig. 5.2. Three weight vectors for the three previous clusters This classification problem is too complex for a single perceptron. A weight vector w cannot satisfy w {\textperiodcentered} p ≥ 0 for all vectors p in P and w {\textperiodcentered} n {\textless} 0 for all vectors n in N . In this situation it is possible to find three different vectors w 1 ,w 2 and w 3 which can act as a kind of " representative " for the vectors in each of the three clusters A, B and C shown in Figure 5.2. Each one of},
author = {Rojas, R},
doi = {10.1007/978-3-642-61068-4_5},
file = {:home/ankur218/master-thesis/thesis-references/K5.pdf:pdf},
isbn = {978-3-540-60505-8},
journal = {Neural Networks},
pages = {pp 99--121},
title = {{Unsupervised Learning and Clustering Algorithms}},
year = {1996}
}
@article{Lata,
author = {Lata, Teodora},
file = {:home/ankur218/master-thesis/thesis-references/Teodora{\_}Thesis{\_}Proposal.pdf:pdf},
pages = {1--3},
title = {{Proposal: Mining of Rationale From Developers ' Chat Messages}}
}
@article{Strombergsson2009,
abstract = {Introduction This paper describes a statistical method that I've used when analyzing the data in a study of children's ability to recognize their recorded voice as their own. To begin with, I had no real understanding of the method I was applying, but simply inserted my data into the formula and computed the results. As I was not completely comfortable that my selection of method was appropriate, I felt a need for a deeper understanding of what I was doing. This paper is the result of my efforts to gain this deeper understanding. Data description The data is from a study of children's ability to identify which of 4 recordings is their own voice. 45 children participated as subjects. 3 children were recorded as references. For each word in the recording script (23 in total), the task for the subjects was to 1) Record their own production of the word 2) Decide which one of four recordings of this word (their own recording + 3 reference recordings, presented in random order) is their own voice. There were two test occasions; on the first, the children performed both the recording and the identification task, on the second, they only performed the identification task. The recordings (23 words * 45 subjects = 1035 recordings) represent observations, and for each recording the following information is specified: • The number of phonemes in the word (ranging from 2 to 5) • The absolute difference (in Hertz) between the subject's average F0 and the most similar reference speaker's average F0 • The Euclidean difference between the subject's average formant frequencies and the most similar reference speaker's average formant frequencies • The absolute difference between the subject's speaking rate (in phonemes/sec) and the most similar reference speaker's speaking rate • One test result (correct/incorrect identification) for each subject on the first test occasion • One test result (correct/incorrect identification) for each subject on the second test occasion},
author = {Str{\"{o}}mbergsson, Sofia},
file = {:home/ankur218/master-thesis/thesis-references/strombergsson.pdf:pdf},
journal = {Analysis},
title = {{Binary Logistic Regression and its application to data from a study of children ' s recognition of their own recorded voices}},
year = {2009}
}
@article{Souza2017,
abstract = {—Human factors such as sentiments, emotions, mood, and stress along with their potential effect on software devel-opment are of paramount importance in software engineering, as we still strongly rely on human-to-human interaction for per-forming software development activities and driving results. With the advance of sentiment analysis tools, software engineering researchers have investigated the interplay between developers' sentiment and software engineering tasks such as issue fixing times. However, there is a lack of studies analyzing whether there is a relation between developers' sentiment and builds performed by continuous integration servers. Build breakage is not desired as it represents a signal that something went wrong in the software development activity and that extra work or rework should be done. In this paper, we report an empirical assessment over Travis CI builds and the corresponding commits in order to understand a potential association between developers' sentiment and build breakage. We found evidence that negative sentiment both affects and is affected by the result of the build process, although the influence seems to be small. Also, we found that developers tend to be more positive when writing about the CI server in commit messages.},
author = {Souza, Rodrigo and Silva, Bruno},
doi = {10.1109/MSR.2017.27},
file = {:home/ankur218/master-thesis/thesis-references/07962396.pdf:pdf},
isbn = {9781538615447},
issn = {21601860},
journal = {IEEE Int. Work. Conf. Min. Softw. Repos.},
keywords = {Continuous Integration,Human factors on Software Engineering,Sentiment Analysis},
pages = {459--462},
title = {{Sentiment Analysis of Travis CI Builds}},
year = {2017}
}
@article{Ri,
author = {Ri, H S W and Dqg, Flhqfh and Pjr, N G D and Dkx, D D G and Vwlu, F V and Xn, D F and Krzdug, Hzwrq and Xn, D F and Sdshu, K L V and Rujdql, L V and Iroorzv, H G D V and Wkh, Suhvhqwv and Zrun, Uhodwhg and Wkh, Sodlqv and Phwkrgrorj, Sursrvhg and Wkh, Glvfxvv and Vhfwlrq, Uhvxowv and Wkh, Suhvhqwv and Ri, Fkdoohqjhv and Sdshu, Frqfoxghv W K H},
file = {:home/ankur218/master-thesis/thesis-references/08109733.pdf:pdf},
keywords = {affective computing,named entity recognition,natural language,persian,sentiment analysis,support vector machines},
pages = {79--83},
title = {{Persian Named Entity Recognition}},
year = {2017}
}
@article{Chen2016,
author = {Chen, Yaw-Huei and Li, Shu-Fong},
doi = {10.1109/CEC.2016.7743935},
file = {:home/ankur218/master-thesis/thesis-references/07743935.pdf:pdf},
isbn = {978-1-5090-0623-6},
journal = {2016 IEEE Congr. Evol. Comput.},
pages = {1280--1286},
title = {{Using latent Dirichlet allocation to improve text classification performance of support vector machine}},
url = {http://ieeexplore.ieee.org/document/7743935/},
year = {2016}
}
@article{Metzmacher2017,
author = {Metzmacher, Amelie and Verena, Heinrichs and Bj{\"{o}}rn, Falk and Schmitt, Robert},
file = {:home/ankur218/master-thesis/thesis-references/08022663.pdf:pdf},
pages = {5--6},
title = {{Customer Language Processing}},
year = {2017}
}
@article{Jurafsky2017,
abstract = {Third Edition draft},
author = {Jurafsky, Daniel and Martin, James H},
file = {:home/ankur218/master-thesis/thesis-references/ed3book.pdf:pdf},
title = {{Speech and Language Processing - An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition}},
url = {https://web.stanford.edu/{~}jurafsky/slp3/ed3book.pdf},
year = {2017}
}
@article{Caruana2006,
abstract = {A number of supervised learning methods have been introduced in the last decade. Unfortunately, the last comprehensive empirical evaluation of supervised learning was the Statlog Project in the early 90's. We present a large-scale empirical comparison between ten supervised learning methods: SVMs, neural nets, logistic regression, naive bayes, memory-based learning, random forests, decision trees, bagged trees, boosted trees, and boosted stumps. We also examine the effect that calibrating the models via Platt Scaling and Isotonic Regression has on their performance. An important aspect of our study is the use of a variety of performance criteria to evaluate the learning methods.},
author = {Caruana, Rich and Niculescu-Mizil, Alexandru},
doi = {10.1145/1143844.1143865},
file = {:home/ankur218/master-thesis/thesis-references/caruana.icml06.pdf:pdf},
isbn = {1595933832},
issn = {1595933832},
journal = {Proc. 23rd Int. Conf. Mach. Learn.},
number = {1},
pages = {161--168},
pmid = {1000253691},
title = {{An empirical comparison of supervised learning algorithms}},
url = {http://portal.acm.org/citation.cfm?doid=1143844.1143865},
volume = {C},
year = {2006}
}
@article{Ortu2017,
abstract = {—The summary presented in this paper highlights the results obtained in a four-year project aiming at analyzing the development process of software artifacts from two points of view: Effectiveness and Affectiveness. The first attribute is meant to analyze the productivity of the Open Source Communities by measuring the time required to resolve an issue, while the latter provides a novel approach for studying the development process by analyzing the affectiveness expressed by developers in their comments posted during the issue resolution phase. Affectivenes is obtained by measuring Sentiment, Politeness and The present paper summarizes the main results obtained by the authors at the end of the project, with the main goal of building a bridge between researchers and developers, in order to provide information able to help developers in their very complex and high demanding daily job. Research has focused on understanding emotions and mood both in software engineering and software development and how the human aspects of a technical discipline can affect final results [1], [2], [3], [6], [7], [9], [11] and improve software quality. Our journey started when we found that comments posted by developers on software repositories contain not only tech-nical information, but also valuable information about sen-timents and emotions. We then started the creation of a dataset, now publicly available [15], [16], hosting more than 1K projects, 700K issue reports and 2 million comments. We fetched the data by mining the Jira repository of four open source communities: Apache, Spring, JBoss and CodeHaus and we also presented the tools used for the mining activity and how information is organized in the dataset. We manually labeled 2,000 issue comments and 4,000 sentences written by developers with emotions such as love, joy, surprise, anger, sadness and fear. By sharing the repository, we wanted to fill the gap of missing data in the area and to encourage the research community to perform studies in the field of software emotions. The second step has been the study of the developer networks of the open source projects hosted in JIRA [14]. By analyzing 7 big open source projects, we further investigated how the productivity was distributed across the communities. To measure the productivity we considered factors such as the community size, the number of fixed issues, the distribution of fixed issuess maintenance type and priority, and the average issue fixing time. As a first result we found the presence of Pareto's law (20{\%} of developers doing 80{\%} of the work), and that there were a few developers that posted and commented the majority of issues. We showed the independence of the average issue resolution time from the other factor considered, such as the community size and the kind of issues mainte-nance and priority. There are many other factors that may impact the average community issue fixing time, for example software component involved in the issue resolution or the portion of code involved. This result agrees with other studies about the social structure of open source projects. We further investigated how the productivity was distributed across the communities. As a third step we focused our attention in understanding the relationship among sentiment, emotions, politeness and productivity measured in terms of " issue fixing time " . In [4], [13] we presented the results about politeness and attractive-ness on 22 open-source software projects developed using the Agile board of the JIRA repository. Our results showed that the level of politeness in the communication process among developers does have an effect on both the time required to fix issues and the attractiveness of the project to both active and potential developers. The more polite developers were, the less time it took to fix an issue. In the majority of cases, the more the developers wanted to be part of project, the more they were willing to continue working on the project over time. In [10] we showed that the three affective metrics, i.e., emo-tions, sentiment and politeness, were independent, showing a weak correlation of at most 0.36, in contrast to some of the control metrics who obtained a moderate to strong correlation among themselves of at most 0.7. Then, we showed how af-fectiveness metrics statistically improve an explanation model of issue fixing time compared to a model based on control metrics. The 4th, 5th and 6th most important metrics in the model corresponded to {\%} of love comments (-50.19{\%}), issue average politeness (+49.76{\%}) and {\%} of sadness comments (+38.39{\%}). In other words, comments containing JOY and LOVE emotions had shorter issue fixing time, while comments containing SADNESS emotion had a longer fixing time. Although we found that the politeness of the last comment},
author = {Ortu, Marco and Destefanis, Giuseppe and Counsell, Steve and Marchesi, Michele and Tonelli, Roberto},
doi = {10.1109/SEmotion.2017.10},
file = {:home/ankur218/master-thesis/thesis-references/07961894.pdf:pdf},
isbn = {9781538627938},
journal = {Proc. - 2017 IEEE/ACM 2nd Int. Work. Emot. Aware. Softw. Eng. SEmotion 2017},
keywords = {affectiveness,development process,emotions},
pages = {52--53},
title = {{Connecting the dots: Measuring effectiveness and affectiveness in software systems}},
year = {2017}
}
@article{Dzvonyar2016,
abstract = {User feedback is an important means of validating require-ments and discovering new requirements in continuous soft-ware evolution. However, users have a low motivation to provide feedback and prefer applications which do not inter-rupt their work. Due to missing context information, devel-opers have difficulties to analyze feedback, and to integrate it into their development work. In this paper, we describe CAFE, a context-aware feed-back system which consists of: (1) a framework for collecting in-situ user feedback enriched with usage context data; and (2) a process for integrating feedback into a team's develop-ment activities. While the process is applicable to all kinds of applications, the implemented framework concentrates on mobile user feedback and its particular challenges. We evaluated CAFE in a mobile application. Our results indicate that the system is a valuable step toward increasing user motivation to provide feedback and decreasing the de-velopers' effort to integrate feedback, ultimately improving user involvement.},
author = {Dzvonyar, Dora and Krusche, Stephan and Alkadhi, Rana and Bruegge, Bernd},
doi = {10.1145/2896941.2896952},
file = {:home/ankur218/master-thesis/thesis-references/dzvonyar2016feedback.pdf:pdf},
isbn = {9781450341578},
journal = {Proc. Int. Work. Contin. Softw. Evol. Deliv. - CSED '16},
keywords = {agile,mobile feedback,recognized as an important,requirements traceability,text,usage con-,user involvement,user involvement has been},
number = {May},
pages = {12--18},
title = {{Context-aware user feedback in continuous software evolution}},
url = {http://dl.acm.org/citation.cfm?doid=2896941.2896952},
year = {2016}
}
@article{Kanakaraj2015,
abstract = {—Most sentiment analysis systems use bag-of-words approach for mining sentiments from the online reviews and social media data. Rather considering the whole sen-tence/paragraph for analysis, the bag-of-words approach consid-ers only individual words and their count as the feature vectors. This may mislead the classification algorithm especially when used for problems like sentiment classification. Traditional ma-chine learning algorithms like Naive Bayes, Maximum Entropy, SVM etc. are widely used to solve the classification problems. These machine learning algorithms often suffer from biasness towards a particular class. In this paper, we propose Natural Language (NLP) based approach to enhance the sentiment classification by adding semantics in feature vectors and thereby using ensemble methods for classification. Adding semantically similar words and context-sense identities to the feature vectors will increase the accuracy of prediction. Experiments conducted demonstrate that the semantics based feature vector with ensem-ble classifier outperforms the traditional bag-of-words approach with single machine learning classifier by 3-5{\%}.},
author = {Kanakaraj, Monisha and Mohana, Ram and Guddeti, Reddy},
doi = {10.1109/ICSCN.2015.7219856},
file = {:home/ankur218/master-thesis/thesis-references/07219856.pdf:pdf},
isbn = {9781467368230},
journal = {Signal Process. Commun. Netw. (ICSCN), 2015 3rd Int. Conf.},
pages = {1--5},
title = {{NLP Based Sentiment Analysis on Twitter Data Using Ensemble Classifiers}},
year = {2015}
}
@article{Guzman2017,
abstract = {Users of the Twitter microblogging platform share a considerable amount of information through short messages on a daily basis. Some of these so-called tweets discuss issues related to software and could include information that is relevant to the companies developing these applications. Such tweets have the potential to help requirements engineers better understand user needs and therefore provide important information for software evolution. However, little is known about the nature of tweets discussing software-related issues. In this paper, we report on the usage characteristics, content and automatic classification potential of tweets about software applications. Our results are based on an exploratory study in which we used descriptive statistics, content analysis, machine learning and lexical sentiment analysis to explore a dataset of 10,986,495 tweets about 30 different software applications. Our results show that searching for relevant information on software applications within the vast stream of tweets can be compared to looking for a needle in a haystack. However, this relevant information can provide valuable input for software companies and support the continuous evolution of the applications discussed in these tweets. Furthermore, our results show that it is possible to use machine learning and lexical sentiment analysis techniques to automatically extract information about the tweets regarding their relevance, authors and sentiment polarity.},
author = {Guzman, Emitza and Alkadhi, Rana and Seyff, Norbert},
doi = {10.1007/s00766-017-0274-x},
file = {:home/ankur218/master-thesis/thesis-references/s00766-017-0274-x.pdf:pdf},
issn = {1432010X},
journal = {Requir. Eng.},
keywords = {Content analysis,Requirements engineering,Software evolution,Textmining,User feedback},
number = {3},
pages = {387--412},
publisher = {Springer London},
title = {{An exploratory study of Twitter messages about software applications}},
volume = {22},
year = {2017}
}
@misc{Rittel1973,
author = {Rittel, Horst W J and Webber, Melvin M},
file = {:home/ankur218/master-thesis/thesis-references/rittel-dilemma.pdf:pdf},
pages = {15},
publisher = {Policy Sciences, Elsevier Scientific Publishing Company},
title = {rittel-dilemma.pdf},
year = {1973}
}
@article{Marshall2016,
abstract = {Social media and discussion centric collaborative tools have become an integral part of software development team communication. Accessible by mobile apps and alongside development tools, these tools provide a medium for conversation and enable teams to share project artifacts including commits, documents, and models. As with other forms of human communication, team members naturally emote during software development, resulting in affective post content expressing emotions such as urgency, frustration, and commendation. The effects of affective interaction on team performance, while studied in the literature, are still not well understood, particularly for student teams. This paper adds to the exploration of affect, by examining the effect of emotional post content on project performance metrics among teams of students in a software engineering course. The data set consists of over thirteen hundred forum posts produced by five teams across three Scrum Sprints in two different classes, each of which was taught by a different instructor. Using manual sentiment analysis techniques, we found that individuals with less emotive posts performed better than those that emoted more and that less affective individuals were evaluated more positively by their peers. From a pedagogical and management perspective, these results indicate that intervention may be needed when posts become emotionally charged in software development team communication. {\textcopyright} 2016 ACM.},
author = {Marshall, Allen and Gamble, Rose F. and Hale, Matthew L.},
doi = {10.1145/2897000.2897003},
file = {:home/ankur218/master-thesis/thesis-references/07801411.pdf:pdf},
isbn = {9781450341691},
journal = {Proc. 1st Int. Work. Emot. Aware. Softw. Eng. - SEmotion '16},
pages = {6--11},
title = {{Outcomes of emotional content from agile team forum posts}},
url = {http://dl.acm.org/citation.cfm?doid=2897000.2897003},
year = {2016}
}
@article{Tu2017,
author = {Tu, Hong T. and Phan, Tuoi T. and Nguyen, Khu P.},
doi = {10.1109/ICSSE.2017.8030943},
file = {:home/ankur218/master-thesis/thesis-references/08030943.pdf:pdf},
isbn = {978-1-5386-3422-6},
journal = {2017 Int. Conf. Syst. Sci. Eng.},
keywords = {-latent semantic analysis,convex optimization,coordinate descent,matrix decomposition,regularization},
number = {6},
pages = {588--593},
title = {{An adaptive Latent Semantic Analysis for text mining}},
url = {http://ieeexplore.ieee.org/document/8030943/},
year = {2017}
}
@article{MEKA2016,
author = {Read, Jesse and Reutemann, Peter and Pfahringer, Bernhard and Holmes, Geoff},
file = {:home/ankur218/master-thesis/thesis-references/12-164.pdf:pdf},
journal = {J. Mach. Learn. Res.},
number = {1},
pages = {667--671},
title = {{Meka: a multi-label/multi-target extension to weka}},
url = {http://jmlr.org/papers/v17/12-164.html},
volume = {17},
year = {2016}
}
@article{AlOmran2017,
abstract = {—To uncover interesting and actionable information from natural language documents authored by software develop-ers, many researchers rely on " out-of-the-box " NLP libraries. However, software artifacts written in natural language are different from other textual documents due to the technical language used. In this paper, we first analyze the state of the art through a systematic literature review in which we find that only a s›mall minority of papers justify their choice of an NLP library. We then report on a series of experiments in which we applied four state-of-the-art NLP libraries to publicly available software artifacts from three different sources. Our results show low agreement between different libraries (only between 60{\%} and 71{\%} of tokens were assigned the same part-of-speech tag by all four libraries) as well as differences in accuracy depending on source: For example, spaCy achieved the best accuracy on Stack Overflow data with nearly 90{\%} of tokens tagged correctly, while it was clearly outperformed by Google's SyntaxNet when parsing GitHub ReadMe files. Our work implies that researchers should make an informed decision about the particular NLP library they choose and that customizations to libraries might be necessary to achieve good results when analyzing software artifacts written in natural language.},
author = {{Al Omran}, Fouad Nasser A. and Treude, Christoph},
doi = {10.1109/MSR.2017.42},
file = {:home/ankur218/master-thesis/thesis-references/msr17.pdf:pdf},
isbn = {9781538615447},
issn = {21601860},
journal = {IEEE Int. Work. Conf. Min. Softw. Repos.},
keywords = {NLP libraries,Natural language processing,Part-of-Speech tagging,Software documentation},
pages = {187--197},
title = {{Choosing an NLP Library for Analyzing Software Documentation: A Systematic Literature Review and a Series of Experiments}},
year = {2017}
}
@article{Manning2009,
abstract = {Class-tested and coherent, this groundbreaking new textbook teaches web-era information retrieval, including web search and the related areas of text classification and text clustering from basic concepts. Written from a computer science perspective by three leading experts in the field, it gives an up-to-date treatment of all aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating systems; and an introduction to the use of machine learning methods on text collections. All the important ideas are explained using examples and figures, making it perfect for introductory courses in information retrieval for advanced undergraduates and graduate students in computer science. Based on feedback from extensive classroom experience, the book has been carefully structured in order to make teaching more natural and effective. Although originally designed as the primary text for a graduate or advanced undergraduate course in information retrieval, the book will also create a buzz for researchers and professionals alike.},
archivePrefix = {arXiv},
arxivId = {0521865719 9780521865715},
author = {Manning, Christopher D. and Ragahvan, Prabhakar and Schutze, Hinrich},
doi = {10.1109/LPT.2009.2020494},
eprint = {0521865719 9780521865715},
file = {:home/ankur218/master-thesis/thesis-references/irbookonlinereading.pdf:pdf},
isbn = {0521865719},
issn = {13864564},
journal = {Inf. Retr. Boston.},
number = {c},
pages = {1--18},
pmid = {10575050},
title = {{An Introduction to Information Retrieval}},
year = {2009}
}
@article{Nonnenmacher2017,
author = {Nonnenmacher, Manuel},
file = {:home/ankur218/master-thesis/thesis-references/Master's Thesis - Final (1).pdf:pdf},
number = {c},
title = {{Master Thesis on Extraction of Rationale from IRC Messages of Open Source Software Developers}},
year = {2017}
}
@article{Brunet2014,
abstract = {Design is often raised in the literature as important to attaining various properties and characteristics in a software system. At least for open-source projects, it can be hard to find evidence of ongoing design work in the technical artifacts produced as part of the development. Although developers usually do not produce specific design documents, they do communicate about design in different ways. In this paper, we provide quantitative evidence that developers address design through discussions in commits, issues, and pull requests. To achieve this, we built a discussions' classifier and automatically labeled 102,122 discussions from 77 projects. Based on this data, we make four observations about the projects: i) on average, 25{\%} of the discussions in a project are about design; ii) on average, 26{\%} of developers contribute to at least one design discussion; iii) only 1{\%} of the developers contribute to more than 15{\%} of the discussions in a project; and iv) these few developers who contribute to a broad range of design discussions are also the top committers in a project.},
author = {Brunet, Jo{\~{a}}o and Murphy, Gail C. and Terra, Ricardo and Figueiredo, Jorge and Serey, Dalton},
doi = {10.1145/2597073.2597115},
file = {:home/ankur218/master-thesis/thesis-references/Do Developers Discuss Design.pdf:pdf},
isbn = {9781450328630},
journal = {MSR conf.},
keywords = {Design Discussions,Empirical Study,Machine Learning},
pages = {340--343},
title = {{Do developers discuss design?}},
url = {http://dl.acm.org.prox.lib.ncsu.edu/citation.cfm?id=2597073.2597115},
year = {2014}
}
@article{Ortu2015,
abstract = {Issue tracking systems store valuable data for testing hy- potheses concerning maintenance, building statistical pre- diction models and the social interactions of developers when interacting with peers. In particular, the Jira Issue Track- ing System (ITS) is a proprietary tracking system that has gained a tremendous popularity in the last years and of- fers unique features like a project management system and the Jira agile kanban board. This paper presents a dataset extracted from the Jira ITS of four popular open source ecosystems (as well as the tools and infrastructure used for extraction), i.e., the Apache Software Foundation, Spring, JBoss and CodeHaus communities. Our dataset hosts more than 1K projects, containing more than 700K issue reports and more than 2 million issue comments. Using this data, we have been able to deeply study the communication pro- cess among developers, and how this aspect affects the de- velopment process. For example, we found that comments posted by developers contain not only technical informa- tion, but also valuable information about sentiments and emotions. With this repository we would like to encourage further studies in these directions.},
author = {Ortu, Marco and Destefanis, Giuseppe and Adams, Bram and Murgia, Alessandro and Marchesi, Michele and Tonelli, Roberto},
doi = {10.1145/2810146.2810147},
file = {:home/ankur218/master-thesis/thesis-references/ortu{\_}promise.pdf:pdf},
isbn = {978-1-4503-3715-1},
journal = {Proc. 11th Int. Conf. Predict. Model. Data Anal. Softw. Eng.},
keywords = {Affective Analysis,Issue Report,Mining software repository},
pages = {1:1----1:4},
title = {{The JIRA Repository Dataset: Understanding Social Aspects of Software Development}},
url = {http://doi.acm.org/10.1145/2810146.2810147},
year = {2015}
}
@article{Al-ghamdi2017,
author = {Al-ghamdi, Sharefah A and Khabti, Joharah and Al-khalifa, Hend S},
file = {:home/ankur218/master-thesis/thesis-references/08244649.pdf:pdf},
isbn = {9781538606643},
keywords = {apis,application programming interfaces,arabic language,natural language processing,nlp,services,web},
number = {Icdim},
title = {{Exploring NLP Web APIs for Building Arabic Systems}},
year = {2017}
}
@article{Hu2017,
author = {Hu, Weiming and Tian, Guodong and Kang, Yongxin and Yuan, Chunfeng and Maybank, Stephen},
doi = {10.1109/TPAMI.2017.2756039},
file = {:home/ankur218/master-thesis/thesis-references/08049406.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
number = {c},
pages = {1--1},
title = {{Dual Sticky Hierarchical Dirichlet Process Hidden Markov Model and Its Application to Natural Language Description of Motions}},
url = {http://ieeexplore.ieee.org/document/8049406/},
volume = {8828},
year = {2017}
}
@article{Sharma2017,
abstract = {{\textcopyright} 2017 Copyright is held by the owner/author(s). Context: Open Source Software (OSS) developers use mailing lists as their main forum for discussing the evolution of a project. However, the use of mailing lists by developers for decision-making has not received much research attention. Objective: We have explored this issue by studying developers' email discussions around Python Enhancement Proposals (PEPs). Method: Our dataset comprised 42,672 emails from six different mailing lists pertaining to PEP development. We performed multiple forms of analysis on these emails, involving both quantitative measures (e.g., frequency) and deeper analysis of specific PEP discussions (i.e., outlier analysis). Results: Out of three PEP types (Informational, Process and Standard Track), Standard Track PEPs attract a large amount of discussion (both in volume and average number of messages per proposal). Our study also identified specific PEP states and topics that generated a disproportionate amount of discussion. Conclusion: Our outcomes point to several opportunities for improving the management of an OSS team based on the knowledge generated from discussions. We have also identified several interesting avenues for future work such as identifying individuals or groups that present persuasive arguments during decision-making.},
author = {Sharma, P. and Savarimuthu, B.T.R. and Stanger, N. and Licorish, S.A. and Rainer, A.},
doi = {10.1145/3084226.3084271},
file = {:home/ankur218/master-thesis/thesis-references/EASE{\_}2017{\_}Sharma{\_}etal{\_}camera{\_}ready{\_}final.pdf:pdf},
isbn = {9781450348041},
journal = {ACM Int. Conf. Proceeding Ser.},
keywords = {Decision-making,Email discussions,Python development},
number = {June},
title = {{Investigating developers' email discussions during decision-making in Python language evolution}},
volume = {Part F1286},
year = {2017}
}
@article{Fan2017,
author = {Fan, Qiang and Yu, Yue and Yin, Gang and Wang, Tao and Wang, Huaimin},
doi = {10.1109/ESEM.2017.19},
file = {:home/ankur218/master-thesis/thesis-references/Where is the Road for Issue Reports Classification.pdf:pdf},
isbn = {9781509040391},
journal = {Empir. Softw. Eninneering Meas. 2017},
keywords = {issue tracking system, machine learning technique,},
pages = {121--130},
title = {{Where is the Road for Issue Reports Classification Based on Text Mining ?}},
year = {2017}
}
@article{Murgia2014,
abstract = {Software development is a collaborative activity in which developers interact to create and maintain a complex software system. Human collaboration inevitably evokes emotions like joy or sadness, which can affect the collaboration either positively or negatively, yet not much is known about the individual emotions and their role for software development stakeholders. In this study, we analyze whether development artifacts like issue reports carry any emotional information about software development. This is a first step towards verifying the feasibility of an automatic tool for emotion mining in software development artifacts: if humans cannot determine any emotion from a software artifact, neither can a tool. Analysis of the Apache Software Foundation issue tracking system shows that developers do express emotions (in particular gratitude, joy and sadness). However, the more context is provided about an issue report, the more human raters start to doubt and nuance their interpretation of emotions. More investigation is needed before building a fully automatic emotion mining tool.},
author = {Murgia, Alessandro and Tourani, Parastou and Adams, Bram and Ortu, Marco},
doi = {10.1145/2597073.2597086},
file = {:home/ankur218/master-thesis/thesis-references/Do Developers Feel Emotions.pdf:pdf},
isbn = {9781450328630},
journal = {Proc. 11th Work. Conf. Min. Softw. Repos. - MSR 2014},
keywords = {emotion mining,empirical software engineer-,issue report},
pages = {262--271},
title = {{Do developers feel emotions? an exploratory analysis of emotions in software artifacts}},
url = {http://dl.acm.org/citation.cfm?doid=2597073.2597086},
year = {2014}
}
@article{Hesse2016,
abstract = {Context: Decision-making is a vital task during software development. Typically, issue tracking systems are used to document decisions in large open source projects where developers are spread across the world. While most decision documentation approaches assume that developers use rational decision strategies, in practice also naturalistic strategies are employed. However, quantitative studies of the distribution of decision strategies and related knowledge are missing. Objective: Our overall goal is to provide insights and ideas for further research to systematically support and document decision-making during software development in open source projects. In this paper, we analyze decisions documented in comments to issue reports in order to understand the documentation of decision-making in detail. Method: We coded the comments of 260 issue reports of the open source project Firefox for decision-making strategies and knowledge on decisions. Then, we statistically analyzed the coded data with regard to the dominant decision strategy, the distribution of decision strategies and knowledge, and the relations between strategy and knowledge. Results: The vast majority of documented decision-making strategies was naturalistic. Interestingly, for feature requests the percentage of rational decision-making strategies was higher than for bugs. Documented knowledge mostly concerned the decision context. More solutions were documented together with a higher amount of naturalistic decision-making. However, solutions were negatively correlated with the assessment of the situation. So, developers are likely to exploit and document decision problems and solutions in an imbalanced way. Conclusion: Our analysis revealed important insights on how decision-making and its related knowledge is documented during software development in open source projects. For instance, we found naturalistic decision-making to play an important role for development decisions. Our coding tables can be used by other researchers to further investigate our results. The study insights should be reflected in decision support systems to improve their effectiveness and acceptance by developers.},
author = {Hesse, Tom Michael and Lerche, Veronika and Seiler, Marcus and Knoess, Konstantin and Paech, Barbara},
doi = {10.1016/j.infsof.2016.06.003},
file = {:home/ankur218/master-thesis/thesis-references/Documented decision-making strategies.pdf:pdf},
issn = {09505849},
journal = {Inf. Softw. Technol.},
keywords = {Decision documentation,Decision knowledge,Decision-making strategy,Design decision,Empirical study,Issue tracking system,Naturalistic decision-making,Rational decision-making,Software development decision},
pages = {36--51},
publisher = {Elsevier B.V.},
title = {{Documented decision-making strategies and decision knowledge in open source projects: An empirical study on Firefox issue reports}},
url = {http://dx.doi.org/10.1016/j.infsof.2016.06.003},
volume = {79},
year = {2016}
}
@article{Robillard2017,
abstract = {—We advocate for a paradigm shift in supporting the information needs of developers, centered around the concept of automated on-demand developer documentation. Currently, developer information needs are fulfilled by asking experts or consulting documentation. Unfortunately, traditional documenta-tion practices are inefficient because of, among others, the manual nature of its creation and the gap between the creators and consumers. We discuss the major challenges we face in realizing such a paradigm shift, highlight existing research that can be leveraged to this end, and promote opportunities for increased convergence in research on software documentation.},
author = {Robillard, Martin P and Marcus, Andrian and Treude, Christoph and Bavota, Gabriele and Chaparro, Oscar and Ernst, Neil and Gerosa, Marco Aur{\'{e}}lio and Godfrey, Michael and Lanza, Michele and Linares-V{\'{a}}squez, Mario and Murphy, Gail C and Moreno, Laura and Shepherd, David and Wong, Edmund},
doi = {10.1109/ICSME.2017.17},
file = {:home/ankur218/master-thesis/thesis-references/On-Demand Developer Documentation.pdf:pdf},
isbn = {9781538609927},
journal = {Int. Conf. Softw. Maint. Evol.},
pages = {5},
title = {{On-Demand Developer Documentation}},
url = {http://www.inf.usi.ch/lanza/Downloads/Robi2017a.pdf},
year = {2017}
}
@inproceedings{Rennie2003,
abstract = {Naive Bayes is often used as a baseline in text classification because it is fast and easy to implement. Its severe assumptions make such eciency possible but also adversely affect the quality of its results. In this paper we propose simple, heuristic solutions to some of the problems with Naive Bayes classifiers, addressing both systemic issues as well as problems that arise because text is not actually generated according to a multinomial model. We find that our simple corrections result in a fast algorithm that is competitive with stateof-the-art text classification algorithms such as the Support Vector Machine.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Rennie, Jason D M and Shih, Lawrence and Teevan, Jaime and Karger, David R},
booktitle = {Proc. Twent. Int. Conf. Mach. Learn.},
doi = {10.1186/1477-3155-8-16},
eprint = {arXiv:1011.1669v3},
file = {:home/ankur218/master-thesis/thesis-references/icml03-nb.pdf:pdf},
isbn = {978-1-57735-189-4},
issn = {14773155},
pages = {616--623},
pmid = {20630072},
series = {ICML '03},
title = {{Tackling the Poor Assumptions of Naive Bayes Text Classifiers}},
url = {http://www.aaai.org/Papers/ICML/2003/ICML03-081.pdf},
year = {2003}
}
@article{Samuel1959a,
abstract = {Two machine-learning procedures have been investigated 1 in some detail using the game of checkers. Enough work has been done to verify the fact that a computer can be programmed so that it will learn to play a better game of checkers than can be played by the person who wrote the program. Further- more, it can learn to do this in a remarkably short period of time (8 or 10 hours of machine-playing time) when given only the rules of the game, a sense of direction, and a redundant and incomplete list of parameters which are thought to have something to do with the game, but whose correct signs and relative weights are unknown and unspecified. The principles of machine learning verified by these experiments are, of course, applicable to many other situations.},
author = {Samuel, Artur L},
doi = {10.1147/rd.33.0210},
file = {:home/ankur218/master-thesis/thesis-references/05392560.pdf:pdf},
isbn = {0018-8646},
issn = {0018-8646},
journal = {IBM J. Res. Dev.},
number = {3},
pages = {210--229},
title = {{Some studies in machine learning using the game of checkers}},
volume = {3},
year = {1959}
}
@article{InstituteofManagementSciences.1967,
abstract = {With v. 11, no. 3-v. 13, no. 12; Sept. 1965-Aug. 1967: Alternate issues called: Series A, Sciences; or: Series B, Managerial, Series C, Bulletin, each series continuously paged within the volume. With v. 14-21; Sept. 1967-Aug. 1975: Alternate numbers called Theory or Application series. Includes special issues: The Professional series in the management sciences. Issues for Feb. 1965-Aug. 1967 include Bulletin of the Institute of Management Sciences. Feb. 1965-Aug. 1967 include Bulletin of the Institute of Management Sciences.},
author = {West, Churchman and {Institute of Management Sciences.} and {Institute for Operations Research and the Management Sciences.} and Sciences., Institute of Management},
file = {:home/ankur218/master-thesis/thesis-references/mnsc.14.4.b141.pdf:pdf},
issn = {0025-1909},
number = {January 2018},
pages = {B--141--B--146},
title = {{Management science.}},
year = {1967}
}
@article{Alkadhi2014,
abstract = {User feedback is a rich source of information which can help developers to improve software quality and identify missing features. However, developers need to analyze user feedback in order to assess its relevance and potential impact, which bears several challenges due to its quantity, quality, structure, and content, particularly when feedback volume is high. In this paper we present the results of a case study to explore which role collaborative tagging can play to improve user feedback, in particular, its impact on the navigation within, understandability, and structure of user feedback. Our results indicate that collaborative tagging might contribute to decrease the pain when analyzing and organizing user feedback. },
author = {Alkadhi, Rana and Pagano, Dennis and Bruegge, Bernd},
doi = {10.1145/2661685.2661692},
file = {:home/ankur218/master-thesis/thesis-references/p1-alkadhi.pdf:pdf},
isbn = {9781450332279},
journal = {Proc. 6th Int. Work. Soc. Softw. Eng. - SSE 2014},
keywords = {Social software,collaborative tagging,user feedback,user involvement},
pages = {1--8},
title = {{Can collaborative tagging improve user feedback? a case study}},
url = {http://dl.acm.org/citation.cfm?doid=2661685.2661692},
year = {2014}
}
@article{Li2018,
author = {Li, Weifeng and Yin, Junming and Chen, HsinChun},
doi = {10.1109/TKDE.2017.2786727},
file = {:home/ankur218/master-thesis/thesis-references/08239623.pdf:pdf},
issn = {1041-4347},
journal = {IEEE Trans. Knowl. Data Eng.},
number = {XX},
pages = {1--1},
title = {{Supervised Topic Modeling using Hierarchical Dirichlet Process-based Inverse Regression: Experiments on E-Commerce Applications}},
url = {http://ieeexplore.ieee.org/document/8239623/},
volume = {XX},
year = {2018}
}
@article{Blei2003,
abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
archivePrefix = {arXiv},
arxivId = {1111.6189v1},
author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
doi = {http://dx.doi.org/10.1162/jmlr.2003.3.4-5.993},
eprint = {1111.6189v1},
file = {:home/ankur218/master-thesis/thesis-references/nips01-lda.pdf:pdf},
isbn = {9781577352815},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
number = {3},
pages = {993--1022},
pmid = {21362469},
title = {{Latent Dirichlet Allocation}},
volume = {3},
year = {2003}
}
@article{Singh2016,
abstract = {Supervised machine learning is the construction of algorithms that are able to produce general patterns and hypotheses by using externally supplied instances to predict the fate of future instances. Supervised machine learning classification algorithms aim at categorizing data from prior information. Classification is carried out very frequently in data science problems. Various successful techniques have been proposed to solve such problems viz. Rule-based techniques, Logic-based techniques, Instance-based techniques, stochastic techniques. This paper discusses the efficacy of supervised machine learning algorithms in terms of the accuracy, speed of learning, complexity and risk of over fitting measures. The main objective of this paper is to provide a general comparison with state of art machine learning algorithms. {\&}copy; 2016 IEEE.},
author = {Singh, Amanpreet and Thakur, Narina and Sharma, Aakanksha},
file = {:home/ankur218/master-thesis/thesis-references/07724478.pdf:pdf},
isbn = {9789380544199},
journal = {Proc. 10th INDIACom; 2016 3rd Int. Conf. Comput. Sustain. Glob. Dev. INDIACom 2016},
keywords = {ann,artificial neural networks,bayesian,bn,decision trees,dt,k-nearest neighbors,k-nn,logistic regression,lr,network,random forests,rf,supervised},
pages = {1310--1315},
title = {{A review of supervised machine learning algorithms}},
url = {https://www.engineeringvillage.com/share/document.url?mid=cpx{\_}4dbc01df158d4d5e77dM6b8b10178163171{\&}database=cpx},
year = {2016}
}
@article{Katsumata2016,
author = {Katsumata, Sotaro},
doi = {10.1109/ICDMW.2016.141},
file = {:home/ankur218/master-thesis/thesis-references/07836714.pdf:pdf},
journal = {Icdm},
title = {{Website Classification Using Latent Dirichlet Allocation and its Application for Internet Advertising}},
year = {2016}
}
@inproceedings{Toman2006,
abstract = {In this paper we focus our attention on the comparison of various lemmatization and stemming algorithms, which are often used in nature language processing (NLP). Sometimes these two techniques are considered to be identical, but there is an important difference. Lemmatization is generally more utilizable, because it produces the basic word form which is required in many application areas (i.e. cross-language processing and machine translation). However, lemmatization is a difficult task -especially for highly inflected natural languages having a lot of words for the same normalized word form. We present a novel lemmatization algorithm which utilizes the multilingual semantic thesaurus Eurowordnet (EWN). We describe the algorithm in detail and compare it with other widely used algorithms for word normalization on two different corpora. We present promising results obtained by our EWN-based lemmatization approach in comparison to other techniques. We also discuss the influence of the word normalization on classification task in general. In overall, the performance of our method is good and it achieves similar precision and recall in comparison with other word normalization methods. However, our experiments indicate that word normalization does not affect the text classification task significantly.},
author = {Toman, Michal and Tesar, Roman and Jezek, Karel},
booktitle = {Proc. InSciT},
file = {:home/ankur218/master-thesis/thesis-references/10.1.1.83.6363.pdf:pdf},
isbn = {9780494016435; 0494016434},
keywords = {classification,eurowordnet,lemmatization,stemming,word normalization},
pages = {354--358},
title = {{Influence of word normalization on text classification}},
url = {http://www.kiv.zcu.cz/research/groups/text/publications/inscit20060710.pdf},
year = {2006}
}
@article{Rogers2014,
abstract = {Software development and maintenance require making many decisions over the lifetime of the software. The decision problems, alternative solu- tions, and the arguments for and against these solutions comprise the sys- tem's rationale. This information is potentially valuable as a record of the developer and maintainers' intent. Unfortunately, this information is not explicitly captured in a structured form that can be easily analyzed. Still, while rationale is not explicitly captured, that does not mean that rationale is not captured at all—decisions are documented in many ways throughout the development process. This paper tackles the issue of extracting ra- tionale from text by describing a mechanism for using two existing tools, GATE (General Architecture for Text Engineering) and WEKA (Waikato Environment for Knowledge Analysis) to build classification models for text mining of rationale. We used this mechanism to evaluate different combinations of text features and machine learning algorithms to extract rationale from Chrome bug reports. Our results are comparable in accuracy to to those obtained by human annotators.},
author = {Rogers, Benjamin and Qiao, Yechen and Gung, James and Mathur, Tanmay and Burge, Janet E},
doi = {10.1007/978-3-319-14956-1_26},
file = {:home/ankur218/master-thesis/thesis-references/1eb88cd5010117131bdcc6be49750b086f8b.pdf:pdf},
journal = {6th Int. Conf. Des. Comput. Cogn.},
pages = {1----20},
title = {{Using Text Mining Techniques to Extract Rationale from Existing Documentation}},
year = {2014}
}
@article{Guzman2016,
abstract = {Users of the Twitter microblogging platform share a vast amount of information about various topics through short messages on a daily basis. Some of these so called tweets include information that is relevant for software companies and could, for example, help requirements engineers to identify user needs. Therefore, tweets have the potential to aid in the continuous evolution of software applications. Despite the existence of such relevant tweets, little is known about their number and content. In this paper we report on the results of an exploratory study in which we analyzed the usage characteristics, content and automatic classification potential of tweets about software applications by using descriptive statistics, content analysis and machine learning techniques. Although the manual search of relevant information within the vast stream of tweets can be compared to looking for a needle in a haystack, our analysis shows that tweets provide a valuable input for software companies. Furthermore, our results demonstrate that machine learning techniques have the capacity to identify and harvest relevant information automatically.},
author = {Guzman, Emitza and Alkadhi, Rana and Seyff, Norbert},
doi = {10.1109/RE.2016.67},
file = {:home/ankur218/master-thesis/thesis-references/07765515.pdf:pdf},
isbn = {9781509041213},
journal = {Proc. - 2016 IEEE 24th Int. Requir. Eng. Conf. RE 2016},
pages = {96--105},
title = {{A Needle in a Haystack: What Do Twitter Users Say about Software?}},
year = {2016}
}
@article{Mannila1996a,
abstract = {Knowledge discovery in databases and data mining aim at semiautomatic tools for the analysis of large data sets. We give an overview of the area and present some of the research issues, especially from the database angle},
author = {Mannila, Heikki},
doi = {10.1109/SSDM.1996.505910},
file = {:home/ankur218/master-thesis/thesis-references/00505910.pdf:pdf},
isbn = {0-8186-7264-1},
journal = {Proc. 8th Int. Conf. Sci. Stat. Data Base Manag.},
pages = {2--9},
title = {{Data mining: machine learning, statistics, and databases}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=505910},
year = {1996}
}
@article{Damiano2017,
abstract = {{\textcopyright} 2016 IEEE. In the last years, Cognitive Systems are increasingly appearing, offering new ways for developing Question Answering solutions able to autonomously extract an answer for a question formulated in natural language. Currently, to the best of our knowledge, most of the available Question Answering solutions are designed for the English language and use SQL-like knowledge bases to provide factual answers to a natural language question. Starting from these considerations, this work presents a preliminary Question Answering framework for closed-domains, like Cultural Heritage. It has been expressly thought to extract factual answers from collections of documents by operating with the Italian language. Such a framework exploits a variety of NLP methods for the Italian language to help the understanding of user's questions and the extraction of precise answers from textual passages contained into documents. Moreover, Deep Learning techniques have been used to proficiently understand the topic of a question, whereas a rule-based approach relying on dictionaries has been applied for the annotation and indexing of collections of documents in Italian, enabling their usage into a state-of-the-art Information Retrieval engine. An experimental session has also been arranged, showing very promising preliminary results.},
author = {Damiano, Emanuele and Spinelli, Raffaele and Esposito, Massimo and Pietro, Giuseppe De},
doi = {10.1109/SITIS.2016.100},
file = {:home/ankur218/master-thesis/thesis-references/07907527.pdf:pdf},
isbn = {9781509056989},
journal = {Proc. - 12th Int. Conf. Signal Image Technol. Internet-Based Syst. SITIS 2016},
keywords = {Cognitive Computing,Italian Text,NLP,Question answering,Unstructured Information},
pages = {604--611},
title = {{Towards a Framework for Closed-Domain Question Answering in Italian}},
year = {2017}
}
@article{Tian2015,
abstract = {Many software artifacts are written in natural language or contain substantial amount of natural language contents. Thus these artifacts could be analyzed using text analysis techniques from the natural language processing (NLP) community, e.g., the part-of-speech (POS) tagging technique that assigns POS tags (e.g., verb, noun, etc.) to words in a sentence. In the literature, several studies have already applied POS tagging technique on software artifacts to recover important words in them, which are then used for automating various tasks, e.g., locating buggy files for a given bug report, etc. There are many POS tagging techniques proposed and they are trained and evaluated on non software engineering corpus (documents). Thus it is unknown whether they can correctly identify the POS of a word in a software artifact and which of them performs the best. To fill this gap, in this work, we investigate the effectiveness of seven POS taggers on bug reports. We randomly sample 100 bug reports from Eclipse and Mozilla project and create a text corpus that contains 21,713 words. We manually assign POS tags to these words and use them to evaluate the studied POS taggers. Our comparative study shows that the state-of-the-art POS taggers achieve an accuracy of 83.6{\%}-90.5{\%} on bug reports and the Stanford POS tagger and the TreeTagger achieve the highest accuracy on the sampled bug reports. Our findings show that researchers could use these POS taggers to analyze software artifacts, if an accuracy of 80-90{\%} is acceptable for their specific needs, and we recommend using the Stanford POS tagger or the TreeTagger.},
author = {Tian, Yuan and Lo, David},
doi = {10.1109/SANER.2015.7081879},
file = {:home/ankur218/master-thesis/thesis-references/A comparative study on the effectiveness of part-of-speech tagging techniques on bug reports.pdf:pdf},
isbn = {9781479984695},
journal = {2015 IEEE 22nd Int. Conf. Softw. Anal. Evol. Reengineering, SANER 2015 - Proc.},
pages = {570--574},
title = {{A comparative study on the effectiveness of part-of-speech tagging techniques on bug reports}},
year = {2015}
}
@article{Lata2016,
author = {Lata, Teodora},
file = {:home/ankur218/master-thesis/thesis-references/Thesis{\_}Teodora{\_}Lata.pdf:pdf},
number = {c},
title = {{Bachelor Thesis on Mining of Chat Messages to Reconstruct Rationale}},
year = {2016}
}
@article{Alkadhi2017,
abstract = {Chat messages of development teams play an increasingly significant role in software development, having replaced emails in some cases. Chat messages contain information about discussed issues, considered alternatives and argumentation leading to the decisions made during software development. These elements, defined as rationale, are invaluable during software evolution for documenting and reusing development knowledge. Rationale is also essential for coping with changes and for effective maintenance of the software system. However, exploiting the rationale hidden in the chat messages is challenging due to the high volume of unstructured messages covering a wide range of topics. This work presents the results of an exploratory study examining the frequency of rationale in chat messages, the completeness of the available rationale and the potential of automatic techniques for rationale extraction. For this purpose, we apply content analysis and machine learning techniques on more than 8,700 chat messages from three software development projects. Our results show that chat messages are a rich source of rationale and that machine learning is a promising technique for detecting rationale and identifying different rationale elements.},
archivePrefix = {arXiv},
arxivId = {1704.08500},
author = {Alkadhi, Rana and Lata, Teodora and Guzmany, Emitza and Bruegge, Bernd},
doi = {10.1109/MSR.2017.43},
eprint = {1704.08500},
file = {:home/ankur218/master-thesis/thesis-references/Rationale in development chat messages.pdf:pdf},
isbn = {9781538615447},
issn = {21601860},
journal = {IEEE Int. Work. Conf. Min. Softw. Repos.},
keywords = {Chat messages,Empirical Software Engineering,Rationale},
pages = {436--446},
title = {{Rationale in Development Chat Messages: An Exploratory Study}},
year = {2017}
}
@article{Goel2017,
author = {Goel, Priya},
file = {:home/ankur218/master-thesis/thesis-references/Thesis{\_}Priya{\_}{\_}TUM{\_}FINALVER2 (1).pdf:pdf},
title = {{Master's Thesis on Detecting emerging business sectors using mobile application market analysis.}},
year = {2017}
}
@article{Kurtanovic2017,
abstract = {Rationale refers to the reasoning and justification behind human decisions, opinions, and beliefs. In software engineering, rationale management focuses on capturing design and requirements decisions and on organizing and reusing project knowledge. This paper takes a different view on rationale written by users in online reviews. We studied 32,414 reviews for 52 software applications in the Amazon Store. Through a grounded theory approach and peer content analysis, we investigated how users argue and justify their decisions, e.g. about upgrading, installing, or switching software applications. We also studied the occurrence frequency of rationale concepts such as issues encountered or alternatives considered in the reviews and found that assessment criteria like performance, compatibility, and usability represent the most pervasive concept. We then used the truth set of manually labeled review sentences to explore how accurately we can mine rationale concepts from the reviews. Support Vector Classifier, Naive Bayes, and Logistic Regression, trained on the review metadata, syntax tree of the review text, and influential terms, achieved a precision around 80{\%} for predicting sentences with alternatives and decisions, with top recall values of 98{\%}. On the review level, precision was up to 13{\%} higher with recall values reaching 99{\%}. We discuss the findings and the rationale importance for supporting deliberation in user communities and synthesizing the reviews for developers.},
author = {Kurtanovic, Zijad and Maalej, Walid},
doi = {10.1109/RE.2017.86},
file = {:home/ankur218/master-thesis/thesis-references/Mining User Rationale from Software Reviews.pdf:pdf},
isbn = {978-1-5386-3191-1},
journal = {2017 IEEE 25th Int. Requir. Eng. Conf.},
pages = {61--70},
title = {{Mining User Rationale from Software Reviews}},
url = {http://ieeexplore.ieee.org/document/8048891/},
year = {2017}
}
@article{Tran2017,
author = {Tran, Trung Kien and Sato, Hiroshi},
file = {:home/ankur218/master-thesis/thesis-references/08233569.pdf:pdf},
isbn = {9781538607435},
keywords = {api calls are the,api sequence,benignwares,etc,idf,malware,methods that computer programs,natural language process,paragraph vectors,tf-,the operating,use to communicate with},
pages = {101--105},
title = {{NLP-based Approaches for Malware Classification from API Sequences}},
year = {2017}
}
@article{Peng2002,
abstract = {The purpose of this article is to provide researchers, editors, and readers with a set of guidelines for what to expect in an article using logistic regression tech- niques. Tables, figures, and charts that should be included to comprehensively assess the results and assumptions to be ver- ified are discussed. This article demonstrates the preferred pattern for the application of logistic methods with an illustra- tion of logistic regression applied to a data set in testing a research hypothesis. Recommendations are also offered for appropriate reporting formats of logistic regression results and the minimum observation-to-predictor ratio. The authors evaluated the use and interpretation of logistic regression pre- sented in 8 articles published in The Journal of Educational Research between 1990 and 2000. They found that all 8 studies met or exceeded recommended criteria. Key},
author = {Peng, Chao-Ying Joanne and Lee, Kuk Lida and Ingersoll, Gary M.},
doi = {10.1080/00220670209598786},
file = {:home/ankur218/master-thesis/thesis-references/10.1.1.600.8212.pdf:pdf},
isbn = {4478015481},
issn = {0022-0671},
journal = {J. Educ. Res.},
keywords = {binary data analysis,categorical variables,dichotomous outcome,logistic modeling,logistic regression},
number = {1},
pages = {3--14},
pmid = {18498816},
title = {{An Introduction to Logistic Regression Analysis and Reporting}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00220670209598786},
volume = {96},
year = {2002}
}
@article{Somasundaram2012,
author = {Somasundaram, Kalyanasundaram and Murphy, Gail C},
file = {:home/ankur218/master-thesis/thesis-references/Automatic categorization of bug reports using latent Dirichlet allocation.pdf:pdf},
isbn = {9781450311427},
journal = {Proc. 5th ACM India Softw. Eng. Conf.},
keywords = {component recommendation,recommendation system,software bug triage},
pages = {125--130},
title = {{Automatic Categorization of Bug Reports Using Latent Dirichlet Allocation}},
year = {2012}
}
@article{Dutoit2006,
abstract = {Rationale is the justification behind decisions. It is captured and used in many different forms during software engineering. While it has not achieved widespread use in practice, several approached have emerged and successfully been used in seelcted projects. The goal of this chapter is to review the current state-of-the-art of rationale management approaches and tool support in software engineering, and map future research directions.},
author = {Dutoit, Ah},
file = {:home/ankur218/master-thesis/thesis-references/10.1.1.22.1259.pdf:pdf},
isbn = {3540309977},
journal = {Ration. Manag. Softw. Eng.},
keywords = {design rationale,ibis,issue model,negotiation,qoc,software evolution},
number = {0},
pages = {1--48},
title = {{Rationale management in software engineering}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.22.1259{\&}rep=rep1{\&}type=pdf},
volume = {0},
year = {2006}
}
@article{Jain2017,
author = {Jain, Pratiksha},
file = {:home/ankur218/master-thesis/thesis-references/Patents.pdf:pdf},
title = {{Master's Thesis on Predicting companies success on patent application success with help of machine learning and data analysis.}},
year = {2017}
}
@article{Bacchelli2012,
author = {Bacchelli, Alberto and {Dal Sasso}, Tommaso and D'Ambros, M and Lanza, M},
file = {:home/ankur218/master-thesis/thesis-references/Content Classification of Development Emails.pdf:pdf},
isbn = {9781467310673},
journal = {Proc. 34th ACM/IEEE Int. Conf. Softw. Eng.},
keywords = {-empirical software engineering,unstructured},
pages = {375--385},
title = {{Content Classifcation of Development Emails}},
year = {2012}
}
@article{mockus2002two,
annote = {Can OSS development compete with traditional development methods?

- Apache web server and the Mozilla browser},
author = {Mockus, Audris and Fielding, Roy T and Herbsleb, James D},
file = {:home/ankur218/master-thesis/thesis-references/mozilla.pdf:pdf},
journal = {ACM Trans. Softw. Eng. Methodol.},
number = {3},
pages = {309--346},
title = {{Two Case Studies of Open Source Software Development: Apache and Mozilla}},
volume = {11},
year = {2002}
}
@article{Karbab2017,
abstract = {The astonishing spread of Android OS, not only in smartphones and tablets but also in IoT devices, makes this operating system a very tempting target for malware threats. Indeed, the latter are expanding at a similar rate. In this respect, malware fingerprints, whether based on cryptographic or fuzzy-hashing, are the first defense line against such attacks. Fuzzy-hashing fingerprints are suitable for capturing malware static features. Moreover, they are more resilient to small changes in the actual static content of malware files. On the other hand, dynamic analysis is another technique for malware detection that uses emulation environments to extract behavioral features of Android malware. However, to the best of our knowledge, there is no such fingerprinting technique that leverages dynamic analysis and would act as the first defense against Android malware attacks. In this paper, we address the following question: could we generate effective fingerprints for Android malware through dynamic analysis? To this end, we propose DySign, a novel technique for fingerprinting Android malware's dynamic behaviors. This is achieved through the generation of a digest from the dynamic analysis of a malware sample on existing known malware. It is important to mention that: (i) DySign fingerprints are approximated of the observed behaviors during dynamic analysis so as to achieve resiliency to small changes in the behaviors of future malware variants; (ii) Fingerprint computation is agnostic to the analyzed malware sample or family. DySign leverages state-of-the-art Natural Language Processing (NLP) techniques to generate the aforementioned fingerprints, which are then leveraged to build an enhanced Android malware detection system with family attribution.},
archivePrefix = {arXiv},
arxivId = {1702.05699},
author = {Karbab, El Mouatez Billah and Debbabi, Mourad and Alrabaee, Saed and Mouheb, Djedjiga},
doi = {10.1109/MALWARE.2016.7888739},
eprint = {1702.05699},
file = {:home/ankur218/master-thesis/thesis-references/07888739.pdf:pdf},
isbn = {9781509045426},
journal = {2016 11th Int. Conf. Malicious Unwanted Software, MALWARE 2016},
pages = {139--146},
title = {{DySign: Dynamic fingerprinting for the automatic detection of android malware}},
year = {2017}
}
@article{Machado2014,
abstract = {Humans are hardwired as problem-solvers. Professional education, in particular, enables us to solve complex problems. Even decades ago, we could safely send a crew to the moon and back. A moon-bound project is a very challenging and complex problem, but it is a tame one. The problem is clearly defined and the challenge becomes how to find the best solution. As the world and issues become more interconnected, there is a different type of problem in the horizon - "wicked" problems. A wicked problem is normally complex and challenging, but differs from the "tame" problem because there is no agreement in terms of problem definition. A wicked problem does not allow for the "choice" of best solution. Solutions tend to only mitigate the problem and sometimes generate unpredictable consequences. For instance, climate change is an issue that requires a level of ingenuity that cannot be achieved by a limited group of people, regardless how brilliant they are. It cannot be addressed by our dominant scientific, reductionist, discipline-based, and proprietary approach either. This paper proposes Massive Online Open Research (MOOR) as a better approach to deal with wicked problems. In terms of organization, this paper includes a literature review on online collaboration, focusing on the dynamics of knowledge creation and innovation. Selected open online research initiatives are used to contextualize the literature review. Based on the literature review and real cases, a MOOR framework is presented and discussed. Limitations and opportunities for future research are also included.},
author = {Machado, Marcelo a and Verghese, George and Peltola, Tero},
file = {:home/ankur218/master-thesis/thesis-references/06921178.pdf:pdf},
isbn = {9781890843304},
journal = {PICMET '14 Infrastruct. Serv. Integr.},
pages = {236--242},
title = {{Massive Open Online Research : An Approach to Deal with Wicked Problems}},
year = {2014}
}
@article{Agung2017,
author = {Agung, Anak and Ratna, Putri and Sanjaya, Randy and Wirianata, Tomi and Purnamasari, Prima Dewi},
file = {:home/ankur218/master-thesis/thesis-references/08168488.pdf:pdf},
isbn = {9786025043116},
keywords = {an essay grading,assess student documents,assessment process,csm,essay grading,jaro-winkler,lsa,lsi,or in other words,svd,that can automatically,time efficiency in essay,to improve objectivity and,we need a system},
pages = {235--240},
title = {{Word Level Auto-correction for Latent Semantic Analysis Based Essay Grading System}},
year = {2017}
}
@article{Guzzi2013,
abstract = {"IEEE Catalog Number: CFP1378C-ART"--Copyright page. " ... co-located with the 35th ACM/IEEE International Conference on Software Engineering (ICSE 2013)" -- Welcome from the Chairs.},
author = {Guzzi, Anja and Bacchelli, Alberto and Lanza, Michele and Pinzger, Martin and {Van Deursen}, Arie},
doi = {10.1109/MSR.2013.6624039},
file = {:home/ankur218/master-thesis/thesis-references/Communication in Open Source Software Development Mailing Lists.pdf:pdf},
isbn = {9781467329361},
issn = {21601852},
journal = {IEEE Int. Work. Conf. Min. Softw. Repos.},
pages = {277--286},
title = {{Communication in open source software development mailing lists}},
year = {2013}
}
@article{Suhaimin2017,
author = {Suhaimin, Mohd Suahiri Md and Hanafi, Mohd and Hijazi, Ahmad and Alfred, Rayner and Coenen, Frans and Resource, Human and Division, Management and Kingdom, United},
file = {:home/ankur218/master-thesis/thesis-references/08079931.pdf:pdf},
isbn = {9781509063321},
keywords = {bilingual,feature,feature extraction,language,language is,sarcasm detection,sentiment analysis,shortened word forms and,stylistic text coupled with,the misspelled words,the use of dual},
pages = {703--709},
title = {{Natural Language Processing Based Features for Sarcasm Detection : An Investigation Using Bilingual Social Media Texts}},
year = {2017}
}
@article{Linstead2007,
author = {Linstead, Erik and Rigor, Paul and Bajracharya, Sushil and Lopes, Cristina and Baldi, Pierre},
doi = {10.1145/1321631.1321709},
file = {:home/ankur218/master-thesis/thesis-references/0ec16425bc23ad2bb29402c00fcf0620d43c.pdf:pdf},
isbn = {978-1-59593-882-4},
journal = {Proc. Twenty-second IEEE/ACM Int. Conf. Autom. Softw. Eng.},
keywords = {mining software,program understanding,topic models},
pages = {461--464},
title = {{Mining Concepts from Code with Probabilistic Topic Models}},
url = {http://doi.acm.org/10.1145/1321631.1321709},
year = {2007}
}
@article{Littman1996,
abstract = {This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible to researchers familiar with machine learning. Both the historical basis of the field and a broad selection of current work are summarized. Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. The work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word ``reinforcement.'' The paper discusses central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state. It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning.},
archivePrefix = {arXiv},
arxivId = {cs/9605103},
author = {Littman, Michael and Moore, Andrew},
doi = {10.1613/jair.301},
eprint = {9605103},
file = {:home/ankur218/master-thesis/thesis-references/live-301-1562-jair.pdf:pdf},
isbn = {0-7803-3213-X},
issn = {10769757},
journal = {Eur. Signal Process. Conf.},
pages = {1475 -- 1479},
pmid = {17255001},
primaryClass = {cs},
title = {{Reinforcement Learning: A Survey}},
year = {2011}
}
@article{Liu2008,
abstract = {This article makes further study on data needed by automatic construction for chinese medicinal ontology' concept description arch itacture, reconstructs and uses recognized knowledge in Chinese medicine's domain by theory and technology of NLP. Based on realizing Chinese medicine knowledge description architacture's automatic construction and acqui. ri. ng successfully, this article use experts' knowledge to realize au-learning system of limited text's ontology and try exploring domain ontology' evolution it revolve bottleneck problems oJ' ontology study effectively to lay the data base for Chinese knowledge's dining and use. Untill now, this has been more ideal and applied method and its successful study would be provide theory gist and technology supportfor professional domain ontology's automatic construction.},
author = {Liu, Yao and Chen, Xuefei and Sui, Zhifang and Wang, Huili and Zhou, Yang},
doi = {10.1109/ICALIP.2008.4589992},
file = {:home/ankur218/master-thesis/thesis-references/04589992.pdf:pdf},
isbn = {9781424417230},
journal = {ICALIP 2008 - 2008 Int. Conf. Audio, Lang. Image Process. Proc.},
number = {2007},
pages = {50--55},
title = {{On automatic construction of based-NLP Chinese medicine ontology concept's description architacture}},
year = {2008}
}
@article{Tsarev2011,
abstract = {This paper presents a new generic text summarization method using Non-negative Matrix Factorization (NMF) to estimate sentence relevance. Proposed sentence relevance estimation is based on normalization of NMF topic space and further weighting of each topic using sentences representation in topic space. The proposed method shows better summarization quality and performance than state of the art methods on DUC 2002 standard dataset. In addition, we study how this method can improve the performance of supervised and unsupervised text classification tasks. In our experiments with Reuters-21578 and Classic4 benchmark datasets we apply developed text summarization method as a preprocessing step for further multi-label classification and clustering. As a result, the quality of classification and clustering has been significantly improved. {\textcopyright} 2011 IEEE.},
author = {Tsarev, Dmitry and Petrovskiy, Mikhail and Mashechkin, Igor},
doi = {10.1109/HIS.2011.6122102},
file = {:home/ankur218/master-thesis/thesis-references/06122102.pdf:pdf},
isbn = {9781457721502},
journal = {Proc. 2011 11th Int. Conf. Hybrid Intell. Syst. HIS 2011},
keywords = {clustering,generic text summarization,latent semantic analysis,multi-label classification,non-negative matrix factorization},
pages = {185--189},
title = {{Using NMF-based text summarization to improve supervised and unsupervised classification}},
year = {2011}
}
@article{Rehurek2010,
author = {Rehurek, Radim and Sojka, Petr},
file = {:home/ankur218/master-thesis/thesis-references/lrec2010{\_}final.pdf:pdf},
journal = {Lr. 2010 Work. New Challenges Nlp Fram.},
pages = {45--50},
title = {{Software framework for topic modelling with large corpora}},
year = {2010}
}
@article{Panichella2014a,
abstract = {Written communications recorded through channels such as mailing lists or issue trackers, but also code co-changes, have been used to identify emerging collaborations in software projects. Also, such data has been used to identify the relation between developers' roles in communication networks and source code changes, or to identify mentors aiding newcomers to evolve the software project. However, results of such analyses may be different depending on the communication channel being mined. This paper investigates how collaboration links vary and complement each other when they are identified through data from three different kinds of communication channels, i.e., mailing lists, issue trackers, and IRC chat logs. Also, the study investigates how such links overlap with links mined from code changes, and how the use of different sources would influence (i) the identification of project mentors, and (ii) the presence of a correlation between the social role of a developer and her changes. Results of a study conducted on seven open source projects indicate that the overlap of communication links between the various sources is relatively low, and that the application of networks obtained from different sources may lead to different results.},
author = {Panichella, Sebastiano and Bavota, Gabriele and {Di Penta}, Massimiliano and Canfora, Gerardo and Antoniol, Giuliano},
doi = {10.1109/ICSME.2014.47},
file = {:home/ankur218/master-thesis/thesis-references/How DevelopersтАЩ Collaborations Identified from Different Sources.pdf:pdf},
isbn = {9780769553030},
issn = {1063-6773},
journal = {Proc. - 30th Int. Conf. Softw. Maint. Evol. ICSME 2014},
keywords = {Developer Social Network,Developers,Empirical Study},
pages = {251--260},
title = {{How developers' collaborations identified from different sources tell us about code changes}},
year = {2014}
}
@article{Rui2016,
author = {Rui, Weikang and Liu, Jinwen and Jia, Yawei},
doi = {10.1109/ICBDA.2016.7509787},
file = {:home/ankur218/master-thesis/thesis-references/07509787.pdf:pdf},
isbn = {978-1-4673-9590-8},
journal = {2016 IEEE Int. Conf. Big Data Anal.},
keywords = {-feature selection,big data,clustering,embedding},
pages = {1--5},
title = {{Unsupervised feature selection for text classification via word embedding}},
url = {http://ieeexplore.ieee.org/document/7509787/},
year = {2016}
}
@article{Tong2001,
abstract = {Support vector machines have met with significant success in numerous real-world learning tasks. However, like most machine learning algorithms, they are generally applied using a randomly selected training set classified in advance. In many settings, we also have the option ofusing pool-based active learning. Instead ofusing a randomly selected training set, the learner has access to a pool ofunlabeled instances and can request the labels for some number of them. We introduce a new algorithm for performing active learning with support vector machines, i.e., an algorithm for choosing which instances to request next. We provide a theoretical motivation for the algorithm using the notion of a version space. We present experimental results showing that employing our active learning method can significantly reduce the need for labeled training instances in both the standard inductive and transductive settings},
author = {Tong, Simon and Koller, Daphne},
doi = {10.1162/153244302760185243},
file = {:home/ankur218/master-thesis/thesis-references/tong01a.pdf:pdf},
isbn = {1558607072},
issn = {15324435},
journal = {J. Mach. Learn. Res.},
keywords = {active learning,classifica-,relevance feedback,selective sampling,support vector machines,tion},
pages = {45--66},
pmid = {8804822},
title = {{Support Vector Machine Active Learning with Applications to Text Classification}},
year = {2001}
}
@book{Bruegge2009,
abstract = {For courses in Software Engineering, Software Development, or Object-Oriented Design and Analysis at the Junior/Senior or Graduate level. This text can also be utilized in short technical courses or short, intensive management courses. This textbook shows how to use both the principles of software engineering as well as the practices of various object-oriented tools, processes, and products. Using a step by step case study to illustrate the concepts and topics in each chapter, this book emphasizes practical experience: participants can apply the techniques learned in class by implementing a real-world software project.},
author = {Bruegge, Bernd and Dutoit, Allen H},
booktitle = {Import01},
file = {:home/ankur218/master-thesis/thesis-references/POO{\_}Software{\_}Engineering{\_}Using{\_}UML{\_}Patterns{\_}and{\_}Java{\_}3rd{\_}Edition.pdf:pdf},
isbn = {0130471100},
pages = {762},
title = {{Object-oriented software engineering : using UML, patterns and Java}},
url = {http://www.scis.nova.edu/{~}peslaka/mmis661fa11.docx},
year = {2009}
}
@article{Guzman2014,
abstract = {App users can submit feedback about downloaded apps by writing review comments and giving star ratings directly in the distribution platforms. Previous research has shown that this type of feedback contains important information for software evolution. However, in the case of the most popular apps, the amount of received feedback and its unstructured nature can produce difficulties in its analysis. We present an interactive user feedback visualization which displays app reviews from four different points of view: general, review based, feature based and topic-feature based. We conducted a study which visualized 2009 reviews from the Dropbox app available in the App Store. Participants considered the approach useful for software evolution tasks as they found it could aid developers and analysts get an overview of the most and least popular app features, and to prioritize their work. While using different strategies to find relevant information during the study, most participants came to the same conclusions regarding the user reviews and assigned tasks.},
author = {Guzman, Emitza and Bhuvanagiri, Padma and Bruegge, Bernd},
doi = {10.1109/VISSOFT.2014.33},
file = {:home/ankur218/master-thesis/thesis-references/FAVe{\_}Visualizing User Feedback for Software Evolution.pdf:pdf},
isbn = {9780769553054},
journal = {Proc. - 2nd IEEE Work. Conf. Softw. Vis. Viss. 2014},
pages = {167--171},
title = {{FAVe: Visualizing user feedback for software evolution}},
year = {2014}
}
@article{McCallum1998a,
abstract = {Recent approaches to text classification have used two different first-order probabilistic models for classification, both of which make the naive Bayes assumption. Some use a multi-variate Bernoulli model, that is, a Bayesian Network with no dependencies between words and binary word features (e.g. Larkey and Croft 1996; Koller and Sahami 1997). Others use a multinomial model, that is, a uni-gram language model with integer word counts (e.g. Lewis and Gale 1994; Mitchell 1997). This paper aims to clarify the confusion by describing the differences and details of these two models, and by empirically comparing their classification performance on five text corpora. We find that the multi-variate Bernoulli performs well with small vocabulary sizes, but that the multinomial performs usually performs even better at larger vocabulary sizes—providing on average a 27{\%} reduction in error over the multi-variate Bernoulli model at any vocabulary size. Introduction},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {McCallum, Andres and Nigam, Kamal},
doi = {10.1.1.46.1529},
eprint = {0-387-31073-8},
file = {:home/ankur218/master-thesis/thesis-references/multinomial-aaaiws98.pdf:pdf},
isbn = {0897915240},
issn = {0343-6993},
journal = {AAAI/ICML-98 Work. Learn. Text Categ.},
pages = {41--48},
pmid = {20236947},
title = {{A Comparison of Event Models for Naive Bayes Text Classification}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.65.9324{\&}rep=rep1{\&}type=pdf},
year = {1998}
}
@article{Rogers2012,
abstract = {The rationale for a software system captures the designers' and developers' intent behind the decisions made during its development. This information has many potential uses but is typically not captured explicitly. This paper describes an initial investigation into the use of text mining and parsing techniques for identifying rationale from existing documents. Initial results indicate that the use of linguistic features results in better precision but significantly lower recall than using text mining. 2012 IEEE.},
author = {Rogers, Benjamin and Gung, James and Qiao, Yechen and Burge, Janet E.},
doi = {10.1109/ICSE.2012.6227091},
file = {:home/ankur218/master-thesis/thesis-references/06227091.pdf:pdf},
isbn = {9781467310673},
issn = {02705257},
journal = {Proc. - Int. Conf. Softw. Eng.},
keywords = {rationale,text mining},
pages = {1313--1316},
title = {{Exploring techniques for rationale extraction from existing documents}},
year = {2012}
}
@article{Guzman2015,
author = {Guzman, Emitza},
file = {:home/ankur218/master-thesis/thesis-references/How Do Users Like This Feature.pdf:pdf},
title = {{Do Users Like This Feature? A Fine Grained Sentiment Analysis of App Reviews}},
year = {2015}
}
@article{Patwardhan2017,
author = {Patwardhan, Amol},
doi = {10.1109/CIC.2017.00014},
file = {:home/ankur218/master-thesis/thesis-references/08181475.pdf:pdf},
isbn = {978-1-5386-2565-1},
journal = {2017 IEEE 3rd Int. Conf. Collab. Internet Comput.},
keywords = {emotion,emotion aware software development,mining,process and,sentiment analysis,team collaboration},
pages = {20--26},
title = {{Sentiment Identification for Collaborative, Geographically Dispersed, Cross-Functional Software Development Teams}},
url = {http://ieeexplore.ieee.org/document/8181475/},
year = {2017}
}
@article{Joachims1998a,
abstract = {This paper explores the use of Support Vector Machines (SVMs) for learning text classifiers from examples. It analyzes the particular properties of learning with text data and identifies why SVMs are appropriate for this task. Empirical results support the theoretical findings. SVMs achieve substantial improvements over the currently best performing methods and behave robustly over a variety of different learning tasks. Furthermore they are fully automatic, eliminating the need for manual parameter tuning.},
author = {Joachims, Thorsten},
doi = {10.1007/BFb0026683},
file = {:home/ankur218/master-thesis/thesis-references/joachims{\_}98a.pdf:pdf},
isbn = {3540644172},
issn = {03436993},
journal = {Mach. Learn.},
number = {LS-8 Report 23},
pages = {137--142},
pmid = {9934216},
title = {{1 Introduction 2 Text Categorization 3 Support Vector Machines}},
url = {http://www.springerlink.com/index/drhq581108850171.pdf},
volume = {1398},
year = {1998}
}
@article{Abuleil2007,
author = {Abuleil, Saleem},
doi = {10.1109/ICTAI.2007.179},
file = {:home/ankur218/master-thesis/thesis-references/04410419.pdf:pdf},
isbn = {076953015X},
issn = {10823409},
journal = {Proc. - Int. Conf. Tools with Artif. Intell. ICTAI},
keywords = {and relationships between two,etc,or more},
pages = {440--443},
title = {{Using NLP techniques for tagging events in Arabic text}},
volume = {2},
year = {2007}
}