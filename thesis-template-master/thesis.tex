\documentclass[a4paper,12pt,twoside]{report}

\usepackage{acronym}
\usepackage{url}
\usepackage{cite}
\usepackage{listings}
\usepackage[pdftex]{graphicx}
\usepackage[hang,small,bf]{caption}
\usepackage{styles/tum}
\usepackage{setspace}
\usepackage[german,english]{babel}
\usepackage{float}
\usepackage{floatflt}
\usepackage{fancyhdr}
\usepackage{color}
\usepackage{booktabs}
\usepackage[pdftex,bookmarks=true,plainpages=false,pdfpagelabels=true]{hyperref}
\usepackage{mdwlist}
\usepackage{enumerate}
\usepackage{paralist}
\usepackage{array}
\usepackage{longtable}
\usepackage{listings}
\usepackage[utf8x]{inputenc}
\usepackage[capitalize, noabbrev]{cleveref}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{adjustbox}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage[table]{xcolor}
\usepackage{tabularx}
\usepackage{multirow}
\newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}} % linksbündig mit Breitenangabe
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}} % zentriert mit Breitenangabe
\newcolumntype{R}[1]{>{\raggedleft\arraybackslash}p{#1}} % rechtsbündig mit Breitenangabe

% Path for graphics
\graphicspath{{figures/}}

\begin{document}
\setlength{\evensidemargin}{22pt}
\setlength{\oddsidemargin}{22pt}


\def\doctype{Master's Thesis}
\def\faculty{Informatik}
\def\title{Mining Rationale from Issue Tracking Systems}		%TODO add title in German
\def\titleGer{Rekonstruktion von Begr{\"u}ndungsmodellen aus Aufgabenverwaltungssystemen}	%TODO add title in German
\def\supervisor{Prof. Bernd Brügge, Ph.D.}
\def\advisor{Rana Alkadhi, M.Sc.}
\def\author{Ankur Sinha}			%TODO add author name
\def\date{15.02.2018}		%TODO add submission / handover date


\hypersetup{pdfborder={0 0 0},
                        pdfauthor={<author>},
                        pdftitle={<title english>},
                        }

\lstset{showspaces=false, numbers=left, frame=single, basicstyle=\small}

\pagenumbering{alph}

\include{tex/cover}
\include{tex/titlepage}
\newpage
\thispagestyle{empty}
\mbox{}
\include{tex/disclaimer}

\newpage
\thispagestyle{empty}
\mbox{}

\chapter*{Acknowledgements}
To write.

\pagenumbering{roman}

\selectlanguage{english}
\begin{abstract}

%abstract english

Rationale knowledge is particularly important during software maintenance and evolution because it is valuable to understand the rationale behind the previous decisions. Rationale knowledge, in the context of software engineering, corresponds to the reasoning and logic behind the decisions taken during all phases of software development. Such decisive conversations are spread out across various mediums. Rationale may be discussed face-to-face or over other modes of communication such as chats, emails, or issue trackers to mention a few. It is thus important to extract and mine these messages that were exchanged over different modes of communication to recover rationale. Open source projects come with licenses that provides the rights to study, develop and also contribute to the same. Additionally, issue trackers for open source projects are available publicly. Therefore, this research focuses on mining rationale from the issue trackers of open source projects: Apache Lucene, Mozilla Thunderbird and Ubuntu. These rationale captured can help developers evaluate decisions, improve understandability, and document the pertinent information better.

\end{abstract}

\clearpage

\selectlanguage{german}
\begin{abstract}

%abstract german
Rationales Wissen ist besonders wichtig während der Softwarewartung und evolution, da es wertvoll ist, die Gründe hinter den vorherigen Entscheidungen zu verstehen. Rationales Wissen, im Kontext von Software-Engineering, entspricht der Argumentation und Logik hinter der Entscheidung in allen Phasen der Softwareentwicklung. Solche entscheidenden Gespräche sind auf verschiedene Medien verteilt. Begründungen können von Angesicht zu Angesicht oder über andere Arten der Kommunikation wie Chats, E-Mails oder Problem-Tracker diskutiert werden, um nur einige zu nennen. Es ist daher wichtig, diese Nachrichten, die über verschiedene Kommunikationsarten ausgetauscht wurden, zu extrahieren und abzubauen, um die Logik zu verwalten. Open-Source-Projekte werden mit Lizenzen geliefert, die das Recht zum Studium, zur Entwicklung und zum Beitrag dazu bieten. Daher konzentriert sich diese Forschung auf Bergbauprinzipien aus Open-Source-Projekten wie Apache Lucene, Mozilla Thunderbird und Ubuntu. Diese erfasste Begründung kann Entwicklern helfen, Entscheidungen zu analysieren, die Verständlichkeit zu verbessern und die relevanten Informationen besser zu dokumentieren.

\end{abstract}

\clearpage

\selectlanguage{english}


\tableofcontents
\clearpage

\clearpage

\begin{acronym}

\acro{MNB}{Multinomial Naive Bayes}
\acro{DT}{Decision Tree}
\acro{RF}{Random Forest}
\acro{LR}{Logistic Regression}
\acro{SVM}{Support Vector Machines}
\acro{HTML}{Hypertext Markup Language}
\acro{TXT}{Text}
\acro{SQL}{Structured Query Language}
\acro{NLP}{Natural Language Processing}
\acro{POS}{Parts-of-Speech}
\acro{SOLR}{Need to look up}
\acro{SGD}{Stochastic Gradient Descent}
\acro{GATE}{General Architecture for Text Engineering}
\acro{WEKA}{Waikato Environment for Knowledge Analysis}

\end{acronym}

\pagenumbering{arabic}

\fancyhead{}
\pagestyle{fancy}
\fancyhead[LE]{\slshape \leftmark}
\fancyhead[RO]{\slshape \rightmark}
\headheight=15pt


%------- chapter 1 -------

\chapter{Introduction}
Modern software development has resorted to agile methodologies in order to speed up delivery to clients and customers. Being iterative in nature, software development has its task cut out for decision making during different phases such as requirement analysis, system design, implementation, testing and maintenance, for improvement. Decision making is done through discussions between different members of the team. The problems or issues that are in the forefront usually cannot be solved algorithmically. They belong to a class of special problems known as the wicked problems \cite{Rittel1973}. In addition to discussing the issues, proposals are suggested to solve them and arguments are given in favor of or against the given proposal before making the final decision. In other words, the reasoning behind the proposals, arguments and decisions are also known as rationale. 
\bigbreak
Due to fast paced development nature of the software industry, importance has inclined more toward development than logging the reasoning behind the decisions taken. Capturing, documentaining and maintaining rationale can significantly avert major risks in future and thus aid better evolution and maintenance \cite{Bruegge2009} \cite{Dutoit2006}. In addition, it helps understand the logic and reasoning behind certain decisions and therefore save time by adopting the necessary while ignoring the rejected proposals. Rationale may be discussed face-to-face or over other software development artifacts such as chat messages, IRC messages and issue trackers \cite{Lata2016} \cite{Nonnenmacher2017} \cite{Panichella2014}.  
\bigbreak
In this thesis, the focus lies on extracting rationale out of developers' comments from issue tracking systems of three Open Source Software (OSS) projects: Apache Lucene, Mozilla Thunderbird and Ubuntu. An exploratory study is conducted using the datasets of the aforementioned OSS projects using which analysis is done on the rationale frequency observed and investigate capturing rationale automatically using machine learning techniques. 

\section{Problem Statement}
Extracting rationale from software development artifacts is imperative in order to comprehend the reasoning behind why certain proposals were made, why they were advocated or criticised, and lastly, how the members of the team took a decision based on a gamut of criteria in consideration. With requests for changes coming in at a very fast pace for developers, capturing rationale can be a vital cog in the wheel of software development. Teams and organizations undergo changes as well and hence, the rationale documented can be of great use to someone who is beginning their stint with the team. This helps them to peruse and cogitate on why certain things the way they are and save crucial time to know which paths to explore and which to avoid. It can thus be imagined that not capturing the rationale may lead to reinventing the wheel, which is completely uncalled for and waste of time, had the rationale been documented \cite{Bruegge2009}. In the past, however, developers have not paid much heed to capture and document rationale. The reason behind this can be attributed to limited time and additional efforts \cite{Dutoit2006}. OSS projects are usually led in a different way compared to its commercial counterparts \cite{mockus2002two}. While companies of great stature do lend their support to OSS projects, volunteers from, and sometimes across, different parts of the world are at helm in driving the development. These volunteers themselves choose what they want to work on compared to industrial settings where usually one is assigned a task by their superiors. In addition, they lack system level designs and hence, a concrete deliverable. These could be thought of some of the prime reasons as to why not much attention has been given to documenting rationale. However, due to the level of passion from the developers in taking up tasks of their interest, OSS projects have managed to maintain very high quality. A great example of this would be Linux when compared to its commercial counterparts such as Windows or Macintosh \cite{mockus2002two}. Although messages from software development artifacts are logged and rationale can be found in them, this can be quite a tedious task due to many reasons. Firstly, one has to go through too many messages, many of which can be completely irrelevant or insignificant. Secondly, finding proper correlation and link between different comments with many irrelevant ones occurring in between can make one lose track of things. This task of extracting rationale and documenting them in a clear and concise manner can be a cumbersome task even for human beings, especially due to the fact that some artifacts may have many messages on a given day, let alone over a period of many years. This thesis thus tries to address the aforementioned problem of capturing and documenting rationale from issue tracking systems using machine learning algorithms for text classification.

\section{Objective}
Of the many software development artifacts, issue tracking systems are one of the potential sources for capturing rationale. Unlike other channels such as chat messages or emails, issue tracking systems specifically concentrate exclusively on development of the pertinent project. In the past, there has been research on extracting emotions of developers from issue tracking systems \cite{Marshall2016} \cite{Robillard2017}. Additionally, studies have also been conducted on classification of reports from issue tracking systems \cite{Fan2017}. This thesis explores the possibilities of finding rationale and classify them automatically from issue tracking systems of three OSS projects, namely, Apache Lucene, Mozilla Thunderbird and Ubuntu. In addition, this thesis also tries to extend the work of Nonnenmacher \cite{Nonnenmacher2017} by trying to find links between messages from IRC channel and issue tracking systems of the projects mentioned earlier. The Research Hypotheses (RH) are thus formulated as follows.

\begin{itemize}
\item[\textbf{RH1}] \textit{Messages from ITS of OSS projects contain rationale.} The frequency with which rationale appears in messages from ITS is an important factor to consider them as a useful source of rationale.   
\item[\textbf{RH2}] \textit{Rationale can be captured automatically from ITS.} Machine learning algorithms are capable of automatically extract if a given message contains rationale or not, which in other words is binary classification. Additionally, these algorithms can also perform fine-grained classification on those messages that are considered to contain rationale elements such as issues, alternatives, pro-arguments, con-arguments and decisions; in other words, multi-label classification. 
\item[\textbf{RH3}] \textit{Mutual issues exist in IRC and ITS.} There exists certain issues that are possibly discussed in both, IRC channel as well as ITS. These issues could therefore be linked together to know more about the rationale behind them.    
\end{itemize}

\section{Methodology}
This thesis is divided into three main phases: data collection, content analysis and automatic classification, all of which are sequential and the output of one phase serves as input of the next phase. In the first phase, to collect data, all the suitable OSS projects whose data is publicly available are considered. Later, datasets which are already provided by the website as a dump are downloaded. Those projects whose websites do not provide any dataset readily have been scraped. In both the instances of readily available dump or scraped data, the necessary contents were parsed and finally stored in a common structured format in the database. Random Stratified Sampling was applied at the data stored and all the messages were also decomposed into individual sentences. The final dataset thus consisted of 8,310 sentences from 300 issues of all three projects; these were also the input for the content analysis phase. 
\bigbreak
In the content analysis phase, two annotators, the author and the advisor, considered the dataset obtained in the previous phase mentioned in paragraph earlier. They had to label all the messages whether they contained rationale or not, and if they did contain, the annotators had to further specify the element present in the rationale such as issue, alternative, pro-argument, con-argument and decision. In order to perform this step, Neuendorf's \cite{Neuendorf2017a} content analysis technique was followed. First, a labeling guide, mentioned in detail in Appendix A, was prepared. This labeling guide provided understanding to both the annotators to reducde th disagreements significantly since they would now know which one to label as what. Second, disagreements, if any, were sorted out between the annotators. Finally, the results of this stage served as ground truth training set for the automatic classification phase.  
\bigbreak
In the final phase of automatic classification, the ground truth obtained from the previous phase was used for training the various machine learning algorithms. Before running the classifier models, numerous data preprocessing methods such as bag-of-words, n-gram tokenization and parts-of-speech tagging were applied. The dataset was divided into training set and testing set by the virtue of performing k-fold cross validation to test the accuracy of the model and retrieve the best performing ones. The classifier models were capable of performing both kinds of classification, binary as well as fine-grained classification. The results were later studied and insights were gained to validate the research hypotheses formulated earlier.

\section{Outline}


%------- chapter 2 -------
\chapter{Foundation}

\section{Rationale Management}

During different stages such as planning, designing, developing, testing and maintenance, individuals responsible come together to tackle any particular issue. Such a discussion includes the numerous ways in which the problem can be solved. A problem, however, cannot be solved just by proposing a possible solution. Different team members come together to show their support or go against it by pointing the demerits of a suggested implementation. Finally, they come together towards a mutual conclusion and decide to go ahead with a particular suggestion. Rationale can thus be defined as the logical reasoning behind a particular act or statement. In the context of software engineering, rationale is the reasoning behind the decision taken with respect to some task in hand during various phases of software development \cite{Dutoit2006} \cite{Bruegge2009}. 
\bigbreak
Conversations between developers can take place in person or across digital medium. Digital medium may include emails, chat messengers and issue trackers to name a few. While discussions taking place in person cannot be captured, technological advancements have made it possible to extract rationale from the aforementioned digital media. Capturing these vital information from different artifcats and managing these rationale can therefore be of great benefit for other developers. This helps them in a way such that one does not have to go through the entire conversation history which would include a lot of irrelevant, petty, or off-topic comments; concentrating and focusing only on the pertinent messages can be made possible through rationale management. 
\bigbreak
The problems or issues to be tackled, more often than not, do not have path towards a solution or a concrete end point. Such problems are popularly described as wicked problems. With respect to computer science, wicked problems do not have any concrete algorithm or predefined point to solve a problem. Wicked problems were studied by Professor Horst Rittel and Webber \cite{Rittel1973} from the Architecture Department at the University of California, Berkely. They described such problems as those which are not formulated properly. In addition, he stated that such problems are solved by multiple decision makers. This is very synonymous to the fact that, in software engineering, such a situation has become a commonplace. West Churchman \cite{InstituteofManagementSciences.1967} of the same university mentioned in a couple of sentences earlier, in the guest editorial of a publication, echoing similar views. In the year 2014, Marcelo et al. \cite{Machado2014}, proposed the Massive Open Online Research, which is claimed to be a framework to deal with wicked problems. 
\bigbreak
Taking a leaf out of the works of Bruegge and Dutoit\cite{Bruegge2009}, five types of rationale elements are taken into consideration for this research. They are: issues, alternatives, pro-arguments, con-arguments and decision.
 
\subsubsection{Issues}
Issues are tasks that need to be solved. They can be a new feature, a major or minor bug, or a problem that could have stemmed out of an existing implementation. Issues can also be termed as wicked problems \cite{Rittel1973} since they may neither have any predefined path to reach the goal nor a proper end point to the goal itself. Some examples of issues from the data obtained are, \textit{"How do I go about limiting the search window as well as the number of matches?"} and \textit{"It does seem odd that all failures we've seen have been for very complex polygons".}  

\subsubsection{Alternatives}
Alternatives are the possible solutions to solve the issue in hand. Developers come up with different strategies to solve the issue. However, there are cases when an individual or a group of indviduals may not come up with a concrete solution. In such a scenario, temporary fixes are suggested by members of the group. Statements like, \textit{"I made a change just to see what would happen and x-sender started changing"} and \textit{"I found the way to remove a news server account" are some examples of alternatives.}

\subsubsection{Pro-arguments}
Pro-arguments are made to lend support to a particular alternative or decision. Additionally, they may also state extra advantages and merits as to why a particular approach must be taken. From the dataset, examples such as, \textit{"It is well possible that that will work"} and \textit{"From how I read the code, it does reject them, so it should work"}, for pro-arguments were encountered. 

\subsubsection{Con-arguments}
Con-arguments are the opposite of pro-arguments. They refute claims and also state the disadvantages or demerits of choosing a particular solution. Examples of con-arguments from the dataset includes, \textit{"One principle problem is that it's duplicated functionality for no good reason"} and \textit{"This is inconsistent and unneccesarily difficult to use".}

\subsubsection{Decisions}
Decisions are final conclusions made by the team members to solve an issue. While decisions can be made by alternatives suggested, they can also be made directly. Alternatively, decisions can also be made by without discussing or dismissing an issue. \textit{"This bug was fixed in the package snapcraft - 2.8.8+16.10"} and \textit{"Though Banshee won't be in 12.04 anymore, this is still a valid papercut"} are a couple of examples of decision from the dataset used in this thesis.


\section{Related Work}

In this section, we look at all the works relevant to this thesis done by others. 

\subsection{Mining Sentiments from Development Artifacts}
In the past, research has been carried out to retrieve different kinds of elements from issue tracking systems. Ortu et al.\cite{Ortu2017} published their work on extracting emotions and sentiments of developers from JIRA issue trackers of four different open source projects.  Sentiments such as love, joy, surprise, anger, sadness and fear were mined from 2,000 issue comments spanning 4,000 sentences from the JIRA issue tracking system of open source communities namely, Apache, Spring, CodeHaus and JBoss. This was a smaller version of a project where Ortu et. al.\cite{Ortu2015} carried out similar research with a dataset that spanned 700,000 reports of issues and 2 million comments. In another work of Murgia et al.\cite{Murgia2014}, it has been concluded that being polite helped in fixing the issue in lesser amount of time. 
\bigbreak
Marshall et al.\cite{Marshall2016} demonstrated the outcomes of emotions from the forum posts of agile teams. Their dataset contained more than 1,300 forum posts from five teams. The posts from the forums were classified into unemotional, positive, negative and neutral. It was discovered that members of the team showing less emotions performed better than others. In addition, such individuals were evaluated more positively by their cohorts. 
\bigbreak
A study was conducted by Souza and Silva \cite{Souza2017} where they performed sentiment analysis on Travis Continuous Integration builds. They carried out empirical assessment of 1,262 projects hosted on GitHub having more than 609,000 builds using Travis CI. It was found out that negative sentiments from developers leads to build breakage in continuous integration processes, although the influence is small. 
\bigbreak
Sentiments about software development can also be mined from social media. One such research was conducted by Guzman et al.\cite{Guzman2017} where they extracted more than 10 million tweets of 30 different mobile and desktop software applications from Twitter. Their study demonstrated the type of content present in tweets with respect to the concerned software application. The tweets were categorized into 25 groups; some of which are praises, complaints, service, shortcomings and others, from general public. In addition to manual content analysis, supervised machine learning techniques were used to classify the tweets into different categories. 

\subsection{Automatic Classification of Rationale Elements}
Like mining and classifying sentiments, rationale elements were also extracted in some works. Kurtanovic et al.\cite{Kurtanovic2017} conducted research similar to that of Guzman et al.\cite{Guzman2017} mentioned in the previous section. They performed manual content analysis and automatic classification of rationale from more than 52,000 user reviews of 52 software applications from the Amazon Store. Reviews and its pertinent sentences were classified using SVM, MNB and LR into the following: issue, alternative, criteria, decision and justification.  
\bigbreak
Fan et al.\cite{Fan2017} performed a study on a dataset obtained from GitHub spanning 80 projects and more than 252,000 issue reports. The goal was to classify them into bug or non-bug related sentences by running algorithms such as SVM, LR, MNB and RF using a two-fold approach. The first step included the computing probability to find out whether a sentence was bug-prone related or not. This was later used as an input in the second step coupled with other factors such as characteristics of the person who made the comment, their contributions, and others, to finally classify the sentence as bug-prone or not. 
\bigbreak
Rogers et al.\cite{Rogers2014} carried out manual and automatic classification of rationale on 200 Chrome bug reports using GATE and WEKA. Rogers et al.\cite{Rogers2012} also exclusively studied parsin and annotating techniques to extract rationale. While the binary classification was conducted to see if a sentence contained rationale or not, fine-grained classification was also performed to check if a sentence had the following kinds of rationale: requirements, decisions, alternatives, arguments, assumptions, questions, answers, and procedures. The automatic extraction of rationale elements was carried out using machine learning techniques such as SGD, RF and MNB. 
\bigbreak
Synonymous to the classification mentioned earlier, Alkadhi et al.\cite{Alkadhi2017} performed classification of rationale elements where the dataset included more than 8,700 chat messages from 3 software development teams. Apart from the binary classification of extracting if there was any rationale in a sentence or not, fine-grained classification was also performed to extract issues, alternatives, pro-arguments, con-arguments and decisions using MNB and SVM machine learning algorithms. 
\bigbreak
Bachelli et al.\cite{Bacchelli2012} used a dataset of around 1,500 emails from mailing lists. They then tried to classify the contents of the emails into 5 categories. The categories into which they were classified automatically were natural language, junk, patch, stack trace and source code, using MNB classifier. 

%\subsection{Generating Categories using Topic Modeling}
%In the past, research has been carried out to generate categories using Topic Modeling techniques such as LDA. 

\section{Natural Language Processing}

Natural Language Processing (NLP) is a popular branch of computer science to extract meaningful features from natural language texts that are comprehensible to humans \cite{Al-ghamdi2017} \cite{Suhaimin2017}. Categorization and classification of natural language texts can also be done using NLP based algorithms. In the past, NLP has been used for various purposes in numerous domains. Malware detection studies has been conducted using NLP based approaches by Karbab et al. \cite{Karbab2017} and Tran et al.\cite{Tran2017}. Sentiment classification of twitter texts and hotel reviews were carried out by Kanakaraj et al.\cite{Kanakaraj2015} and Ghorpade et al.\cite{Ghorpade2012} respectively. The branch of NLP and its algorithms have grown astoundingly and are being implemented in many languages such as Persian\cite{Ri}, Arabic\cite{Abuleil2007}, Chinese\cite{Liu2008}, German\cite{Metzmacher2017} and Italian\cite{Damiano2017}. 
\bigbreak
In addition, some methodologies under NLP can also be used for data preprocessing while performing machine learning tasks. Some of the most popular methods and techniques from NLP and their pertinent works are discussed below. 

\subsection{Preprocessing Steps}
The following section explores different preprocessing steps that can be applied for text classification. 

\subsubsection{Stopwords Removal}
A sentence usually is comprised of different parts-of-speech. However, there may be some words that are very common across all sentences and thereby does not contribute to learning about specific features or keywords. In such a scenario, researchers deploy stopword removal mechanism to filter out words that are of less or no interest to them. An exhaustive list of stopwords has been published by the Information Retrieval Group, School of Computing, University of Glasgow\footnote{\url{http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words}}. In addition, one can also create their own stopwords list if specific information or keywords are being looked for or to be omitted. 
\bigbreak
Given a sentence: \textit{Munich is a really beautiful city with a cosmopolitan crowd.} 
\bigbreak
After applying stopwords removal, the sentence would then look like: \textit{Munich really beautiful city cosmopolitan crowd.} 
\bigbreak
Rogers et al.\cite{Rogers2012} carried out an experiment to identify rationale from documents using linguistic features such as stopwords removal to conclude that it resulted in better precision but lower recall. Kurtanovic et al.\cite{Kurtanovic2017} also performed stopwords removal in their data preprocessing step while retrieving rationale from software reviews. Guzman et al.\cite{Guzman2017}\cite{Guzman2017a}\cite{Guzman2016}\cite{Guzman2014} used stopwords removal in many of their works extensively.

\subsubsection{Punctuations Removal}
Similar to words, punctuations are different parts of speech that can be removed from text after which the filtered data can be fed to the classifier. Some commonly witnessed punctuations include fullstop (.), comma (,), colon (:), semi-colon (;) amongst others. 
\bigbreak
Given a sentence: \textit{Munich has many kinds of people living here such as: Indians, Chinese, Americans.}
\bigbreak
After applying punctuations removal, the sentence would then look like: \textit{Munich has many kinds of people living here such as Indians Chinese Americans}
\bigbreak
Like stopwords removal, Kurtanovic et al.\cite{Kurtanovic2017} also performed punctuation removal as well for retrieving rationale from software reviews. However, Bacchelli et al.\cite{Bacchelli2012} and Guzman\cite{Guzman2015} used the emphasis of punctuations for their research. 

\subsubsection{Stemming}
Stemming is a popular preprocessing technique of mapping similar words with different variations to one single word by truncation. One of the most popular stemmers out there in the field of research is the Porter Stemmer \cite{Porter}. Manning et al.\cite{Manning2009} state that stemming increases recall but harms precision. An example of stemming would be that words like \textit{operational, operative, operations} would all get mapped to \textit{operate}. However, there are cases were words also get mapped to a single word which may not have an exact dictionary meaning. An example of such a case can be \textit{calculation, calculative} getting mapped to \textit{calculat} instead of \textit{calculate}\cite{Toman2006}. Stemming has been used as a preprocessing step in the works of Fan et al.\cite{Fan2017}, Murgia et al.\cite{Murgia2016} and Panichela et al.\cite{Panichella2014a} to mention a few.

\subsubsection{Lemmatization}
Another preprocessing technique, but rather a better replacement of stemming, is lemmatization. In this technique, words of different variations are not truncated but rather are mapped to a root word. This root word is identical to a word found in the dictionary. Toman et al.\cite{Toman2006} state that lemmatization is a difficult and expensive process but is more beneficial. An example of lemmatization would be that words like \textit{is} and \textit{are} would be mapped to \textit{be}, which is an actual word found in the dictionary. Lemmatization has been performed by Guzman et al.\cite{Guzman2014}, Toman et al. \cite{Toman2006} and Kurtanovic et al.\cite{Kurtanovic2017} as part of preprocessing technique in their research. 

\subsubsection{Bag-of-Words}
Given a corpus of \textit{N} documents, each document may contain many words. A Bag-of-Words (BoW) can thus be formed by counting the frequency of every unique word occuring across N documents. However, to form a vocabulary pertaining to the text dataset, techniques such as stopwords removal, punctuations removal, stemming and lemmatization, can be applied to prune on commonly occuring words and different variations of the same word. An example would be as follows.
\bigbreak
Sentence 1: \textit{I went to Munich.}
\bigbreak
Sentence 2: \textit{Munich is a very beautiful place compared to Berlin.}
\bigbreak
Sentence 3: \textit{Berlin has more startups than Munich}
\bigbreak
Applying the preprocessing techniques such as stopwords removal, punctuations removal, stemming and lemmatization, the BoW would look like as in \ref{tab:bowExample}. Nonnenmacher\cite{Nonnenmacher2017} and Goel \cite{Goel2017}, both, have used BoW model for their research on extraction of rationale and topic modeling using LDA, respectively. Additionally, Somasundaram et al. \cite{Somasundaram2012} took advantage of the same for performing categorization of bug reports.
\begin{table} %[hb!]
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \def\arraystretch{1} % 1 is the default, change whatever you need (line spacing)
    \begin{tabular}{p{2cm} p{2cm}}
        \toprule
        \textbf{Word} & \textbf{Count}\\
        \midrule
			Munich & 3 \\
			Berlin & 2 \\ 
			beautiful & 1 \\ 
			compared & 1 \\ 
			startups & 1 \\
			place & 1 \\ 
        \midrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Example for Bag-of-Words Model}
    \label{tab:bowExample}
\end{table}

\subsubsection{N-Gram Tokenization}
Bag-of-words takes one word at a time and counts them. However, n-gram tokenization is a method were multiple words appearing continuously can be grouped as one term. This approach helps in extracting better meaning if multiple words occuring together make better sense than their individual counterparts. These terms of n-grams or n-tokens grouped together can then be used as a feature while running the classifier. 
\bigbreak
Here is an example sentence: \textit{Linux is a robust operating system}
\bigbreak
It can be seen clearly from Table \ref{tab:ngramExample} that the results of 2-gram or 3-gram tokenization add more value in terms of using it as features when compared to 1-gram tokenization. Alkadhi et al.\cite{Alkadhi2017} used n-gram tokenization for their research on extraction of rationale from chat messages. The minimum value of \textit{n} was 1 whereas the maximum value was 3 in order to conduct the study. 
\begin{table} %[hb!]
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \def\arraystretch{1} % 1 is the default, change whatever you need (line spacing)
    \begin{tabular}{p{4cm} p{10cm}}
        \toprule
        \textbf{N-Gram} & \textbf{Result}\\
        \midrule
			1-gram (unigram) & Linux, is, a, robust, operating, system \\
			2-gram (bigram) & Linux is, is a, a robust, robust operating, operating system \\ 
			3-gram (trigram) & Linux is a, is a robust, a robust operating, robust operating system \\
        \midrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Example for N-Gram Tokenization}
    \label{tab:ngramExample}
\end{table}


\subsubsection{Term Frequency - Inverse Document Frequency}

Term Frequency - Inverse Document Frequency (TFIDF) is the product of two values, term frequency and inverse document frequency\footnote{\url{http://www.tfidf.com/}}. Term Frequency (TF) can be defined as the number of times a given term occurs in a document. Inverse Document Frequency (IDF), on the other hand, checks for strength of frequency of a given word. 
\bigbreak
Consider the following documents to form a Document Term Matrix\footnote{\url{https://janav.wordpress.com/2013/10/27/tf-idf-and-cosine-similarity/}}.  A Document Term Matrix (DTM) converts the corpus of documents into a matrix of documents and the count of indivual words occuring in each of the document. 
\bigbreak
Document 1: \textit{I learn machine} 
\bigbreak
Document 2: \textit{You learn machine} 
\bigbreak
Document 3: \textit{Learning and loving machine learning}
\bigbreak
A simple example of DTM is illustrated using Table \ref{tab:dtmExample}. 
\begin{table} %[hb!]
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \def\arraystretch{1} % 1 is the default, change whatever you need (line spacing)
    \begin{tabular}{p{3cm} p{2cm} p{2cm} p{2cm} p{2cm} p{2cm} p{2cm} p{2cm}}
        \toprule
        \textbf{Document} & \textbf{i} & \textbf{learn} & \textbf{machine} & \textbf{learning} & \textbf{you} & \textbf{and} & \textbf{loving}\\
        \midrule
			Document 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0\\
			Document 2 & 0 & 1 & 1 & 0 & 1 & 0 & 0 \\ 
			Document 3 & 0 & 0 & 1 & 2 & 0 & 1 & 1 \\
        \midrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Example for Document Term Matrix}
    \label{tab:dtmExample}
\end{table}
\bigbreak
Given a set of documents, \textit{D}, \textit{$t_x$} is the term in the document, \textit{$d_i$}, for which TFIDF is to be computed, \textit{$t_n$} is the total number of words occuring in document, \textit{$d_i$}.
\bigbreak
The formula for TF is as follows:
\begin{equation}
\label{eq:et}
    TF(t, d_i) = \frac{t_x}{t_n}
\end{equation}
And, the formula for IDF is as follows:
\begin{equation}
\label{eq:et}
    IDF(t, D) = log\frac{N}{|\{d \in D : t \in D\}|}
\end{equation}
From equations 2.1 and 2.2, TFIDF is therefore:
\begin{equation}
\label{eq:et}
    TFIDF(t, d, D) = tf(t, d).idf(t, D)
\end{equation}
Using equations 2.1, 2.2 and 2.3, TFIDF of the term  \textit{"learning"} occuring in document 3, $d_3$, can now be computed. It can be seen that the word \textit{"learning"} occurs twice across the documents, hence from equation 2.1:
\begin{equation}
\label{eq:et}
    TF(learning, d_3) = \frac{2}{5} = 0.4
\end{equation}
The IDF for the word \textit{"learning"} from 2.2, is therefore:
\begin{equation}
\label{eq:et}
    IDF(learning, D) = log(\frac{2}{1}) = 0.301
\end{equation}
The TFIDF using equations 2.4 and 2.5 is thus:
\begin{equation}
\label{eq:et}
    TFIDF(learning, d_3, D) = 0.4\times0.301 = 0.12
\end{equation}
\bigbreak
Guzman et al.\cite{Guzman2017}, Fan et al.\cite{Fan2017}, Nonnenmacher\cite{Nonnenmacher2017} and Goel \cite{Goel2017} are some of the few who have extensively used TFIDF mechanism in their works.  
\subsection{Topic Modeling}
Topic modeling is an approach in the domain of NLP to extract a specific number of topics from a large text corpus. The topics are retrieved by computing the probabilities of frequently occurring words that constitute the text corpus \cite{Zou2017} \cite{Linstead2007}. Preprocessing techniques mentioned earlier can be applied before generating all the topics depending on the insights being looked for to make the final results more meaningful. It is to be noted that the name of the topics are not given by the algorithm but the end users themselves; the algorithm will only give the frequently occurred words for every given topic \cite{Goel2017}.
\bigbreak
Mathematically, topic modeling is a kind of a Bayesian inference model where every document in the text corpus is associated with a probability distribution over topics and these topics are nothing but probability distribution over words \cite{Goel2017}. Many topic modeling algorithms exists such as Latent Semantic Analysis (LSA) \cite{Agung2017}\cite{Tu2017}, Latent Dirichlet Allocation (LDA) \cite{Katsumata2016} \cite{Chen2016}, and Hierarchial Dirichlet Process (HDP) \cite{Li2018} \cite{Hu2017} to mention a few. This thesis performs topic modeling using LDA since many related works have incorporated the same. Some of these works are mentioned in the paragraphs to come. 
\bigbreak
Guzman at al. \cite{Guzman2015} \cite{Guzman2014} used topic modeling approach such as LDA to visualize user feedback and fine grained sentiment analysis of app reviews. For automatic classification of bug reports, Somasundaram et al. \cite{Somasundaram2012} used LDA to achieve the same. Pagano and Maalej\cite{Pagano2011} studied the blogging style of developers by applying topic modeling using LDA. 
% Write it as pseudocode if possible
\subsubsection{Latent Dirichlet Allocation}
Latent Dirichilet Allocation (LDA) is a topic modeling algorithm introduced by Blei at al. \cite{Blei2003}, where topics are formed using a generative process. The algorithm ha been adapted from Goel \cite{Goel2017} and is described as follows.
\bigbreak
1. Let w be number of words in the document, D; M be the number of documents in the corpora; k be the number of topics that can be comprised of. 
\bigbreak
2. Dirichlet distribution with parameter vector alpha of length k is chosen for k different topic distributions and parameter vector beta of length M is chosen for M documents in the corpora.
\bigbreak
3. Repeat until M documents, for a given document D belonging to corpora:
\bigbreak
(a) Sample a multinomial distribution of topics from the dirichlet distribution with parameter vector alpha chosen earlier and for each topic
\bigbreak
(b) Sample a multinomial distribution of words in that topic from the dirichlet distribution with parameter vector beta chosen earlier.
\bigbreak
(b) Repeat until n words, for a given word w in the document:
\bigbreak
i. Pick one topic from the multinomial topic distribution sampled above and then generate word from the multinomial word distribution of the chosen topic 
\bigbreak
ii. Add that word to the document.

\subsection{Parts-of-Speech Tagging}
Parts-of-Speech tagging, also known as PoS tagging, is a NLP technique where a sentence is broken into individual components and the PoS for each of those components are assigned \cite{Jurafsky2017}. A sentence may contain words as well as punctuations. PoS tagging technique can also be used as a preprocessing technique for classification where features would be extracted based on the pattern and types of PoS used in every sentence. It is to be noted that this tagging can be coarse grained such as noun, verb, adjective, and others, or even fine grained where the tagging could be something like comparative adjective or superlative adjective, personal pronoun, past tense or past participle. This thesis uses the Penn Treebank Project from the University of Pennsylvania\footnote{\url{https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html}} used by Spacy\footnote{\url{https://spacy.io/usage/linguistic-features}} library for its PoS tagging related experiments.
\bigbreak
Kurtanovic and Maalej \cite{Kurtanovic2017} used PoS tagging techniques in their quest to mine rationale from software reviews. Guzman et al.\cite{Guzman2015} took advantage of the same to perform fine grained sentiment analysis of app reviews. To perform sentiment analysis on twitter data, PoS tagging was used as a preprocessing step by Kanakaraj and Guddeti \cite{Kanakaraj2015}.

%\subsection{Named Entity Recognition}
%Named Entity Recognition (NER) is a technique to extract information from textual content. Unlike PoS which gives %information about each and every word, NER extracts specific information from text such as name, organization, location, %time and monetary values. NER can thus be helpful for retrieving specific entities to give fine grained insights about %each comment.
%\bigbreak
%An example of NER would be as follows:
%\bigbreak
%Brad will leave Munich after 10 PM. 
%\bigbreak
%Brad - Name
%\bigbreak
%Munich - Location
%\bigbreak
%10 PM - Time
%\bigbreak
%Note: List out all the works for NER

\section{Machine Learning}
Machine learning is a term coined by Arthur Samuel in the year 1959 \cite{Samuel1959a} while working at IBM. He states that it is the domain of computer science where computers learn without being explicitly programmed. Mannila \cite{Mannila1996a} expressed opinion on the fact that machine learning tries to work with concepts that is beyond the ability of human beings to see and work. In the upcoming sections, machine learning techniques, pipeline, transformation methods, algorithms and performance metrics are discussed. 

\subsection{Techniques}

\subsubsection{Supervised Learning}
Supervised learning is a technique where the algorithm learns from a given set of examples. Given a dataset with many entries, the algorithm gets hold of both, all the inputs and the pertinent output \cite{Singh2016}\cite{Caruana2006}. This helps the classifier to come up with patterns to map the given set of inputs to the output. Supervised learning, thus, can classify if a sentence contains rationale or not based on certain inputs and its features. This technique would however require sufficient amount of data to learn or train and hence improve the performance of the classifier. Some of the popular supervised learning algorithms\footnote{\url{https://www.kdnuggets.com/2016/08/10-algorithms-machine-learning-engineers.html}},\footnote{\url{http://www.dataschool.io/comparing-supervised-learning-algorithms/}} are Logistic Regression, Multinomial Naive Bayes, Decision Trees, Support Vector Machines and Random Forest, all of which have been used in this thesis. Patwardhan \cite{Patwardhan2017}, Kurtanovic and Maleej \cite{Kurtanovic2017}, and Guzman et al.\cite{Guzman2016}, have all opted for supervised learning techniques in their research works.

\subsubsection{Unsupervised Learning}  
Contrary to supervised learning, unsupervised learning technique has no labeled outputs for the given set of inputs. The unsupervised learning algorithm applied has to come up with patterns and relations from the data supplied \cite{Ball2011}\cite{Rojas1996}. The discovered patterns thus help in categorizing or clustering the data which can be studied by researchers later for better understanding of what constitutes the data. Clustering algorithms such as K-Means and Apriori are popular clustering algorithms\footnote{\url{https://machinelearningmastery.com/supervised-and-unsupervised-machine-learning-algorithms/}},\footnote{\url{https://www.dezyre.com/article/top-10-machine-learning-algorithms/202}} that belong to the class of unsupervised learning techniques. Rui et al.\cite{Rui2016} and Tsarev et al. \cite{Tsarev2011} have incorporated unsupervised learning techniques to perform text classifications in their research. 

\subsubsection{Reinforcement Learning} 
There exists another technique, which neither completely relies on output like supervised learning nor is completely like the approach of unsupervised learning, known as reinforcement learning. In reinforcement learning, the machine or agent tries to learn the behavior of something specific from a given environment based on feedback or reward. The goal of the algorithm is to maximize the reward. These behaviors, depending on the nature of the problem, can be learnt all at once or can be adaptive in nature. Littman and Moore \cite{Littman1996} published work on the ground principles of reinforcement learning. 

\subsection{Pipeline}

\subsubsection{Training} 
For an algorithm to make predictions, it must first learn and train itself using some data. A part of the overall dataset, known as training dataset, is thus used for training the algorithm by working with some parameters. It is to be noted that more the quality and quantity of the training dataset, better the training\footnote{\url{http://www.holehouse.org/mlclass/11_Machine_Learning_System_Design.html}}. In other words, there must be enough examples from the different classes in good proportion for the algorithm to learn.  If the dataset is highly imbalanced or skewed, balancing techniques can be applied\footnote{\url{https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/}}. In the case of text classification, the training data can be a group of sentences with some preprocessing steps mentioned in Section 2.3.1 along with the concerned output. The output can be something like, whether the sentence contains rationale or not, or whether the sentence has a positive tone or not, to mention a few.

\subsubsection{Testing} 
After having trained the data on a bulk portion of the entire dataset, the model must be tested by running the classifier on the minor portion of the dataset known as the test dataset. The metrics from the test dataset are the ones taken into account when evaluating the performance of the classifier. The metrics are explained in Section 2.4.5. 

\subsubsection{Cross-Validation} 
Models may be biased if they are being tested on a specific set of data. To improve fairness, cross validation technique is followed. In this method, the dataset is divided into k-folds, with k-1 folds for training and 1-fold for testing. This procedure is iterated over the entire dataset such that each portion k of the dataset would have been the testing dataset at some point across different iterations\footnote{\url{https://www.openml.org/a/estimation-procedures/1}}. This thesis uses a 10-fold cross validation approach. An example of 10-fold cross validation approach is illustrated in the following figure \ref{fig:k-fold}.
\begin{figure}[h] %b!]
    \centering
    \includegraphics[width=9cm]{k-fold}
    \caption{Example for K-Fold Cross Validation}
    \small Image adapted from Sebastian Raschka\footnotemark.
    \label{fig:k-fold}
\end{figure}
\footnotetext{\url{https://sebastianraschka.com/faq/docs/evaluate-a-model.html}}

\subsection{Transformation Methods}

\subsubsection{Binary Relevance} 
Binary relevance is a kind of problem transformation method applied to multi-class or multi-label classification problems. Using this approach, a multi-class problem is decomposed into multiple binary classification problems. For example, if there are five classes, the problem would be decomposed into five binary classification problem where the classifier runs independently on each of the class using the input features\footnote{\url{https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/}}. 

\subsubsection{Label Powerset} 
Label powerset is another form of problem transformation method applied to multi-class or multi-label classification problems. In the case of label powerset, one single multi-class classifier is used to train all unique combinations of label from the training dataset.
\bigbreak
Both Lata \cite{Lata2016} and Nonnenmacher\cite{Nonnenmacher2017} have used BR and LP transformation methods to perform multi-label/multi-class text classification to extract rationale from chat messages and IRC messages respectively. 

\subsection{Algorithms}
Many algorithms exist in the domain of machine learning to perform different kinds of classification. The scope of this thesis, however, is text classification using supervised learning techniques. The algorithms that will be looked into are mentioned in this section.

\subsubsection{Logistic Regression}
Given a set of independent variables, $x_1$, $x_2$,.., $x_n$, Logistic Regression (LR) is an algorithm that predicts the outcome, $Y$, that is a binary or categorical variable \cite{Peng2002}\cite{Strombergsson2009} . It is a special form of linear regression except that probability is calculated by using the ratio of logarithm of odds. The data is fit into a logit function for the prediction of outcomes. Binary logistic model predicts the outcomes of two classes, Class A (0) and Class B (1), whereas multinomial logistic model is capable of predicting more than two classes, for example, Class A, Class B and Class C\cite{Jurafsky2017}. 
\bigbreak
Given $b$ the co-efficient of $x_1$ and $a$ the bias term, log of odds ratio is given as:
\begin{align*}
log\frac{Y}{1-Y} &= a + bx_1
\end{align*}
\bigbreak
Transforming the above log of odds ratio to get the value of $Y$:
\begin{align*}
Y &=  \frac{e^{a + bx_1}}{1 + e^{a + bx_1}}
\end{align*}
\bigbreak
Rogers et al.\cite{Rogers2012} and Kurtanovic et al.\cite{Kurtanovic2017} have used LR for extracting rationale and performing classification on their respective datasets of software reviews and bug reports. 

\subsubsection{Multinomial Naive Bayes}
Naive Bayes (NB) belongs to the class of algorithms that are predominantly based on the Bayes Theorem. Algorithms of this group have a common notion that features that contribute to the predicition of an outcome are all independent of each other. However, in real world, this assumption contradict the hypothesis based on which these algorithms function. Naive Bayes, though, is considered to be easy, fast and efficient \cite{Rennie2003}. 
\bigbreak
Given two events $C$ and $F$, the Bayes Theorem formula, for computing the probability of event $C$ given that $F$ has occured, can be defined as: 
\begin{align*}
P(C|F) &= \frac{P(C|F) \times P(C)}{P(F)}
\end{align*}
\bigbreak
MacCullum and Nigam \cite{McCallum1998a} published their research on a variant of Naive Bayes, popularly known as the Multinomial Naive Bayes (MNB) model. Unlike the simple Naive Bayes model, MNB uses multinomial distribution for each of the attribute features\footnote{\url{https://stats.stackexchange.com/questions/33185/difference-between-naive-bayes-multinomial-naive-bayes}}. In addition, for tasks like text classification, MNB takes the frequency of word counts, or sequences of word counts, or n-gram tokens independently into account when compared to NB model which only tries to predict the presence or absense of individual words. 
\bigbreak
Given a class $c$ and features $f_1$, $f_2$,.., $f_n$, the formula under NB is:
\begin{align*}
p(c|f_1,...,f_n) \propto p(c) \times p(f_1|c) \times ... \times p(f_n|c)
\end{align*}
\bigbreak
When $p(c|f_i)$ is said to have a multinomial distribution, it is said to be using MNB model.  
\bigbreak
Both Lata \cite{Lata2016} and Nonnenmacher\cite{Nonnenmacher2017} have used MNB model to perform text classification to extract rationale from chat messages and IRC messages respectively. 

\subsubsection{Support Vector Machines}
Support Vector Machine (SVM) is a popular supervised machine learning algorithm that can be used for regression as well as classification\footnote{\url{https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/}}. In SVM, items from a dataset are plotted as points in an n-dimensional space where n equals the number of features in consideration to perform the classification. The value of each feature corresponds to the value of coordinate. A hyperplane is then used to segregate the classes into two. To increase the confidence of correctly classifying a data point to the right class, the margin between the hyperplane and the data point must not be close; more the distance between them better the likelihood of proper classification\cite{Joachims1998a}.  
\bigbreak
In real world, datasets can rarely be linearly separable. In such a scenario, kernels come to rescue when more than two dimensions are involved. To separate the classes, the low dimensional input dimensional space is therefore mapped to a higher dimensional space \cite{Tong2001}. The demerit of this approach, although inevitable, is that is results in longer training time while running the classifier. An illustration of SVM is shown in Figure \ref{fig:svm}. 
\begin{figure}[h] %b!]
    \centering
    \includegraphics[width=5cm]{optimal-hyperplane}
    \caption{Example for Support Vector Machines}
    \small Image adapted from OpenCV\footnotemark.
    \label{fig:svm}
\end{figure}
\footnotetext{\url{https://docs.opencv.org/2.4/doc/tutorials/ml/introduction_to_svm/introduction_to_svm.html}}
\bigbreak
SVM has been used rigorously in the past for various text classification projects. In addition to the thesis works of Lata \cite{Lata2016} and Nonnenmacher\cite{Nonnenmacher2017}, Fan et al.\cite{Fan2017}, Guzman et al.\cite{Guzman2016} and Bacchelli et al.\cite{Bacchelli2012} have also used SVM for text classification tasks in the past. 

\subsubsection{Decision Trees}
Decision tools predominantly used for classification and regression are Decision Trees (DT). At the top most level, there exists one node from where decision needs to be made at every level going downwards based on some rules pertaining to the attribute in consideration, until the final goal is reached\cite{Jain2017}. 
\bigbreak
At every level, for each node, there exists an attribute that is chosen to split into their pertinent classes based on the samples provided. This split is done using a goodness function; some of them are information gain, information gain ratio and gini index, to mention a few. The condition for an attribute to be chosen is the one that gives the smallest tree and hence, an attribute that gives the purest node is chosen. A typical criteria for computing impurity is information gain which increases as the average value of purity of the relevant subsets an attribute produces. Attribute that results in highest information gain is therefore chosen finally\cite{Jain2017}. 
\bigbreak
The highest information gain is chosen after computing the information gain for each of the attribute. Splitting process occurs repeatedly until the scenario where data cannot be split any further. Later, from the bottom, pruning of the tree takes place to make it shorter and avoid overfitting of any kind. In addition to SVM, Nonnenmacher\cite{Nonnenmacher2017}, Fan et al.\cite{Fan2017} and Guzman et al.\cite{Guzman2016} have also used DT for text classification tasks in their respective works.

\subsubsection{Random Forest}
Random forests belong to a special class of learning algorithms known as the ensemble learning algorithm. This methodology believes individual classifiers are weak and are not having high accuracy. Hence, random forests use techniques such as bagging to overcome this limitation. Random forests thus creates different subsets from the dataset and decision tree classifier is run on each of these subsets. Bagging is then used to combine the results of all the individual classifier run on different subsets to perform the final classification; it decreases the test error by lowering the variance of prediction\cite{Jain2017}. 
\bigbreak
Due to their nature of running the same algorithm multiple times over different subsets, random forests can be completely parallelized as well. Random forests have more advantages since it aggregates many weak classifiers to make the final classification. Thanks to its ensemble learning approach, it prevents overfitting and gives better accuracy. In addition to handling data without any kinds of preprocessing, random forests are also considered to be resitant to outliers and over-training\cite{Jain2017}. In addition to MNB, SVM and DT, Nonnenmacher\cite{Nonnenmacher2017} performed the experiements using Random Forest model as well. 

\subsection{Performance Metrics}
Performance metrics of a classifier is imperative to know how accurate the model is. A confusion matrix can hence be plotted which comprises of True Positive (TP), True Negative (TN), False Positive (FP) and False Negative (FN) as depicted in Figure \ref{fig:confusion-matrix}.
\begin{figure}[h] %b!]
    \centering
    \includegraphics[width=5cm]{confusion_matrix}
    \caption{Confusion Matrix}
    \small Image adapted MLXTEND\footnotemark.
    \label{fig:confusion-matrix}
\end{figure}
\footnotetext{\url{https://rasbt.github.io/mlxtend/user_guide/evaluate/confusion_matrix/}}
\bigbreak
Given a positive class, $P_C$, and a negative class, $N_C$, the following can be defined:
\bigbreak
True Positive Rate (TPR) is the proportion of correctly classified $P_C$. True Negative Rate (TNR) is the proportion of correctly classified $N_C$. False Positive Rate (FPR) is the proportion of incorrectly classified $N_C$, classified as $P_C$. False Negative Rate (FNR) is the proportion of incorrectly classified $P_C$, classified as $N_C$. The four components of the confusion matrix defined earlier can now be used to define the following subsections.

\subsubsection{Accuracy} 
Accuracy is the ratio of sum of TP and TN to the entire number of samples in the dataset.
\begin{align*}
Accuracy &= \frac{ TP + TN}{TP + TN + FP + FN}
\end{align*}

\subsubsection{Precision} 
Precision is the ratio of TP to the sum of TP and FP.
\begin{align*}
Precision &= \frac{TP}{TP + FP}
\end{align*}

\subsubsection{Recall} 
Recall is the ratio of TP to the sum of TP and FN. Recall is also known as hit rate, True Positive Rate (TPR) or sensitivity.
\begin{align*}
Recall &= \frac{TP}{TP +FN}
\end{align*}

\subsubsection{F1 Score} 
F1 score is the harmonic mean of recall and precision. 
\begin{align*}
F1 &= \frac{2TP}{2TP + FP + FN}
\end{align*}

\section{Tools}
There are a wide range of tools to accomplish the tasks that have been carried out in this thesis. Some of these tools are free and open-sourced while the rest are commercial. This research has been carried out only using the tools that are popular, have been used in the past to carry out similar tasks by others, and are completely free. 
\bigbreak
For the annotation tasks, spreadsheet application such as Libre Office\footnote{\url{https://www.libreoffice.org/}} has been used although many have used GATE in the past \cite{Lata2016}\cite{Nonnenmacher2017}. The reason for using Libre Office was that it comes readily available Ubuntu operating systems and does not require additional installation, like in the cast of GATE. 
\bigbreak
To carry out tasks such as scraping, classification and NLP, Python\footnote{\url{https://www.python.org/}} was used. Python is a programming language that can cater to the needs of the tasks needed to accomplish in this thesis. In addition, Python can be installed across any operating system. Python has an extensive list of libraries for scraping. This thesis uses BeautifulSoup\footnote{\url{https://www.crummy.com/software/BeautifulSoup/bs4/doc/}} and Requests\footnote{\url{http://docs.python-requests.org/en/master/}} to scrape data from different websites. While Requests was used to request and get responses from the URL to be scraped, BeautifulSoup was used to achieve the final goal of fetching the content. In addition, BeautifulSoup also had its own parsers that was used to extract the content needed.
\bigbreak
Results of scraping and final annotations were stored in a MySQL\footnote{\url{https://www.mysql.com/}} database. As stated by themselves, MySQL is also the world's most popular open sourced database. Like Python, MySQL is free and can also be installed across different platforms and hence was used by both, the author as well as his advisor for the tasks pertaining for scraping and manual labeling. 
\bigbreak
Topic modeling using LDA was performed using a famous library named Gensim\footnote{\url{https://radimrehurek.com/gensim/}}. Rehurek and Sojka \cite{Rehurek2010} published their work on the internal details of how Gensim works as well. Gensim is also capable of supporting other topic modeling techniques such as Hierarchial Dirichlet Process and Latent Semantic Analysis. 
\bigbreak
Scikit-learn\footnote{\url{http://scikit-learn.org/stable/}} is one of the most sought after machine learning libraries for Python \cite{Pedregosa2012}. It supports multiple machine learning methodologies such as classification, regression, clustering, dimensionality reduction, to mention a few. All the binary classification tasks in this thesis has been carried out using LR, MNB, SVM, DT and RF, which come packaged with the scikit-learn library. Kurtanovic and Maleej \cite{Kurtanovic2017} have also used this library for their work on mining rationale from software reviews. However, at the time of writing this thesis, scikit-learn did not provide transformation methods such as Binary Relevance and Label Powerset for multi-class and multi-label classifications. Hence, an extension of scikit-learn called scikit-multilearn\footnote{\url{http://scikit.ml/}} was used. However, the library did not yield proper results for a lot of configurations and algorithms. 
\bigbreak
Topic modeling and classification tasks in Python have been carried with the help of some additional libraries such as NLTK\footnote{\url{http://www.nltk.org/}} and SpaCy\footnote{\url{https://spacy.io/}}. NLTK was used for tokenization and lemmatization while SpaCy was used for POS tagging techniques. NLTK and SpaCy were extensively studied by Al Omran and Treude \cite{AlOmran2017} where they explored NLP libraries for analyzing software documentation. 
\bigbreak
MEKA\footnote{\url{http://meka.sourceforge.net/}}\cite{MEKA2016}, an extension of WEKA\footnote{\url{https://www.cs.waikato.ac.nz/ml/weka/}}, has been used to overcome the limitations of scikit-learn and scikit-multilearn. The fine grained classifications using transformation methods such as BR and LP are supported by MEKA. In addition, MEKA also has a robust range of preprocessing options. This tool has also been used by Lata \cite{Lata2016} and Nonnenmacher \cite{Nonnenmacher2017} in their respective research works. 
\bigbreak
For quick analysis of results and neat data visualizations, R programming language\footnote{\url{https://www.r-project.org/}} was used, a language concentrating on statistical analyses. The graphic libraries offered by R have been claimed to be more pleasing to the eyes when compared to Python\footnote{\url{https://www.datacamp.com/community/tutorials/r-or-python-for-data-analysis}}. All the graphs in this thesis has been generated using ggplot2\footnote{\url{http://ggplot2.org/}} library for R. 

%------- chapter 3 -------

\chapter{Data Collection}

This chapter describes the datasets used to carry out the research and the collection of data from the three sources: Apache Lucene, Mozilla Thunderbird and Ubuntu. All three sources mentioned use different issue trackers. Apache Lucene uses JIRA owned by Atlassian Inc., Mozilla Thunderbird uses Bugzilla developed by Mozilla Foundation and Ubuntu uses Launchpad created by Canonical Ltd. 
\bigbreak
There are multiple reasons why these projects have specifically been chosen. First of all, the projects chosen are all completely open sourced. Studying and analysing the data from open sourced projects, especially the ones from Apache Software Foundation (ASF) has been a common practice in the research community. In the past, Bacchelli et al.\cite{Bacchelli2012} used data from Apache Mina to classify development emails. Ortu et al.\cite{Ortu2015} studied the JIRA repository dataset of ASF. Panichella et al. \cite{Panichella2014} roped in the datasets from Apache HTTPD, CXF and Lucene. Besides datasets from ASF, the same authors mentioned in this paragraph have also used other projects such as JBoss, Spring and Hibernate. Additionally, these projects also have been around for quite a long time, have a large community that is active, and have been making releases from time to time. Another reason for choosing such projects is that while scraping data, the author of the scraper needs to respect the rules of the website. At the time of scraping, these websites did not impose any kind of restrictions on the data that had to be fetched; as a matter of fact, JIRA tracker of Apache Lucene also provided with readily available data for download. The final reason for choosing these projects is also to continue a research work done by \cite{Nonnenmacher2017} in his master thesis where he extracted rationale from IRC messages. This master thesis also uses his dataset which is described in Section X.Y.Z. 

\section{Issue Trackers Dataset}
This section investigates how data was obtained from issue trackers of Apache Lucene, Mozilla Thunderbird and Ubuntu. In addition, Table \ref{tab:rawIssueTrackers} shows the figures of the raw dataset. 

\begin{table} %[hb!]
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \def\arraystretch{1} % 1 is the default, change whatever you need (line spacing)
    \begin{tabular}{p{4cm} p{5cm} p{2cm} p{3cm}}
        \toprule
        \textbf{Project} & \textbf{Timeline} & \textbf{Issues} & \textbf{Comments}\\
        \midrule
			Apache Lucene & 2001 - 2017 (until August) & 7,932 & 74,012\\
			Mozilla Thunderbird & 2008 - 2017 (until August) & 4,367 & 26,587\\ 
			Ubuntu & 2004 - 2017 (until August) & 28,429 & 150,008\\
        \midrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Overview of Issue Trackers Raw Dataset}
    \label{tab:rawIssueTrackers}
\end{table}

\subsubsection{Apache Lucene}
Apache Lucene\footnote{\url{https://lucene.apache.org/}} is an open sourced high performance text search engine written in Java by Doug Cutting in 1999. The project was donated to Apache Foundation\footnote{\url{https://www.apache.org/}} in the year 2001. To develop and maintain the software, the issue tracker called JIRA\footnote{\url{https://www.atlassian.com/software/jira}} developed by Atlassian\footnote{\url{https://www.atlassian.com}} is used. At the time of conducting this research, the total number of issues were 7,940. However, only 7,932 issues were fetched since some issues could have been deleted by the moderators, contained non-English characters or had no comments.
\bigbreak
In JIRA, each issue gives us an option to export all the data needed for the research in XML, JSON or Word. However, JIRA also provides a link to get all these information needed for upto 1,000 issues in XML. This link was altered 8 times to cover 7,932 issues. The XML data from the links were saved locally as XML files. The XML ElementTree API available for Python was used to parse the XML files and extract the necessary data. Figure \ref{fig:luceneRawDistro} shows the distribution of comments for Apache Lucene dataset. 

\begin{figure}[h] %b!]
    \centering
    \includegraphics[width=14cm]{lucene-comment-distribution-raw}
    \caption{Overview of distribution of comments for Apache Lucene}
    \label{fig:luceneRawDistro}
\end{figure}

\subsubsection{Mozilla Thunderbird}
Mozilla Thunderbird\footnote{\url{https://www.mozilla.org/en-US/thunderbird/}} is an open sourced cross platform email client developed by Mozilla Foundation\footnote{\url{https://www.mozilla.org/en-US/}} with initial release dating back to 2003. The issue tracker used by Mozilla Thunderbird is Bugzilla\footnote{\url{https://bugzilla.mozilla.org/}} which was developed by Mozilla Foundation itself. The oldest issue, however, dates back to June 2007 and the number of issues fetched were 4,367. Like Apache Lucene, issues with no comments were ignored. 
\bigbreak
As mentioned earlier, JIRA gave us the option to get all the data needed for upto 1,000 issues on each request. However, Bugzilla did not have any option that was similar. In the case of Bugzilla, data for each issue had to be accessed individually. Another drawback of Bugzilla when compared to JIRA was that the data when exported did not have the comments for the relevant issues. Hence, all the necessary data, including the comments, for the issues in Bugzilla were scraped using BeautifulSoup, a library for Python to scrape data from the web. Figure \ref{fig:thunderbirdRawDistro} shows the distribution of comments for Mozilla Thunderbird dataset. 

\begin{figure}[h] %b!]
    \centering
    \includegraphics[width=14cm]{thunderbird-comment-distribution-raw}
    \caption{Overview of distribution of comments for Mozilla Thunderbird}
    \label{fig:thunderbirdRawDistro}
\end{figure}

\subsubsection{Ubuntu}
Ubuntu\footnote{\url{https://www.ubuntu.com/}} is an open sourced operating system developed by Canonical Ltd.\footnote{\url{https://www.canonical.com/}} in the year 2004. The same team is also responsible for having their own issue tracking system known as Launchpad\footnote{\url{https://launchpad.net/}} which also houses the issues of Ubuntu. The number of issues fetched since the beginning of the project are 28,429. Issues with no comments were not scraped, just like in the case of Apache Lucene and Mozilla Thunderbird. Additionally, a major problem faced while scraping data from Launchpad was that there were abundant number of downlinks. When these links were accessed manually, they kept loading until getting timed out and returned 404 error while scraping.
\bigbreak
Launchpad did not have its export option to fetch mass number of issues and its comments. Hence, each and every issue had to be scraped one at a time. In addition, not all the issues had the same HTML tags and attributes for the comments section. Launchpad provides individual link for each of the comment of the pertinent issue and hence, the comments were scraped by obtaining the individual links for comments. All the links were requested and the necessary data was retrieved using BeautifulSoup, the library mentioned in the previous section. Figure \ref{fig:ubuntuRawDistro} shows the distribution of comments for Ubuntu dataset. 

\begin{figure}[h] %b!]
    \centering
    \includegraphics[width=14cm]{ubuntu-comment-distribution-raw}
    \caption{Overview of distribution of comments for Ubuntu}
    \label{fig:ubuntuRawDistro}
\end{figure}

%\subsection{Commit Logs Dataset}
%This section scrutinizes how the data of commit messages were obtained for Apache Lucene, Mozilla Thunderbird and Ubuntu.

%\subsubsection{Apache Lucene}
%Apache Lucene uses Git for its version control, which was developed by Linus Torvald and released in 2005. Apache Lucene along with SOLR is hosted together within the same repository on GitHub. The repository was cloned to local environment in the system to retrieve the commit logs. Git allows the logs of the repository to be exported in TXT format and this is the method that has been used to get all the logs for Apache Lucene. However, a parsing script was additionally written in Python to obtain all the commit id, author, date and commit message respectively. These information was later stored in a MySQL database. 

%\subsubsection{Mozilla Thunderbird}
%Mozilla Thunderbird uses Mercurial for its version control, which was developed by Matt Mackall and released in 2005. The Mozilla Thunderbird project in a repository owned by Mozilla. This repository was cloned to the system to extract the commit logs. Like Git, Mercurial also offers users an option to extract the entire commit log history in TXT format. This data was parsed using a script written in Python to retrieve all the commit id, author, date and commit message respectively. The retrieved information was eventually stored in a MySQL database. 

%\subsubsection{Ubuntu}
%Ubuntu makes use of Bazaar primarily for its version control, which was developed by Martin Pool in 2005 and maintained by Canonical Ltd. The Ubuntu project is hosted on Launchpad platform using Bazaar. Due to too numerous repositories, the entire Ubuntu project could not be cloned individually. However, a script in Python was written using the BeautifulSoup library; similar to the script used for fetching data from issue trackers for Ubuntu. Identical problems of many downlinks were encountered and hence, only those that were up were fetched automatically. A MySQL database was used to store all of these information. 

\section{IRC Messages Dataset}

The IRC messages dataset has been scraped by Nonnenmacher \cite{Nonnenmacher2017} for his thesis where he has extracted rationale out of the same. The following data in Table \ref{tab:rawIRCMessages} are the statistics of the raw data collected. 

\begin{table} %[hb!]
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \def\arraystretch{1} % 1 is the default, change whatever you need (line spacing)
    \begin{tabular}{p{4cm} p{5cm} p{2cm} p{3cm}}
        \toprule
        \textbf{Project} & \textbf{Timeline} & \textbf{Threads} & \textbf{Messages}\\
        \midrule
			Apache Lucene & 2004 - 2017 (until August) & 1,059 & 273,123\\
			Mozilla Thunderbird & 2004 - 2017 (until August) & 1,850 & 299,771\\ 
			Ubuntu & 2004 - 2017 (until August) & 4,592 & 2,897,987\\
        \midrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Overview of IRC Messages Raw Dataset}
    \label{tab:rawIRCMessages}
\end{table}

%------- chapter 4 -------

\chapter{Manual Content Analysis}

This chapter dives into the procedure of manual content analysis and the formation of ground truth for machine learning experiments to be carried out later. In addition, this chapter also gives insights on how the sample data for the experiements to be performed were obtained from the initial raw dataset. 

\section{Ground Truth Dataset}
An imperative step after performing machine learning experiements is to measure characteristics such as accuracy, precision, recall and F1 score. This, in turn, means one needs to have a reliable dataset for ground truth. Messages from the issue trackers have no pre-defined structure as to whether they contain any kind of rationale or not. To have similar understanding, be on the same page and reduce the number of disagreements later, both the annotators randomly went through a few sentences. The annotators marked rationale for each of them if applicable, classified them appropriately, and shared their perspectives before concluding on mutual agreements as to how to go about in the main manual content analysis experiment.  Some of the examples are mentioned in detail in the coding guide for manual content analysis. There were two kinds of classification performed in this stage: binary and multi-class classification. Binary classification was done to check if the sentence contains any kind of rationale or not. Multi-class classification was done to classify the sentence, if rationale is found, into five categories: issue, alternatives, pro-arguments, con-arguments and decision, which are explained as follows.

\begin{itemize}
\item \textbf{Issue:} the problem to be solved, or a feature to be implemented
\item \textbf{Alternative:} the feasible solutions that could address the issue
\item \textbf{Pro-Argument:} the argument put across in favor of a particular alternative
\item \textbf{Con-Argument:} the argument put across against a particular alternative
\item \textbf{Decision:} the final conclusions made to resolve the issue
\end{itemize}

\section{Random Stratified Sampling}
For the main content analysis, two annotators, the author and his advisor, individually read through individual sentences of all comments spanning 100 issues from each of the three projects. Although the number of issues fetched for each of them were much higher, only 100 of them were attained for each project using Random Stratified Sampling (RSS) due to time constraints of the research. RSS can be of two types: proportionate random stratified sampling and disproportionate random stratified sampling. In proportionate random stratified sampling\footnote{\url{http://www.oxfordreference.com/view/10.1093/oi/authority.20110803100349910}}, the parent dataset is divided into multiple strata and the child dataset sampled randomly must have the strata in the same proportion as the parent dataset. Contrary to proportionate random stratified sampling, the case of disproportionate random stratified sampling\footnote{\url{http://www.oxfordreference.com/view/10.1093/oi/authority.20110803095722568}} has the parent dataset divided into multiple strate but the child dataset sampled randomly may not have its strata in the same proportion as the parent dataset. There are, however, three steps carried out sequentially to obtain the sample which are as follows.

\begin{itemize}
\item {Step 1:} Filter the dataset by discarding issues that do not fall under the required date range. The required date range is the range used in the IRC message dataset which can be referred in Table \ref{tab:rawIRCMessages}. This is to make sure the comments from issue trackers are from the same duration as messages from IRC. 
\item {Step 2:} In the next step, count the number of comments for each issue that are under the required date range but only consider issues that have between 5 and 30 comments, and divide them into 5 groups: 6-10 comments, 11-15 comments, 16-20 comments, 21-25 comments and 26-30 comments, in order to avoid issues with too few comments (less than 5) or way too many comments (greater than 30). 
\item {Step 3:} Perform proportionate random stratified sampling to obtain 100 random issues from the filtered dataset in step 2 for each of the three projects. 
\end{itemize}



\begin{table} %[hb!]
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \def\arraystretch{1} % 1 is the default, change whatever you need (line spacing)
    \begin{tabular}{p{4cm} p{2cm} p{2cm} p{2cm} p{2cm} p{2cm}}
        \toprule
        \textbf{Project} & \textbf{6-10} & \textbf{11-15} & \textbf{16-20} & \textbf{21-25} & \textbf{25-30}\\
        \midrule
			Apache Lucene & 53 & 23 & 12 & 7 & 5\\
			Mozilla Thunderbird & 68 & 20 & 7 & 3 & 2\\ 
			Ubuntu & 61 & 19 & 10 & 6 & 4\\
        \midrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Number of issues in each strata after RSS}
    \label{tab:strataProportion}
\end{table}

From Table \ref{tab:strataProportion} and Figure \ref{fig:multilineStrata}, it can be seen that there is an inverse correlation between the number of issues and comments in each strata. All the three projects, Apache Lucene, Mozilla Thunderbird and Ubuntu, demonstrate that the number of issues in each strata gradually decreases as the number of comments in them increases. 
\bigbreak
\begin{figure}[h] %b!]
    \centering
    \includegraphics[width=11cm]{rss-multi-line-plot}
    \caption{Number of issues in each strata for all 3 projects}
    \label{fig:multilineStrata}
\end{figure}
The figures on number of comments and the number of sentences under each project after performing the random stratified sampling are presented in Table \ref{tab:overviewRSS}. 

\begin{table} %[hb!]
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \def\arraystretch{1} % 1 is the default, change whatever you need (line spacing)
    \begin{tabular}{p{4cm} p{1cm} p{2cm} p{3cm}}
        \toprule
        \textbf{Project} & \textbf{Issues} & \textbf{Comments} & \textbf{Sentences}\\
        \midrule
			Apache Lucene & 100 & 963 & 2,446\\
			Mozilla Thunderbird & 100 & 987 & 3,086\\ 
			Ubuntu & 100 & 813 & 2,782\\
        \midrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Overview of dataset after Random Stratified Sampling}
    \label{tab:overviewRSS}
\end{table}

\section{Manual Annotation}
After having performed Random Stratified Sampling, the next step was to manully annotate or label each every sentence from all the 3 projects, Apache Lucene, Mozilla Thunderbird and Ubuntu. These annotations would therefore form the groundtruth to perform the machine learning classification experiments in later stages of this thesis. Manual annotation has been a popular technique and has been implemented in the past by various researchers \cite{Alkadhi2017} \cite{Nonnenmacher2017}. 
\bigbreak
To perform this step, Excel was used since it was a tool to achieve the goal without having the need to install anything more. A set of criteria found in Appendix A was agreed upon and followed by the two annotators, the author and his advisor. Both the annotators individually labeled the sentences from all the 3 projects. While the author of this thesis took 21 hours to accomplish this task, the same task took a tad bit more, 21 hours and 15 minutes for his advisor. 
\bigbreak
The second step of this annotation task was to keep all the complete agreements intact but discuss the sub-agreements and complete disagreements. Sub-agreements were those sentences were there was an overlap of labeling between the author and his advisor. For an example, a sentence was labeled as an issue and decision by the author while the advisor marked it as an issue and an alternative. One can note that both had agreed that the sentece does belong to the class of issue but had conflicting opinions about decision or an alternative. Complete disagreements are cases were both of them marked a given sentence as completely different with no overlap of opinions. For example, a sentence was marked as an alternative by the author while his advisor marked it as a decision. Both, the author and his advisor, then sat once again, this time together, to resolve all the conflicting opinions and come to a mutual conclusion on the labels. Table \ref{tab:labelBinary} and Table \ref{tab:labelFine} gives the statistics of agreements and disagreements of the two annotators. 

\begin{table} %[hb!]
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \def\arraystretch{1} % 1 is the default, change whatever you need (line spacing)
    \begin{tabular}{p{4cm} p{3cm} p{3cm} p{3cm}}
        \toprule
        \textbf{Project} & \textbf{Sentences} & \textbf{Agreements} & \textbf{Disagreements}\\
        \midrule
			Apache Lucene & 2,446 & 76\% & 24\%\\
			Mozilla Thunderbird & 3,086 & 69\% & 31\%\\ 
			Ubuntu & 2,782 & 75\% & 25\%\\
        \midrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Annotation Statistics for Binary Classification}
    \label{tab:labelBinary}
\end{table}

\begin{table} %[hb!]
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \def\arraystretch{1} % 1 is the default, change whatever you need (line spacing)
    \begin{tabular}{p{4cm} p{3cm} p{3cm} p{3cm}}
        \toprule
        \textbf{Project} & \textbf{Sentences} & \textbf{Agreements} & \textbf{Disagreements}\\
        \midrule
			Apache Lucene & 2,446 & 55\% & 45\% \\
			Mozilla Thunderbird & 3,086 & 56\% & 44\% \\ 
			Ubuntu & 2,782 & 61\% & 39\% \\
        \midrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Annotation Statistics for Fine Grained Classification}
    \label{tab:labelFine}
\end{table}

\section{Annotation Results}
The results of manual annotation from both the annotators are presented in this section. Table \ref{tab:distroBinaryRationale} gives a detailed overview with both, number and percentages, for all three projects. It can be inferred that Apache Lucene had the highest ratio between sentences with rationale to ones without any rationale whereas Mozilla Thunderbird and Ubuntu appear to be having a healthy ratio between both, rationale and no rationale. Ubuntu is the only project though where the number of sentences with rationale has been outnumbered marginally by the number of sentences not containing any kind of rationale in it. Figure \ref{fig:distroBinaryRationale} shows the proportion of messages for all three projects. Similarly, Table \ref{tab:distroMultiRationale} presents complete overview with numbers and percetage for fine-grained rationale found in the dataset. Apache Lucene (11\%) had the least percentage of issues compared to Mozilla Thunderbird (24\%) and Ubuntu (25\%). However, higher percentage of decisions were made in Apache Lucene (8\%) than Mozilla Thunderbird (3\%) or Ubuntu (4\%). The numbers look very similar even in the case of alternatives, pro-arguments and con-arguments, where Apache Lucene outnumbers Mozilla Thunderbird and Ubuntu. The following numbers can also lead to the inference that due to lesser number of issues, more number of final decisions were reached in case of Apache Lucene. This also leads to another observation that lesser decisions were made in the case of Mozilla Thunderbird and Ubuntu because the numbers for alternatives, pro-argument and con-argument are also low, which are crucial to reach a final conclusion. Figure \ref{fig:distroMultiRationale} shows the distribution of fine-grained rationale in the dataset across all three projects. 

\begin{table} %[hb!]
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \def\arraystretch{1} % 1 is the default, change whatever you need (line spacing)
    \begin{tabular}{p{4cm} p{3cm} p{3cm} p{3cm}}
        \toprule
        \textbf{Project} & \textbf{Sentences} & \textbf{Rationale} & \textbf{No Rationale}\\
        \midrule
			Apache Lucene & 2,446 & 1,780 (73\%) & 666 (27\%)\\
			Mozilla Thunderbird & 3,086 & 1,577 (51\%) & 1,509 (49\%)\\ 
			Ubuntu & 2,782 & 1,349 (48\%) & 1,433 (52\%)\\
        \midrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Distribution of Rationale in Sentences}
    \label{tab:distroBinaryRationale}
\end{table}

\begin{figure}[h] %b!]
    \centering
    \includegraphics[width=11cm]{binary-distro-rationale}
    \caption{Distribution of Rationale Frequency}
    \label{fig:distroBinaryRationale}
\end{figure}
\begin{table} %[hb!]
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \def\arraystretch{1} % 1 is the default, change whatever you need (line spacing)
    \begin{tabular}{p{4cm} p{2cm} p{2cm} p{3cm} p{2cm} p{2cm} p{2cm}}
        \toprule
        \textbf{Project} & \textbf{Sentences} & \textbf{Issue} & \textbf{Alternative} & \textbf{Pro-Argument}  & \textbf{Con-Argument}  & \textbf{Decision} \\
        \midrule
			Apache Lucene & 2,446 & 259 (11\%) & 828 (34\%)  & 543 (22\%) & 284 (12\%) & 207 (8\%)\\
			Mozilla Thunderbird & 3,086 & 747 (24\%) & 484 (16\%) & 224 (7\%) & 228 (7\%) & 80 (3\%)\\ 
			Ubuntu & 2,782 & 687 (25\%) & 410 (15\%) & 189 (7\%) & 152 (5\%) & 117 (4\%)\\
        \midrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Distribution of Fine-Grained Rationale in Sentences}
    \label{tab:distroMultiRationale}
\end{table}

\begin{figure}[h] %b!]
    \centering
    \includegraphics[width=12cm]{multi-distro-rationale}
    \caption{Distribution of Fine-Grained Rationale Frequency}
    \label{fig:distroMultiRationale}
\end{figure}

%------- chapter 7 -------

\chapter{Automatic Classification}

In this section, automatic classification of rationale using numerous preprocessing techniques and classification models is performed. The classification is divided into two categories: binary and fine-grained. In binary classification, a sentence is classified as whether it contains rationale or not; in other words, a given sentence can only belong to one class. However, in fine-grained classification, a given sentence may belong to more than one class. Hence, the classifier would aim to classify them into any of the classes such as issue, alternative, pro-argument, con-argument and decision. Both kinds of classifications have been performed using the preprocessing methods that have been described in Section 2.3.1. These preprocessing methods act as configurations that are supplied to the classification models whose results are later described in the sections to follow. Table \ref{tab:configurationNames} describes the name of the configuration and its corresponding preprocessing methods. The five classifiers that have been used to carry out the classification tasks are Multinomial Naive Bayes (MNB), Logistic Regression (LR), Support Vector Machine (SVM), Decision Tree (DT) and Random Forest (RF). In the case of multi-class classification, transformation methods such as Binary Relevance (BR) and Label Powerset (LP) were used in addition to the five classifiers mentioned earlier. 
\newline \newline
Besides binary and fine grained classification, the results of topic modeling are also presented in Section 5.3 for each of the three datasets of issue trackers: Apache Lucene, Mozilla Thunderbird and Ubuntu. In addition, keywords were extracted from each comment of ITS and each message of IRC to find similarity between and link them. Section 5.4 presents the results of linking comments and messages from ITS and IRC together. 

\begin{table} %[hb!]
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \def\arraystretch{1} % 1 is the default, change whatever you need (line spacing)
    \begin{tabular}{p{2cm} p{13cm}}
        \toprule
        \textbf{Config} & \textbf{Preprocessing Methods} \\
        \midrule
			Config 1 & Bag-of-Words \\
			Config 2 & Bag-of-Words + TF-IDF \\ 
			Config 3 & Bag-of-Words + TF-IDF + N-Grams \\
			Config 4 & Bag-of-Words + TF-IDF + N-Grams + Stopwords \\
			Config 5 & Bag-of-Words + TF-IDF + N-Grams + Stopwords + Lemmatization/Stemming \\
			Config 6 & Bag-of-Words + TF-IDF + N-Grams + POS Tagging \\
        \midrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Preprocessing methods and its combinations used for classification}
    \label{tab:configurationNames}
\end{table} 

\section{Binary Classification}
This section presents the results of the binary classification experiments performed using the configurations mentioned in Table \ref{tab:configurationNames} and the algorithms from Section 2.4.4. It is to be noted that in the case of Lucene dataset, unigram results have been presented while trigram results in the cases of Thunderbird and Ubuntu have been shown, since these combinations have given the best results. The experiments have been carried out using scikit-learn Python library. For POS tagging mechanism, Spacy, another popular NLP library was used. 

\subsection{Logistic Regression}
In case of Lucene dataset, LR does its best to predict rationale when Config 6, that is, POS Tagging with unigram is applied with an F1 score of 0.889. However, when the contrary is to be predicted, the most basic configuration of BoW method seems to be the best with an F1 score of 0.591. Thunderbird and Ubuntu datasets, when fed with LR classifier, shows similar results when non-rationale sentences are to be predicted with the basic configuration, Config 1, giving the most impressive results with F1 scores of 0.732 and 0.758 respectively. However, when predicting rationale, Config 3 with trigram gives F1 scores of 0.732 and 0.758 respectively. An overall observation of LR across all three datasets also reveals that the classifier performs better in predicting rationale than when predicting the opposite. Table \ref{tab:binLR} demonstrates the results in detail. 

\begin{table}[h] %[hb!]
    %\resizebox{\textwidth}{!}{%
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \begin{tabular}{L{1.5cm} c ccc | ccc | ccc }
        \toprule
         \multirow{2}{*}{\textbf{Config}} &  \multirow{2}{*}{\textbf{Rationale}} & \multicolumn{3}{c}{\textbf{Lucene}} & \multicolumn{3}{c}{\textbf{Thunderbird}} & \multicolumn{3}{c}{\textbf{Ubuntu}}\\ 
        \cmidrule(l){3-5} \cmidrule(l){6-8} \cmidrule(l){9-11}
            &  & \textbf{Pr} &  \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} \\
        \midrule 	
        & with & \textbf{0.844} & 0.928 & 0.883 & \textbf{0.713} & 0.647 & 0.676 & \textbf{0.760} & 0.701 & 0.726 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 1 \\ Config 1} \end{minipage}} &   without & 0.703 & \textbf{0.519} & \textbf{0.591} & 0.688 & \textbf{0.751} & \textbf{0.716} & 0.734 & \textbf{0.791} & \textbf{0.758} \\ 
        \midrule 	
        & with & 0.816 & 0.978  & 0.889 & 0.674 & 0.700 & 0.681 & 0.714 & 0.781 & 0.743 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 2 \\ Config 2} \end{minipage}} &   without & \textbf{0.837} & 0.386 & 0.518 & 0.703 & 0.677 & 0.684 & 0.769 & 0.704 & 0.731 \\ 
        \midrule 	
        & with & 0.816 & 0.978  & 0.889 & 0.656 & \textbf{0.839} & \textbf{0.732} & 0.671 & \textbf{0.878} & \textbf{0.758} \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 3 \\ Config 3} \end{minipage}} &   without & 0.837 & 0.386 & 0.518 & 0.703 & 0.677 & 0.684 & 0.769 & 0.704 & 0.731 \\ 
        \midrule 	
        & with & 0.816 & 0.978  & 0.885 & 0.643 & 0.613 & 0.621 & 0.671 & 0.720 & 0.689 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 4 \\ Config 4} \end{minipage}} &   without & 0.780 & 0.357  & 0.480 & 0.649 & 0.677 & 0.657 & 0.718 & 0.671 & 0.688 \\ 
        \midrule 	
        & with & 0.802 & 0.981  & 0.881 & 0.651 & 0.629 & 0.631 & 0.700 & 0.721 & 0.705 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 5 \\ Config 5} \end{minipage}} &   without & 0.796 & 0.324  & 0.442 & \textbf{0.718} & 0.665 & 0.687 & \textbf{0.773} & 0.706 & 0.734 \\ 
        \midrule 	
        & with & 0.813 & \textbf{0.981}  & \textbf{0.889} & 0.644 & 0.832 & 0.723 & 0.667 & 0.867 & 0.750 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 6 \\ Config 6} \end{minipage}} &   without & 0.834 & 0.366  & 0.495 & 0.711 & 0.669 & 0.686 & 0.780 & 0.707 & 0.737 \\ 
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Binary classification with LR and 10-fold cross validation}
    \label{tab:binLR}
\end{table}

\subsection{Multinomial Naive Bayes}
When predicting rationale, MNB has an F1 score of 0.884 for Config 2 and Config 3 for the dataset of Lucene. However, Config 2, BoW + TFIDF, would be a better choice since Config 3 is nothing but Config 2 with n-gram preprocessing method, and hence Config 2 is marginally faster. Like in the case of Logistic Regression, Config 1 gives the best result when predicting non-rationale sentences with an F1 score of 0.448. The Thunderbird dataset gives an F1 score of 0.699 with Config 3 when predicting rationale but an F1 score of 0.658 when otherwise. The Ubuntu dataset, with an F1 score of 0.754 performs the best when POS tagging technique is applied whereas Config 2 and 3 get the highest F1 score of 0.697 when trying to predict non-rationale sentences. Table \ref{tab:binMNB} demonstrates the results in detail. 

\begin{table}[h] %[hb!]
    %\resizebox{\textwidth}{!}{%
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \begin{tabular}{L{1.5cm} c ccc | ccc | ccc }
        \toprule
         \multirow{2}{*}{\textbf{Config}} &  \multirow{2}{*}{\textbf{Rationale}} & \multicolumn{3}{c}{\textbf{Lucene}} & \multicolumn{3}{c}{\textbf{Thunderbird}} & \multicolumn{3}{c}{\textbf{Ubuntu}}\\ 
        \cmidrule(l){3-5} \cmidrule(l){6-8} \cmidrule(l){9-11}
            &  & \textbf{Pr} &  \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} \\
        \midrule 	
        & with & \textbf{0.804} & 0.974 & 0.880 & 0.616 & \textbf{0.815} & 0.697 & 0.659 & 0.826 & 0.728 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 1 \\ Config 1} \end{minipage}} &   without & 0.755 & \textbf{0.331} & \textbf{0.448} & \textbf{0.750} & 0.516 & 0.604 & 0.783 & 0.600 & 0.674 \\ 
        \midrule 	
        & with & 0.795 & 0.995  & \textbf{0.884} & \textbf{0.642} & 0.744 & 0.683 & 0.678 & 0.801 & 0.729 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 2 \\ Config 2} \end{minipage}} &   without & 0.830 & 0.289 & 0.413 & 0.711 & 0.603 & 0.645 & 0.773 & 0.644 & \textbf{0.697} \\ 
        \midrule 	
        & with & 0.795 & 0.995 & 0.884 & 0.639 & 0.788 & \textbf{0.699}& \textbf{0.682} & 0.826 & 0.742 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 3 \\ Config 3} \end{minipage}} &   without & 0.830 & 0.289 & 0.413 & 0.711 & 0.603 & 0.645 & 0.773 & 0.644 & 0.697 \\ 
        \midrule 	
        & with & 0.801 & 0.988  & 0.883 & 0.626 & 0.655 & 0.634 & 0.672 & 0.734 & 0.693 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 4 \\ Config 4} \end{minipage}} &   without & 0.827 & 0.311  & 0.438 & 0.656 & \textbf{0.627} & 0.636 & 0.726 & \textbf{0.663} & 0.684 \\ 
        \midrule 	
        & with & 0.781 & 0.994  & 0.874 & 0.613 & 0.674 & 0.635 & 0.671 & 0.734 & 0.693 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 5 \\ Config 5} \end{minipage}} &   without & 0.839 & 0.231  & 0.342 & 0.718 & 0.614 & \textbf{0.658} & 0.783 & 0.643 & 0.701 \\ 
        \midrule 	
        & with & 0.795 & \textbf{0.998}  & 0.884 & 0.643 & 0.770 & 0.696 & 0.669 & \textbf{0.863 }& \textbf{0.754} \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 6 \\ Config 6} \end{minipage}} &   without & \textbf{0.888} & 0.281  & 0.404 & 0.716 & 0.605 & 0.650 & \textbf{0.786} & 0.635 & 0.696 \\ 
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Binary classification with MNB and 10-fold cross validation}
    \label{tab:binMNB}
\end{table}

\subsection{Support Vector Machine}
Unlike other classifiers, recall score of 1.000 was achieved while predicting rationale on Apache Lucene dataset for all configurations but Config 1. The highest F1 score attained was 0.839 using Config 2 for predicting rationale while the top score was 0.682 using Config 1 for predicting non-rationale sentences. In the case of Mozilla Thunderbird dataset, highest precision, recall and F1 scores were achieved using Config 6 for predicting rationale with the F1 score being 0.758. However, in the case of predicting non-rationale sentences on the same dataset, Config 1 performed the best for precision, recall and F1 score, with the F1 score being 0.683. On applying Config 1 to the Ubuntu dataset, top F1 scores of 0.781 and 0.681 were obtained for both. Recall of 1.000 was also achieved using all configurations but Config 1 when classifying non-rationale sentences. Table \ref{tab:binSVM} demonstrates the results. 
\begin{table}[h] %[hb!]
    %\resizebox{\textwidth}{!}{%
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \begin{tabular}{L{1.5cm} c ccc | ccc | ccc }
        \toprule
         \multirow{2}{*}{\textbf{Config}} &  \multirow{2}{*}{\textbf{Rationale}} & \multicolumn{3}{c}{\textbf{Lucene}} & \multicolumn{3}{c}{\textbf{Thunderbird}} & \multicolumn{3}{c}{\textbf{Ubuntu}}\\ 
        \cmidrule(l){3-5} \cmidrule(l){6-8} \cmidrule(l){9-11}
            &  & \textbf{Pr} &  \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} \\
        \midrule 	
        & with & \textbf{0.727} & 0.997 & 0.838 & 0.727 & 0.767 & 0.747 & \textbf{0.811} & \textbf{0.754} & \textbf{0.781} \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 1 \\ Config 1} \end{minipage}} &   without & 0.719 & \textbf{0.649} & \textbf{0.682} & \textbf{0.532} & \textbf{0.967} & \textbf{0.683} & \textbf{0.528} & 0.985 & \textbf{0.681} \\ 
        \midrule 	
        & with & 0.727 & \textbf{1.000} & \textbf{0.839} & 0.727 & 0.767 & 0.747 & 0.811 & 0.754 & 0.781  \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 2 \\ Config 2} \end{minipage}} &   without & 0.719 & 0.649 & 0.682 & 0.448 & 0.900 & 0.597 & 0.515 & \textbf{1.000} & 0.676 \\ 
        \midrule 	
        & with & 0.727 & 1.000 & 0.839 & 0.731 & 0.762 & 0.746 & 0.789 & 0.745 & 0.770 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 3 \\ Config 3} \end{minipage}} &   without & 0.719 & 0.649 & 0.682 & 0.448 & 0.900 & 0.597 & 0.515 & 1.000 & 0.676 \\ 
        \midrule 	
        & with & 0.727 & 1.000 & 0.839 & 0.683 & 0.770 & 0.724 & 0.774 & 0.659 & 0.767 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 4 \\ Config 4} \end{minipage}} &   without & 0.697 & 0.488 & 0.574 & 0.448 & 0.900 & 0.597 & 0.515 & 1.000 & 0.676 \\ 
        \midrule
        & with & 0.727 & 1.000 & 0.839 & 0.683 & 0.770 & 0.724 & 0.774 & 0.659 & 0.767 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 5 \\ Config 5} \end{minipage}} &   without & 0.697 & 0.488 & 0.574 & 0.448 & 0.900 & 0.597 & 0.515 & 1.000 & 0.676 \\ 
        \midrule 	
        & with & 0.727 & 1.000 & 0.839 & \textbf{0.734} & \textbf{0.784} & \textbf{0.758} & 0.780 & 0.723 & 0.750 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 6 \\ Config 6} \end{minipage}} &   without & \textbf{0.728} & 0.634 & 0.677 & 0.448 & 0.900 & 0.597 & 0.515 & 1.000 & 0.676 \\ 
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Binary classification with SVM and 10-fold cross validation}
    \label{tab:binSVM}
\end{table}

\subsection{Decision Tree}
With an F1 score of 0.885, DT performs the best when Config 3 is in action when preciting rationale while the same config also has the highest F1 score of 0.551 when trying to predict non-rationale sentences, in the case of Lucene dataset. Config 1 performs the best in the case of Thunderbird with F1 scores of 0.623 and 0.665 respectively when predicting rationale and non-rationale sentences. When Config 2 is applied to Ubuntu dataset for predicting rationale, an F1 score of 0.685 is achieved while Config 6 seems to perform better when predicting non-rationale sentences with an F1 score of 0.703. Another interesting observation is that, compared to LR and MNB, DT achieves higher scores in predicting non-rationale sentences in the cases of Thunderbird and Ubuntu datasets. Table \ref{tab:binDT} presents the results in detail. 
\begin{table}[h] %[hb!]
    %\resizebox{\textwidth}{!}{%
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \begin{tabular}{L{1.5cm} c ccc | ccc | ccc }
        \toprule
         \multirow{2}{*}{\textbf{Config}} &  \multirow{2}{*}{\textbf{Rationale}} & \multicolumn{3}{c}{\textbf{Lucene}} & \multicolumn{3}{c}{\textbf{Thunderbird}} & \multicolumn{3}{c}{\textbf{Ubuntu}}\\ 
        \cmidrule(l){3-5} \cmidrule(l){6-8} \cmidrule(l){9-11}
            &  & \textbf{Pr} &  \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} \\
        \midrule 	
        & with & 0.827 & 0.937 & 0.878 & 0.651 & \textbf{0.604} & \textbf{0.623} & 0.740 & 0.621 & 0.673 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 1 \\ Config 1} \end{minipage}} &   without & \textbf{0.579} & 0.510 & 0.539 & \textbf{0.645} & \textbf{0.692} & \textbf{0.665} & 0.678 & 0.655 & 0.664 \\ 
        \midrule 	
        & with & 0.826 & 0.939 & 0.878 & 0.625 & 0.605 & 0.611 & 0.727 & \textbf{0.650} & \textbf{0.685} \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 2 \\ Config 2} \end{minipage}} &   without & 0.553 & 0.560 & \textbf{0.551} & 0.632 & 0.652 & 0.638 & \textbf{0.684} & 0.696 & 0.689 \\ 
        \midrule 	
        & with & 0.834 & \textbf{0.945} & \textbf{0.885} & 0.600 & 0.466 & 0.423 & \textbf{0.750} & 0.525 & 0.616 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 3 \\ Config 3} \end{minipage}} &   without & 0.553 & 0.560 & 0.551 & 0.639 & 0.651 & 0.639 & 0.684 & 0.696 & 0.689 \\ 
        \midrule 	
        & with & 0.831 & 0.918 & 0.873 & 0.609 & 0.554 & 0.574 & 0.719 & 0.484 & 0.676 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 4 \\ Config 4} \end{minipage}} &   without & 0.535 & 0.541 & 0.534 & 0.608 & 0.660 & 0.627 & 0.635 & 0.723 & 0.674 \\ 
        \midrule 	
        & with & \textbf{0.841} & 0.845 & 0.844 & \textbf{0.657} & 0.486 & 0.553 & 0.726 & 0.495 & 0.584 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 5 \\ Config 5} \end{minipage}} &   without & 0.477 & \textbf{0.593} & 0.524 & 0.630 & 0.670 & 0.651 & 0.668 & 0.699 & 0.680 \\ 
        \midrule 	
        & with & 0.835 & 0.938 & 0.874 & 0.623 & 0.471 & 0.532 & 0.653 & 0.582 & 0.614 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 6 \\ Config 6} \end{minipage}} &   without & 0.545 & 0.553 & 0.543 & 0.629 & 0.667 & 0.645 & 0.684 & \textbf{0.726} & \textbf{0.703} \\ 
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Binary classification with DT and 10-fold cross validation}
    \label{tab:binDT}
\end{table}

\subsection{Random Forest}
Both, Config 1 and Config 3, attain an F1 score of 0.883 in predicting rationale from the Lucene dataset. However, the score drops to 0.556 when predicting non-rationale sentences on the same dataset. In the case of Thunderbird and Ubuntu, Config 2 outshines other configurations when predicting rationale in sentences with F1 scores of 0.619 and 0.670 respectively. However, in the case of predicting non-rationale sentences Config 4 works the best with 0.757 as the F1 score for Thunderbird dataset while Ubuntu dataset required Config 1 to attain an F1 score of 0.715. Observations similar to that of DT can be noticed as RF performs better in classifiying non-rationale sentences when fed with Thunderbird and Ubuntu datasets. Table \ref{tab:binRF} demonstrates the results in detail. 
\begin{table}[h] %[hb!]
    %\resizebox{\textwidth}{!}{%
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \begin{tabular}{L{1.5cm} c ccc | ccc | ccc }
        \toprule
         \multirow{2}{*}{\textbf{Config}} &  \multirow{2}{*}{\textbf{Rationale}} & \multicolumn{3}{c}{\textbf{Lucene}} & \multicolumn{3}{c}{\textbf{Thunderbird}} & \multicolumn{3}{c}{\textbf{Ubuntu}}\\ 
        \cmidrule(l){3-5} \cmidrule(l){6-8} \cmidrule(l){9-11}
            &  & \textbf{Pr} &  \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} \\
        \midrule 	
        & with & 0.830 & \textbf{0.945} & \textbf{0.883} & 0.689 & 0.518 & 0.585 & 0.644 & \textbf{0.669} & 0.654 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 1 \\ Config 1} \end{minipage}} &   without & 0.742 & 0.427 & 0.538 & 0.665 & 0.659 & 0.657 & 0.740 & 0.697 & \textbf{0.715} \\ 
        \midrule 	
        & with & 0.830 & 0.943 & 0.882 & 0.680 & \textbf{0.577} & \textbf{0.619} & 0.678 & 0.665 & \textbf{0.670} \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 2 \\ Config 2} \end{minipage}} &   without & \textbf{0.782} & 0.408 & 0.525 & 0.689 & 0.621 & 0.649 & \textbf{0.762} & 0.675 & 0.714 \\
        \midrule 	
        & with & 0.834 & 0.942 & 0.883 & 0.699 & 0.430 & 0.526 & 0.738 & 0.525 & 0.610 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 3 \\ Config 3} \end{minipage}} &   without & 0.782 & 0.408 & 0.525 & 0.689 & 0.621 & 0.649 & 0.762 & 0.675 & 0.714 \\ 
        \midrule 	
        & with & 0.836 & 0.906 & 0.868 & 0.661 & 0.462 & 0.538 & 0.737 & 0.479 & 0.579 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 4 \\ Config 4} \end{minipage}} &   without & 0.685 & 0.488 & 0.566 & 0.628 & \textbf{0.700} & \textbf{0.757} & 0.659 & \textbf{0.774} & 0.710 \\ 
        \midrule
        & with & \textbf{0.847} & 0.839 & 0.843 & 0.667 & 0.487 & 0.559 & 0.748 & 0.511 & 0.604 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 5 \\ Config 5} \end{minipage}} &   without & 0.579 & \textbf{0.542} & \textbf{0.556} & 0.690 & 0.660 & 0.601 & 0.735 & 0.677 & 0.702 \\ 
        \midrule 	
        & with & 0.830 & 0.930 & 0.864 & \textbf{0.705} & 0.415 & 0.510 & \textbf{0.768} & 0.523 & 0.618 \\
        \multirow{-2}{*}{\begin{minipage}{4cm}{\scriptsize Config 6 \\ Config 6} \end{minipage}} &   without & 0.748 & 0.394 & 0.507 & \textbf{0.695} & 0.654 & 0.668 & 0.747 & 0.656 & 0.695 \\ 
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Binary classification with RF and 10-fold cross validation}
    \label{tab:binRF}
\end{table}

\subsection{Summary}
In this section, the best configurations and classifiers along with their respective F1 scores are summarized as shown in Table \ref{tab:summaryBC}. For Apache Lucene dataset, the best classifier happens to be LR with Config 6 and F1 score of 0.889 to predict rationale based sentences while the same classifier with Config 1 gives an F1 score of 0.591 to classify non-rationale based sentences. SVM turns out to be the best classifier to predict rationale in datasets of Mozilla Thunderbird and Ubuntu. The configurations applied are Config 6 with an F1 score of 0.758 and Config 1 with an F1 score of 0.781. To predict non-rationale based sentences on Ubuntu dataset, LR with Config 1 gives a top score of 0.758 while RF with Config 4 tops the list to predict the same with a score of 0.757 on the dataset of Mozilla Thunderbird. 
\begin{table} %[hb!]
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \def\arraystretch{1} % 1 is the default, change whatever you need (line spacing)
    \begin{tabular}{p{4cm} p{2cm} p{2cm} p{2cm} p{2cm}}
        \toprule
        \textbf{Dataset} & \textbf{Rationale} & \textbf{Config} & \textbf{Classifier} & \textbf{F1 Score}\\
        \midrule
			Apache Lucene & with & Config 6 & LR & 0.889 \\
			Apache Lucene & without & Config 1 & LR & 0.591 \\
		\midrule
			Mozilla Thunderbird & with & Config 6 & SVM & 0.758 \\ 
			Mozilla Thunderbird & without & Config 4 & RF & 0.757 \\ 
		\midrule
			Ubuntu & with & Config 1 & SVM & 0.781 \\
			Ubuntu & without & Config 1 & LR & 0.758 \\
        \midrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Summary of binary classification}
    \label{tab:summaryBC}
\end{table}

\section{Fine Grained Classification}
This section presents the results of the fine grained classification experiments performed using the configurations mentioned in Table \ref{tab:configurationNames}, transformation methods from Section 2.4.3 and the algorithms from Section 2.4.4. Unlike  binary classification, all three datasets have used trigram tokenization. The scikit-learn library does not support Binary Relevance and Label Transformation methods and hence scikit-multilearn, a library specific for performing multi-class and multi-label classifications was used. However, the results were not impressive when compared to MEKA. In addition, a lot of classifiers along with certain configurations returned a value of 0. Therefore, the fine-grained classifications were perfomed using MEKA exclusively. 

\subsection{Logistic Regression}

\subsubsection{Binary Relevance}
When BR transformation method is applied with LR classifier on the dataset of Apache Lucene, Config 2 performs the best to predict decision element in terms of precision, recall and F1 score with the numbers being 0.879, 0.594 and 0.743 respectively. Config 4, similarly, has highest scores in all three departments when predicting pro-argument in a sentence with scores of 0.734, 0.370 and 0.535 respectively. However, when POS tagging configuration, Config 6, is applied, the best F1 scores for predicting issue, alternative and decision is achieved with scores of 0.457, 0.666 and 0.480 respectively. For the Mozilla Thunderbird dataset, top F1 scores were observed in three instances of classifying issue, alternative and decision with scores of 0.488, 0.410 and 0.416 when using Config 1. Additionally, Config 3 had the best F1 score of 0.512 to classify con-argument while pro-argument had an F1 score of 0.478 with Config 6. The best precision and recall scores were scattered across different configurations for all three datasets. Issue and decision had F1 scores of 0.582 and 0.748 when Config 2 was applied on the Ubuntu dataset; pro-argument and con-argument had scores of 0.471 and 0.297 when Config 3 was used and Config 6 provided an F1 score of 0.556 when classifying alternative related sentences. Table \ref{tab:fgcBRLR} presents the results in detail.
\begin{table}[h] %[hb!]
    %\resizebox{\textwidth}{!}{%
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \begin{tabular}{L{1.5cm} c ccc | ccc | ccc }
        \toprule
         \multirow{2}{*}{\textbf{Config}} &  \multirow{2}{*}{\textbf{Rationale}} & \multicolumn{3}{c}{\textbf{Lucene}} & \multicolumn{3}{c}{\textbf{Thunderbird}} & \multicolumn{3}{c}{\textbf{Ubuntu}}\\
        \cmidrule(l){3-5} \cmidrule(l){6-8} \cmidrule(l){9-11}
          &  & \textbf{Pr} &  \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} \\
        \midrule
        & issue         & 0.141 & 0.151 & 0.258 & 0.608 & 0.331 & \textbf{0.488} & 0.661 & 0.422 & 0.580 \\
        & alternative   & \textbf{0.674} & 0.528 & 0.657 & \textbf{0.618} & 0.260 & \textbf{0.410} & \textbf{0.625} & 0.268 & 0.421 \\
        & pro-argument  & 0.695 & 0.341 & 0.503 & 0.075 & 0.210 & 0.332 & \textbf{0.139} & 0.228 & 0.363 \\
        & con-argument  & 0.132 & 0.239 & 0.368 & 0.077 & 0.421 & 0.494 & 0.059 & 0.118 & 0.209 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 1 \\  Config 1 \\ Config 1 \\Config 1  \\ Config 1 } \end{minipage}}
        & decision      & 0.849 & 0.570 & 0.724 & 0.700 & 0.263 & \textbf{0.416} & 0.872 & 0.581 & 0.734 \\
        \midrule
        & issue         & 0.123 & 0.247 & 0.377 & \textbf{0.613} & 0.320 & 0.477 & 0.657 & \textbf{0.424} & \textbf{0.582} \\
        & alternative   & 0.674 & 0.528 & 0.657 & 0.602 & 0.250 & 0.397 & 0.638 & 0.271 & 0.424 \\
        & pro-argument  & 0.686 & 0.350 & 0.512 & 0.076 & \textbf{0.214} & 0.338 & 0.134 & 0.217 & 0.349 \\
        & con-argument  & 0.132 & 0.239 & 0.368 & 0.077 & 0.421 & 0.494 & 0.059 & 0.118 & 0.209 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 2 \\  Config 2 \\ Config 2 \\Config 2  \\ Config 2 } \end{minipage}}
        & decision      & \textbf{0.879} & \textbf{0.594} & \textbf{0.743} & 0.677 & 0.263 & 0.416 & 0.875 & \textbf{0.598} & \textbf{0.748} \\
        \midrule
        & issue         & 0.109 & 0.317 & 0.435 & 0.594 & 0.313 & 0.469 & 0.649 & 0.412 & 0.570 \\
        & alternative   & 0.671 & 0.528 & 0.656 & 0.534 & 0.229 & 0.370 & 0.259 & 0.251 & 0.390 \\
        & pro-argument  & 0.674 & 0.361 & 0.523 & 0.085 & 0.121 & 0.213 & 0.129 & 0.201 & 0.329 \\
        & con-argument  & 0.132 & 0.239 & 0.368 & 0.077 & \textbf{0.526} & \textbf{0.512} & 0.056 & 0.112 & 0.199 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 3 \\  Config 3 \\ Config 3 \\Config 3  \\ Config 3 } \end{minipage}}
        & decision      & 0.829 & 0.560 & 0.715 & 0.692 & 0.225 & 0.367 & \textbf{0.957} & 0.564 & 0.721 \\
        \midrule
        & issue         & \textbf{0.153} & 0.162 & 0.275 & 0.578 & 0.244 & 0.387 & \textbf{0.662} & 0.328 & 0.486 \\
        & alternative   & 0.658 & 0.504 & 0.637 & 0.561 & 0.180 & 0.303 & 0.581 & 0.105 & 0.190 \\
        & pro-argument  & \textbf{0.734} & \textbf{0.370} & \textbf{0.535} & 0.075 & 0.210 & 0.332 & 0.066 & \textbf{0.587} & \textbf{0.471} \\
        & con-argument  & 0.113 & \textbf{0.585} & 0.473 & 0.074 & 0.504 & 0.501 & \textbf{0.094} & \textbf{0.178} & \textbf{0.297} \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 4 \\  Config 4 \\ Config 4 \\Config 4  \\ Config 4 } \end{minipage}}
        & decision      & 0.838 & 0.527 & 0.688 & \textbf{0.944} & 0.213 & 0.350 & 0.890 & 0.556 & 0.714 \\
        \midrule
        & issue         & 0.153 & 0.162 & 0.275 & 0.578 & 0.244 & 0.387 & 0.662 & 0.328 & 0.486 \\
        & alternative   & 0.658 & 0.504 & 0.637 & 0.561 & 0.180 & 0.303 & 0.581 & 0.105 & 0.190 \\
        & pro-argument  & 0.734 & 0.370 & 0.535 & 0.075 & 0.210 & 0.332 & 0.066 & 0.587 & 0.471 \\
        & con-argument  & 0.113 & 0.585 & 0.473 & 0.074 & 0.504 & 0.501 & 0.094 & 0.178 & 0.297 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 5 \\  Config 5 \\ Config 5 \\Config 5  \\ Config 5 } \end{minipage}}
        & decision      & 0.838 & 0.527 & 0.688 & 0.944 & 0.213 & 0.350 & 0.890 & 0.556 & 0.714 \\
        \midrule
        & issue         & 0.118 & \textbf{0.340} & \textbf{0.457} & 0.323 & \textbf{0.607} & 0.479 & 0.645 & 0.402 & 0.561 \\
        & alternative   & 0.672 & \textbf{0.541} & \textbf{0.666} & 0.207 & \textbf{0.532} & 0.340 & 0.204 & \textbf{0.468} & \textbf{0.556} \\
        & pro-argument  & 0.665 & 0.333 & 0.494 & \textbf{0.598} & 0.072 & \textbf{0.478} & 0.103 & 0.159 & 0.270 \\
        & con-argument  & \textbf{0.137} & 0.366 & \textbf{0.480} & \textbf{0.820} & 0.076 & 0.322 & 0.058 & 0.112 & 0.199 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 6 \\  Config 6 \\ Config 6 \\Config 6  \\ Config 6 } \end{minipage}}
        & decision      & 0.848 & 0.565 & 0.720 & 0.175 & \textbf{0.737} & 0.298 & 0.918 & 0.573 & 0.728 \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{BR transformation method with LR classifier and 10-fold CV}
    \label{tab:fgcBRLR}
\end{table}

\subsubsection{Label Powerset}
For issue and alternative on Apache Lucene dataset, Config 2 returns the best precision of 0.371 and 0.657 as well as F1 scores of 0.430 and 0.736. With regards to classifying decision, recall of 0.676 and F1 score of 0.800 were achieved using Config 4. Config 6 topped all three metrics of precision, recall and F1 score when predicting pro-argument and con-argument with the F1 scores being 0.682 and 0.513. In case of the Mozilla Thunderbird dataset, Config 1 does the best in precision, recall as well as F1 when predicting alternative in a sentence with F1 score of 0.522. In addition, the same configuration also tops with an F1 score of 0.616 in case of classifying issues correctly. However, for other three rational elements, pro-argument, con-argument and decision, Config 2 gets the best F1 scores of 0.314, 0.352 and 0.490 respectively. Config 2 also attains top recall scores for all elements but alternative. In addition, in case of Ubuntu dataset, Config 2 yet again achieves best F1 scores on three occasions of issue, con-argument and decision with the numbers being 0.692, 0.431 and 0.772 respectively. Config 1 with an F1 score of 0.568 and Config 4 with an F1 score of 0.416 perform well in cases of alternative and pro-argument. Table \ref{tab:fgcLPLR} demonstrates the results in detail.
\begin{table}[h] %[hb!]
    %\resizebox{\textwidth}{!}{%
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \begin{tabular}{L{1.5cm} c ccc | ccc | ccc }
        \toprule
         \multirow{2}{*}{\textbf{Config}} &  \multirow{2}{*}{\textbf{Rationale}} & \multicolumn{3}{c}{\textbf{Lucene}} & \multicolumn{3}{c}{\textbf{Thunderbird}} & \multicolumn{3}{c}{\textbf{Ubuntu}}\\
        \cmidrule(l){3-5} \cmidrule(l){6-8} \cmidrule(l){9-11}
          &  & \textbf{Pr} &  \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} \\
        \midrule
        & issue         & 0.305 & 0.232 & 0.372 & 0.544 & 0.447 & \textbf{0.616} & 0.619 & 0.553 & 0.682 \\
        & alternative   & 0.656 & 0.652 & 0.729 & \textbf{0.578} & \textbf{0.360} & \textbf{0.522} & 0.534 & \textbf{0.407} & \textbf{0.568} \\
        & pro-argument  & 0.595 & 0.525 & 0.663 & \textbf{0.360} & 0.183 & 0.308 & 0.398 & 0.259 & 0.409 \\
        & con-argument  & 0.364 & 0.268 & 0.416 & 0.355 & 0.189 & 0.316 & 0.412 & 0.263 & 0.415 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 1 \\  Config 1 \\ Config 1 \\Config 1  \\ Config 1 } \end{minipage}}
        & decision      & 0.774 & 0.628 & 0.766 & 0.556 & 0.313 & 0.475 & 0.745 & 0.624 & 0.766 \\
        \midrule
        & issue         & \textbf{0.371} & 0.216 & \textbf{0.430} & 0.540 & \textbf{0.466} & 0.608 & \textbf{0.620} & 0.568 & \textbf{0.692} \\
        & alternative   & \textbf{0.657} & 0.617 & \textbf{0.736} & 0.571 & 0.339 & 0.500 & 0.549 & 0.385 & 0.548 \\
        & pro-argument  & 0.589 & 0.223 & 0.648 & 0.333 & \textbf{0.188} & \textbf{0.314} & 0.434 & 0.259 & 0.410 \\
        & con-argument  & 0.375 & 0.127 & 0.437 & \textbf{0.386} & \textbf{0.215} & \textbf{0.352} & \textbf{0.494} & \textbf{0.276} & \textbf{0.431} \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 2 \\  Config 2 \\ Config 2 \\Config 2  \\ Config 2 } \end{minipage}}
        & decision      & 0.774 & 0.527 & 0.791 & 0.542 & \textbf{0.325} & \textbf{0.490} & 0.763 & \textbf{0.632} & \textbf{0.772} \\
        \midrule
        & issue         & 0.371 & 0.216 & 0.430 & 0.540 & 0.466 & 0.608 & 0.620 & 0.568 & 0.692 \\
        & alternative   & 0.657 & 0.617 & 0.736 & 0.571 & 0.339 & 0.500 & 0.549 & 0.385 & 0.548 \\
        & pro-argument  & 0.589 & 0.223 & 0.648 & 0.333 & 0.188 & 0.314 & 0.434 & 0.259 & 0.410 \\
        & con-argument  & 0.375 & 0.127 & 0.437 & 0.386 & 0.215 & 0.352 & 0.494 & 0.276 & 0.431 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 3 \\  Config 3 \\ Config 3 \\Config 3  \\ Config 3 } \end{minipage}}
        & decision      & 0.774 & 0.527 & 0.791 & 0.542 & 0.325 & 0.490 & 0.763 & 0.632 & 0.772 \\
        \midrule
        & issue         & 0.350 & 0.274 & 0.424 & \textbf{0.549} & 0.380 & 0.535 & 0.603 & 0.469 & 0.616 \\
        & alternative   & 0.653 & 0.620 & 0.710 & 0.531 & 0.248 & 0.394 & \textbf{0.589} & 0.371 & 0.534 \\
        & pro-argument  & 0.593 & 0.501 & 0.644 & 0.286 & 0.134 & 0.235 & \textbf{0.435} & \textbf{0.265} & \textbf{0.416} \\
        & con-argument  & 0.329 & 0.201 & 0.331 & 0.368 & 0.140 & 0.246 & 0.474 & 0.243 & 0.390 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 4 \\  Config 4 \\ Config 4 \\Config 4  \\ Config 4 } \end{minipage}}
        & decision      & 0.737 & \textbf{0.676} & \textbf{0.800} & 0.667 & 0.300 & 0.461 & 0.725 & 0.632 & 0.772 \\
        \midrule
        & issue         & 0.350 & 0.274 & 0.424 & 0.549 & 0.380 & 0.535 & 0.603 & 0.469 & 0.616 \\
        & alternative   & 0.653 & 0.620 & 0.710 & 0.531 & 0.248 & 0.394 & 0.589 & 0.371 & 0.534 \\
        & pro-argument  & 0.593 & 0.501 & 0.644 & 0.286 & 0.134 & 0.235 & 0.435 & 0.265 & 0.416 \\
        & con-argument  & 0.329 & 0.201 & 0.331 & 0.368 & 0.140 & 0.246 & 0.474 & 0.243 & 0.390 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 5 \\  Config 5 \\ Config 5 \\Config 5  \\ Config 5 } \end{minipage}}
        & decision      & 0.737 & 0.676 & 0.800 & 0.667 & 0.300 & 0.461 & 0.725 & 0.632 & 0.772 \\
        \midrule
        & issue         & 0.355 & \textbf{0.278} & 0.429 & 0.524 & 0.456 & 0.598 & 0.602 & \textbf{0.569} & 0.690 \\
        & alternative   & 0.647 & \textbf{0.671} & 0.735 & 0.517 & 0.306 & 0.462 & 0.546 & 0.376 & 0.538 \\
        & pro-argument  & \textbf{0.613} & \textbf{0.549} & \textbf{0.682} & 0.277 & 0.147 & 0.256 & 0.377 & 0.212 & 0.348 \\
        & con-argument  & \textbf{0.455} & \textbf{0.352} & \textbf{0.513} & 0.324 & 0.193 & 0.322 & 0.417 & 0.230 & 0.373 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 6 \\  Config 6 \\ Config 6 \\Config 6  \\ Config 6 } \end{minipage}}
        & decision      & \textbf{0.788} & 0.647 & 0.781 & \textbf{0.722} & 0.325 & 0.490 & \textbf{0.771} & 0.632 & 0.772 \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{LP transformation method with LR classifier and 10-fold CV}
    \label{tab:fgcLPLR}
\end{table}

\subsection{Multinomial Naive Bayes}

\subsubsection{Binary Relevance}
Config 1 has best precision for all five rationale elements when applied on the Apache Lucene dataset while Config 6 had best recall in three occasions. Config 1 has top F1 score of 0.768 for predicting alternative, Config 4 has F1 score of 0.860 to classify decision, Config 4 has F1 score of 0.525 in case of predicting issue while Config 6 have F1 scores of 0.750 and 0.664 for pro-argument and con-argument prediction. Precision on Mozilla Thunderbird dataset is the same as that on Apache Lucene dataset; Config 1 attains highest precision scores for all five rationale elements. Config 4 does its best in predicting pro-argument and decision with F1 scores of 0.619 and 0.648 while Config 6 achieves F1 scores of 0.673, 0.703 and 0.644 with respect to issue, alternative and con-argument respectively. In case of the Ubuntu dataset, Config 4 gives the best recall while predicting all five rationale elements. With F1 scores of 0.749, 0.713 and 0.784 in the case of issue, alternative and decision, Config 2 performs the best while Config 4 does the best with scores of 0.622 and 0.664 for predicting pro-argument and con-argument. Table \ref{tab:fgcBRMNB} shows all the values in detail.

\begin{table}[h] %[hb!]
    %\resizebox{\textwidth}{!}{%
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \begin{tabular}{L{1.5cm} c ccc | ccc | ccc }
        \toprule
         \multirow{2}{*}{\textbf{Config}} &  \multirow{2}{*}{\textbf{Rationale}} & \multicolumn{3}{c}{\textbf{Lucene}} & \multicolumn{3}{c}{\textbf{Thunderbird}} & \multicolumn{3}{c}{\textbf{Ubuntu}}\\
        \cmidrule(l){3-5} \cmidrule(l){6-8} \cmidrule(l){9-11}
          &  & \textbf{Pr} &  \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} \\
        \midrule
        & issue         & \textbf{0.575} & 0.089 & 0.163 & \textbf{0.654} & 0.383 & 0.543 & \textbf{0.672} & 0.534 & 0.674 \\
        & alternative   & \textbf{0.629} & 0.767 & \textbf{0.768} & \textbf{0.772} & 0.308 & 0.469 & \textbf{0.676} & 0.295 & 0.453 \\
        & pro-argument  & \textbf{0.693} & 0.453 & 0.612 & \textbf{0.556} & 0.045 & 0.085 & \textbf{0.538} & 0.074 & 0.138 \\
        & con-argument  & \textbf{0.640} & 0.113 & 0.202 & \textbf{0.735} & 0.110 & 0.198 & \textbf{0.682} & 0.099 & 0.180 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 1 \\  Config 1 \\ Config 1 \\Config 1  \\ Config 1 } \end{minipage}}
        & decision      & \textbf{0.926} & 0.483 & 0.651 & \textbf{0.769} & 0.125 & 0.222 & 0.922 & 0.404 & 0.670 \\
        \midrule
        & issue         & 0.383 & 0.266 & 0.416 & 0.491 & 0.569 & 0.669 & 0.540 & 0.700 & \textbf{0.749} \\
        & alternative   & 0.584 & 0.755 & 0.740 & 0.479 & 0.552 & 0.681 & 0.477 & 0.595 & \textbf{0.712} \\
        & pro-argument  & 0.501 & 0.641 & 0.719 & 0.292 & 0.353 & 0.512 & 0.288 & 0.397 & 0.556 \\
        & con-argument  & 0.321 & 0.468 & 0.609 & 0.309 & 0.390 & 0.550 & 0.228 & 0.375 & 0.534 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 2 \\  Config 2 \\ Config 2 \\Config 2  \\ Config 2 } \end{minipage}}
        & decision      & 0.606 & 0.758 & 0.845 & 0.293 & 0.425 & 0.592 & 0.724 & 0.650 & \textbf{0.784} \\
        \midrule
        & issue         & 0.383 & 0.266 & 0.416 & 0.491 & 0.569 & 0.669 & 0.540 & 0.700 & 0.749 \\
        & alternative   & 0.584 & 0.755 & 0.740 & 0.479 & 0.552 & 0.681 & 0.477 & 0.595 & 0.712 \\
        & pro-argument  & 0.501 & 0.641 & 0.719 & 0.292 & 0.353 & 0.512 & 0.288 & 0.397 & 0.556 \\
        & con-argument  & 0.321 & 0.468 & 0.609 & 0.309 & 0.390 & 0.550 & 0.228 & 0.375 & 0.534 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 3 \\  Config 3 \\ Config 3 \\Config 3  \\ Config 3 } \end{minipage}}
        & decision      & 0.606 & 0.758 & 0.845 & 0.293 & 0.425 & 0.592 & 0.724 & 0.650 & 0.784 \\
        \midrule
        & issue         & 0.303 & \textbf{0.371} & \textbf{0.525} & 0.453 & 0.589 & 0.668 & 0.491 & \textbf{0.710} & 0.734 \\
        & alternative   & 0.574 & 0.777 & 0.739 & 0.393 & 0.605 & 0.699 & 0.342 & \textbf{0.637} & 0.704 \\
        & pro-argument  & 0.450 & 0.689 & 0.723 & 0.216 & \textbf{0.482} & \textbf{0.619} & 0.187 & \textbf{0.492} & \textbf{0.622} \\
        & con-argument  & 0.229 & 0.461 & 0.584 & 0.219 & 0.465 & 0.605 & 0.172 & \textbf{0.546} & \textbf{0.664} \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 4 \\  Config 4 \\ Config 4 \\Config 4  \\ Config 4 } \end{minipage}}
        & decision      & 0.471 & \textbf{0.812} & \textbf{0.860} & 0.145 & \textbf{0.500} & \textbf{0.648} & 0.576 & \textbf{0.581} & 0.730 \\
        \midrule
        & issue         & 0.303 & 0.371 & 0.525 & 0.453 & 0.589 & 0.668 & 0.491 & 0.710 & 0.734 \\
        & alternative   & 0.574 & 0.777 & 0.739 & 0.393 & 0.605 & 0.699 & 0.342 & 0.637 & 0.704 \\
        & pro-argument  & 0.450 & 0.689 & 0.723 & 0.216 & 0.482 & 0.619 & 0.187 & 0.492 & 0.622 \\
        & con-argument  & 0.229 & 0.461 & 0.584 & 0.219 & 0.465 & 0.605 & 0.172 & 0.546 & 0.664 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 5 \\  Config 5 \\ Config 5 \\Config 5  \\ Config 5 } \end{minipage}}
        & decision      & 0.471 & 0.812 & 0.860 & 0.145 & 0.500 & 0.648 & 0.576 & 0.581 & 0.730 \\
        \midrule
        & issue         & 0.319 & 0.350 & 0.495 & 0.458 & \textbf{0.594} & \textbf{0.673} & 0.549 & 0.691 & 0.748 \\
        & alternative   & 0.549 & \textbf{0.816} & 0.728 & 0.385 & \textbf{0.618} & \textbf{0.703} & 0.442 & 0.549 & 0.676 \\
        & pro-argument  & 0.444 & \textbf{0.783} & \textbf{0.750} & 0.195 & 0.429 & 0.572 & 0.299 & 0.201 & 0.333 \\
        & con-argument  & 0.249 & \textbf{0.585} & \textbf{0.664} & 0.233 & \textbf{0.513} & \textbf{0.644} & 0.341 & 0.382 & 0.546 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 6 \\  Config 6 \\ Config 6 \\Config 6  \\ Config 6 } \end{minipage}}
        & decision      & 0.546 & 0.749 & 0.835 & 0.205 & 0.450 & 0.611 & \textbf{0.931} & 0.573 & 0.728 \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{BR transformation method with MNB classifier and 10-fold CV}
    \label{tab:fgcBRMNB}
\end{table}

\subsubsection{Label Powerset}
For the Apache Lucene dataset, top recall and F1 scores are achieved using Config 2 for issue, pro-argument and con-argument; the F1 scores are 0.430, 0.712 and 0.604 respectively. While Config 6 helps attaining an F1 score of 0.750 in predicting alternative, Config 4 helps in predicting decision with an F1 score of 0.842. Unlike previous instances, Mozilla Thunderbird has F1 scores of 0.690 in applying Config 1 to predict issue, 0.683, 0.524 and 0.602 in applying Config 2 to predict alternative, pro-argument and con-argument, 0.610 with Config 4 to predict decision. Config 1 and Config 2 also tops for similar rationale elements in the case of Ubuntu dataset with scores of 0.771, 0.706 and 0.552 for issue, alternative and con-argument. Config 3 predicts decision the best with an F1 score of 0.733 while Config 5 classified pro-argument well with an F1 score of 0.556. Table \ref{tab:fgcLPMNB} gives a summary of all the scores in detail.

\begin{table}[h] %[hb!]
    %\resizebox{\textwidth}{!}{%
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \begin{tabular}{L{1.5cm} c ccc | ccc | ccc }
        \toprule
         \multirow{2}{*}{\textbf{Config}} &  \multirow{2}{*}{\textbf{Rationale}} & \multicolumn{3}{c}{\textbf{Lucene}} & \multicolumn{3}{c}{\textbf{Thunderbird}} & \multicolumn{3}{c}{\textbf{Ubuntu}}\\
        \cmidrule(l){3-5} \cmidrule(l){6-8} \cmidrule(l){9-11}
          &  & \textbf{Pr} &  \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} \\
        \midrule
        & issue         & 0.378 & 0.270 & 0.421 & 0.493 & \textbf{0.606} & \textbf{0.690} & 0.546 & \textbf{0.748} & \textbf{0.771} \\
        & alternative   & 0.590 & 0.769 & 0.747 & 0.550 & 0.407 & 0.568 & \textbf{0.557} & 0.344 & 0.505 \\
        & pro-argument  & 0.582 & 0.580 & 0.700 & \textbf{0.342} & 0.116 & 0.208 & 0.380 & 0.101 & 0.182 \\
        & con-argument  & 0.453 & 0.236 & 0.379 & 0.344 & 0.145 & 0.252 & 0.475 & 0.125 & 0.222 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 1 \\  Config 1 \\ Config 1 \\Config 1  \\ Config 1 } \end{minipage}}
        & decision      & 0.693 & 0.599 & 0.742 & 0.500 & 0.250 & 0.399 & 0.873 & 0.530 & 0.692 \\
        \midrule
        & issue         & 0.379 & \textbf{0.278} & \textbf{0.430} & 0.487 & 0.546 & 0.654 & 0.563 & 0.636 & 0.723 \\
        & alternative   & 0.592 & 0.705 & 0.728 & 0.373 & \textbf{0.587} & \textbf{0.683} & 0.384 & \textbf{0.615} & \textbf{0.706} \\
        & pro-argument  & 0.508 & \textbf{0.624} & \textbf{0.712} & 0.214 & \textbf{0.371} & \textbf{0.524} & 0.250 & 0.381 & 0.538 \\
        & con-argument  & 0.290 & \textbf{0.468} & \textbf{0.604} & 0.240 & \textbf{0.456} & \textbf{0.602} & 0.222 & 0.395 & \textbf{0.552} \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 2 \\  Config 2 \\ Config 2 \\Config 2  \\ Config 2 } \end{minipage}}
        & decision      & 0.626 & 0.734 & 0.832 & 0.224 & 0.438 & 0.601 & 0.773 & \textbf{0.581} & 0.733 \\
        \midrule
        & issue         & 0.371 & 0.216 & 0.430 & \textbf{0.540} & 0.466 & 0.608 & \textbf{0.620} & 0.568 & 0.692 \\
        & alternative   & \textbf{0.657} & 0.617 & 0.736 & \textbf{0.571} & 0.339 & 0.500 & 0.549 & 0.385 & 0.548 \\
        & pro-argument  & 0.589 & 0.223 & 0.648 & 0.333 & 0.188 & 0.314 & 0.434 & 0.259 & 0.410 \\
        & con-argument  & 0.375 & 0.127 & 0.437 & 0.386 & 0.215 & 0.352 & \textbf{0.494} & 0.276 & 0.431 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 3 \\  Config 3 \\ Config 3 \\Config 3  \\ Config 3 } \end{minipage}}
        & decision      & 0.626 & 0.734 & 0.832 & 0.224 & 0.438 & 0.601 & 0.773 & 0.581 & \textbf{0.733} \\
        \midrule
        & issue         & 0.371 & 0.216 & 0.430 & 0.540 & 0.466 & 0.608 & 0.620 & 0.568 & 0.692 \\
        & alternative   & 0.657 & 0.617 & 0.736 & 0.571 & 0.339 & 0.500 & 0.549 & 0.385 & 0.548 \\
        & pro-argument  & \textbf{0.589} & 0.223 & 0.648 & 0.333 & 0.188 & 0.314 & 0.434 & 0.259 & 0.410 \\
        & con-argument  & 0.375 & 0.127 & 0.437 & 0.386 & 0.215 & 0.352 & 0.494 & 0.276 & 0.431 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 4 \\  Config 4 \\ Config 4 \\Config 4  \\ Config 4 } \end{minipage}}
        & decision      & 0.561 & \textbf{0.758} & \textbf{0.842} & 0.185 & \textbf{0.450} & \textbf{0.610} & 0.593 & 0.573 & 0.724 \\
        \midrule
        & issue         & 0.359 & 0.270 & 0.420 & 0.461 & 0.475 & 0.602 & 0.550 & 0.531 & 0.656 \\
        & alternative   & 0.609 & 0.665 & 0.719 & 0.363 & 0.562 & 0.666 & 0.367 & 0.571 & 0.676 \\
        & pro-argument  & 0.491 & 0.589 & 0.688 & 0.196 & 0.362 & 0.513 & 0.226 & \textbf{0.402} & \textbf{0.556} \\
        & con-argument  & 0.257 & 0.366 & 0.514 & 0.233 & 0.417 & 0.568 & 0.163 & 0.283 & 0.432 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 5 \\  Config 5 \\ Config 5 \\Config 5  \\ Config 5 } \end{minipage}}
        & decision      & 0.561 & 0.758 & 0.842 & 0.185 & 0.450 & 0.610 & 0.593 & 0.573 & 0.724 \\
        \midrule
        & issue         & \textbf{0.383} & 0.239 & 0.383 & 0.490 & 0.581 & 0.676 & 0.534 & 0.734 & 0.761 \\
        & alternative   & 0.592 & \textbf{0.773} & \textbf{0.750} & 0.516 & 0.370 & 0.530 & 0.549 & 0.371 & 0.533 \\
        & pro-argument  & 0.573 & 0.564 & 0.687 & 0.316 & 0.112 & 0.200 & \textbf{0.447} & 0.090 & 0.165 \\
        & con-argument  & \textbf{0.455} & 0.299 & 0.456 & \textbf{0.423} & 0.193 & 0.322 & 0.400 & 0.092 & 0.169 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 6 \\  Config 6 \\ Config 6 \\Config 6  \\ Config 6 } \end{minipage}}
        & decision      & \textbf{0.726} & 0.614 & 0.754 & \textbf{0.643} & 0.225 & 0.367 & \textbf{0.928} & 0.547 & 0.707 \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{LP transformation method with MNB classifier and 10-fold CV}
    \label{tab:fgcLPMNB}
\end{table}

\subsection{Support Vector Machine}

\subsubsection{Binary Relevance}
Config 2 helps attaining top scores of precision in all rationale elements but alternative when applied on Apache Lucene dataset. However, Config 1 provides top scores for recall as well as F1 for all five rationale elements on the same dataset. The F1 scores are 0.462, 0.742, 0.708, 0.553 and 0.812 for issue, alternative, pro-argument, con.argument and decision respectively. The F1 scores are the highest even in the case of Mozilla Thunderbird and Ubuntu dataset for all rationale elements except decision. The scores are 0.688, 0.649, 0.441 and 0.526 for issue, alternative, pro-argument and con-argument in the case of Mozilla Thunderbird dataset. Similarly, the scores are 0.740, 0.666, 0.429 and 0.447 in the case of Ubuntu dataset. However, Config 6 helps in classifying decision elements with scores of 0.504 and 0.809 on Mozilla Thunderbird and Ubuntu dataset respectively. Table \ref{tab:fgcBRSVM} presents the values of all the metrics in detail.
\begin{table}[h] %[hb!]
    %\resizebox{\textwidth}{!}{%
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \begin{tabular}{L{1.5cm} c ccc | ccc | ccc }
        \toprule
         \multirow{2}{*}{\textbf{Config}} &  \multirow{2}{*}{\textbf{Rationale}} & \multicolumn{3}{c}{\textbf{Lucene}} & \multicolumn{3}{c}{\textbf{Thunderbird}} & \multicolumn{3}{c}{\textbf{Ubuntu}}\\
        \cmidrule(l){3-5} \cmidrule(l){6-8} \cmidrule(l){9-11}
          &  & \textbf{Pr} &  \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} \\
        \midrule
        & issue         & 0.427 & \textbf{0.305} & \textbf{0.462} & \textbf{0.625} & \textbf{0.560} & \textbf{0.688} & \textbf{0.688} & \textbf{0.624} & \textbf{0.740} \\
        & alternative   & \textbf{0.709} & \textbf{0.651} & \textbf{0.742} & \textbf{0.602} & \textbf{0.496} & \textbf{0.649} & 0.652 & \textbf{0.512} & \textbf{0.666} \\
        & pro-argument  & 0.645 & \textbf{0.580} & \textbf{0.708} & 0.413 & \textbf{0.286} & \textbf{0.441} & 0.441 & \textbf{0.275} & \textbf{0.429} \\
        & con-argument  & 0.474 & \textbf{0.391} & \textbf{0.553} & 0.547 & \textbf{0.360} & \textbf{0.526} & 0.449 & 0.289 & \textbf{0.447} \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 1 \\  Config 1 \\ Config 1 \\Config 1  \\ Config 1 } \end{minipage}}
        & decision      & 0.808 & \textbf{0.691} & \textbf{0.812} & 0.743 & 0.325 & 0.490 & 0.813 & 0.667 & 0.798 \\
        \midrule
        & issue         & \textbf{0.437} & 0.266 & 0.417 & 0.614 & 0.499 & 0.642 & 0.643 & 0.559 & 0.689 \\
        & alternative   & 0.699 & 0.626 & 0.725 & 0.587 & 0.455 & 0.613 & \textbf{0.667} & 0.459 & 0.621 \\
        & pro-argument  & \textbf{0.671} & 0.556 & 0.694 & \textbf{0.476} & 0.263 & 0.415 & \textbf{0.540} & 0.249 & 0.397 \\
        & con-argument  & \textbf{0.507} & 0.359 & 0.522 & \textbf{0.566} & 0.320 & 0.483 & \textbf{0.470} & 0.257 & 0.407 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 2 \\  Config 2 \\ Config 2 \\Config 2  \\ Config 2 } \end{minipage}}
        & decision      & \textbf{0.839} & 0.562 & 0.786 & \textbf{0.788} & 0.325 & 0.490 & 0.846 & 0.658 & 0.792 \\
        \midrule
        & issue         & 0.437 & 0.266 & 0.417 & 0.614 & 0.499 & 0.642 & 0.643 & 0.559 & 0.689 \\
        & alternative   & 0.699 & 0.626 & 0.725 & 0.587 & 0.455 & 0.613 & 0.667 & 0.459 & 0.621 \\
        & pro-argument  & 0.671 & 0.556 & 0.694 & 0.476 & 0.263 & 0.415 & 0.540 & 0.249 & 0.397 \\
        & con-argument  & 0.507 & 0.359 & 0.522 & 0.566 & 0.320 & 0.483 & 0.470 & 0.257 & 0.407 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 3 \\  Config 3 \\ Config 3 \\Config 3  \\ Config 3 } \end{minipage}}
        & decision      & 0.839 & 0.562 & 0.786 & 0.788 & 0.325 & 0.490 & 0.846 & 0.658 & 0.792 \\
        \midrule
        & issue         & 0.428 & 0.228 & 0.369 & 0.580 & 0.418 & 0.571 & 0.646 & 0.473 & 0.624 \\
        & alternative   & 0.693 & 0.583 & 0.698 & 0.571 & 0.399 & 0.561 & 0.567 & 0.371 & 0.534 \\
        & pro-argument  & 0.664 & 0.516 & 0.662 & 0.391 & 0.201 & 0.333 & 0.358 & 0.201 & 0.333 \\
        & con-argument  & 0.432 & 0.225 & 0.365 & 0.432 & 0.237 & 0.381 & 0.333 & 0.171 & 0.291 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 4 \\  Config 4 \\ Config 4 \\Config 4  \\ Config 4 } \end{minipage}}
        & decision      & 0.763 & 0.638 & 0.773 & 0.735 & 0.313 & 0.476 & \textbf{0.855} & 0.607 & 0.754 \\
        \midrule
        & issue         & 0.428 & 0.228 & 0.369 & 0.580 & 0.418 & 0.571 & 0.646 & 0.473 & 0.624 \\
        & alternative   & 0.693 & 0.583 & 0.698 & 0.571 & 0.399 & 0.561 & 0.567 & 0.371 & 0.534 \\
        & pro-argument  & 0.664 & 0.516 & 0.662 & 0.391 & 0.201 & 0.333 & 0.358 & 0.201 & 0.333 \\
        & con-argument  & 0.432 & 0.225 & 0.365 & 0.432 & 0.237 & 0.381 & 0.333 & 0.171 & 0.291 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 5 \\  Config 5 \\ Config 5 \\Config 5  \\ Config 5 } \end{minipage}}
        & decision      & 0.763 & 0.638 & 0.773 & 0.735 & 0.313 & 0.476 & 0.855 & 0.607 & 0.754 \\
        \midrule
        & issue         & 0.336 & 0.274 & 0.424 & 0.555 & 0.463 & 0.607 & 0.621 & 0.571 & 0.694 \\
        & alternative   & 0.668 & 0.626 & 0.718 & 0.537 & 0.421 & 0.581 & 0.540 & 0.424 & 0.584 \\
        & pro-argument  & 0.633 & 0.569 & 0.699 & 0.244 & 0.179 & 0.301 & 0.400 & 0.254 & 0.403 \\
        & con-argument  & 0.420 & 0.359 & 0.519 & 0.372 & 0.294 & 0.450 & 0.431 & \textbf{0.368} & 0.534 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 6 \\  Config 6 \\ Config 6 \\Config 6  \\ Config 6 } \end{minipage}}
        & decision      & 0.732 & 0.647 & 0.779 & 0.519 & \textbf{0.338} & \textbf{0.504} & 0.755 & \textbf{0.684} & \textbf{0.809} \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{BR transformation method with SVM classifier and 10-fold CV}
    \label{tab:fgcBRSVM}
\end{table}

\subsubsection{Label Powerset}
For the dataset of Apache Lucene, Config 1 gives best F1 scores of 0.397 and 0.760 for classifying issue and alternative, Config 6 gives scores of 0.690 and 0.563 for classifying pro-argument and con-argument, and Config 4 gives a top score of 0.790 for predicting decision element in a sentence. However, in the case of datasets of Mozilla Thunderbird and Ubuntu, the topmost recall and F1 scores are achieved using Config 1. The F1 scores for issue, alternative, pro-argument, con-argument and decision are 0.637, 0.645, 0.434, 0.500 and 0.517 for Mozilla Thunderbird while Ubuntu has scores of 0.693, 0.653, 0.435, 0.507 and 0.821. Table \ref{tab:fgcLPSVM} presents the summary of all the metrics and its values.

\begin{table}[h] %[hb!]
    %\resizebox{\textwidth}{!}{%
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \begin{tabular}{L{1.5cm} c ccc | ccc | ccc }
        \toprule
         \multirow{2}{*}{\textbf{Config}} &  \multirow{2}{*}{\textbf{Rationale}} & \multicolumn{3}{c}{\textbf{Lucene}} & \multicolumn{3}{c}{\textbf{Thunderbird}} & \multicolumn{3}{c}{\textbf{Ubuntu}}\\
        \cmidrule(l){3-5} \cmidrule(l){6-8} \cmidrule(l){9-11}
          &  & \textbf{Pr} &  \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} \\
        \midrule
        & issue         & 0.351 & \textbf{0.251} & \textbf{0.397} & \textbf{0.611} & \textbf{0.493} & \textbf{0.637} & 0.635 & \textbf{0.566} & \textbf{0.693} \\
        & alternative   & 0.671 & \textbf{0.705} & \textbf{0.760} & \textbf{0.521} & \textbf{0.498} & \textbf{0.645} & 0.555 & \textbf{0.502} & \textbf{0.653} \\
        & pro-argument  & 0.596 & 0.549 & 0.680 & 0.301 & \textbf{0.281} & \textbf{0.434} & 0.366 & \textbf{0.280} & \textbf{0.435} \\
        & con-argument  & 0.444 & 0.366 & 0.527 & 0.425 & \textbf{0.338} & \textbf{0.500} & 0.448 & \textbf{0.342} & \textbf{0.507} \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 1 \\  Config 1 \\ Config 1 \\Config 1  \\ Config 1 } \end{minipage}}
        & decision      & \textbf{0.836} & 0.643 & 0.779 & 0.538 & \textbf{0.350 } & \textbf{0.517} & 0.774 & \textbf{0.701} & \textbf{0.821} \\
        \midrule
        & issue         & 0.351 & 0.251 & 0.397 & 0.611 & 0.493 & 0.637 & 0.635 & 0.566 & 0.693 \\
        & alternative   & 0.671 & 0.705 & 0.760 & 0.521 & 0.498 & 0.645 & 0.555 & 0.502 & 0.653 \\
        & pro-argument  & 0.596 & 0.549 & 0.680 & 0.301 & 0.281 & 0.434 & 0.366 & 0.280 & 0.435 \\
        & con-argument  & 0.444 & 0.366 & 0.527 & 0.425 & 0.338 & 0.500 & 0.448 & 0.342 & 0.507 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 2 \\  Config 2 \\ Config 2 \\Config 2  \\ Config 2 } \end{minipage}}
        & decision      & 0.836 & 0.643 & 0.779 & 0.538 & 0.350 & 0.517 & 0.774 & 0.701 & 0.821 \\
        \midrule
        & issue         & 0.351 & 0.251 & 0.397 & 0.611 & 0.493 & 0.637 & 0.635 & 0.566 & 0.693 \\
        & alternative   & 0.671 & 0.705 & 0.760 & 0.521 & 0.498 & 0.645 & 0.555 & 0.502 & 0.653 \\
        & pro-argument  & 0.596 & 0.549 & 0.680 & 0.301 & 0.281 & 0.434 & 0.366 & 0.280 & 0.435 \\
        & con-argument  & 0.444 & 0.366 & 0.527 & 0.425 & 0.338 & 0.500 & 0.448 & 0.342 & 0.507 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 3 \\  Config 3 \\ Config 3 \\Config 3  \\ Config 3 } \end{minipage}}
        & decision      & 0.836 & 0.643 & 0.779 & 0.538 & 0.350 & 0.517 & 0.774 & 0.701 & 0.821 \\
        \midrule
        & issue         & \textbf{0.373} & 0.228 & 0.368 & 0.555 & 0.434 & 0.583 & \textbf{0.660} & 0.546 & 0.682 \\
        & alternative   & \textbf{0.678} & 0.636 & 0.726 & 0.521 & 0.413 & 0.572 & \textbf{0.566} & 0.441 & 0.601 \\
        & pro-argument  & 0.596 & 0.475 & 0.624 & \textbf{0.425} & 0.228 & 0.369 & \textbf{0.455} & 0.212 & 0.348 \\
        & con-argument  & 0.460 & 0.222 & 0.361 & \textbf{0.484} & 0.268 & 0.420 & 0.453 & 0.191 & 0.320 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 4 \\  Config 4 \\ Config 4 \\Config 4  \\ Config 4 } \end{minipage}}
        & decision      & 0.761 & \textbf{0.662} & \textbf{0.790} & 0.538 & 0.338 & 0.504 & \textbf{0.862} & 0.641 & 0.780 \\
        \midrule
        & issue         & 0.373 & 0.228 & 0.368 & 0.555 & 0.434 & 0.583 & 0.660 & 0.546 & 0.682 \\
        & alternative   & 0.678 & 0.636 & 0.726 & 0.521 & 0.413 & 0.572 & 0.566 & 0.441 & 0.601 \\
        & pro-argument  & 0.596 & 0.475 & 0.624 & 0.425 & 0.228 & 0.369 & 0.455 & 0.212 & 0.348 \\
        & con-argument  & 0.460 & 0.222 & 0.361 & 0.484 & 0.268 & 0.420 & 0.453 & 0.191 & 0.320 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 5 \\  Config 5 \\ Config 5 \\Config 5  \\ Config 5 } \end{minipage}}
        & decision      & 0.761 & 0.662 & 0.790 & 0.538 & 0.338 & 0.504 & 0.862 & 0.641 & 0.780 \\
        \midrule
        & issue         & 0.359 & 0.251 & 0.397 & 0.566 & 0.463 & 0.609 & 0.618 & 0.549 & 0.679 \\
        & alternative   & 0.662 & 0.703 & 0.755 & 0.490 & 0.479 & 0.627 & 0.525 & 0.485 & 0.636 \\
        & pro-argument  & \textbf{0.609} & \textbf{0.560} & \textbf{0.690} & 0.268 & 0.232 & 0.373 & 0.371 & 0.275 & 0.428 \\
        & con-argument  & \textbf{0.473} & \textbf{0.401} & \textbf{0.563} & 0.424 & 0.320 & 0.481 & \textbf{0.477} & 0.342 & 0.507 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 6 \\  Config 6 \\ Config 6 \\Config 6  \\ Config 6 } \end{minipage}}
        & decision      & 0.809 & 0.614 & 0.757 & \textbf{0.703} & 0.325 & 0.490 & 0.765 & 0.667 & 0.797 \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{LP transformation method with SVM classifier and 10-fold CV}
    \label{tab:fgcLPSVM}
\end{table}

\subsection{Decision Tree}

\subsubsection{Binary Relevance}
On the Apache Lucene dataset, Config 2 gives the top F1 scores of 0.162 and 0.667 for con-argument and decision while Config 4 helps getting the best F1 scores of 0.067, 0.635 and 0.519 for issue, alternative and pro-argument. It also gives the top recall scores for similar rationale elements. For Mozilla Thunderbird dataset, scores of 0.252 and 0.043 were attained using Config 3 for alternative and con-argument while scores of 0.413, 0.077 and 0.280 were achieved in the case of issue, pro-argument and decision with Config 4. On the Ubuntu dataset, Config 3 helped attain an F1 score of 0.165 for predicting pro-argument element, Config 4 for issue and con-argument with scores of 0.509 and 0.076, and Config 6 for alternative and decision with scores of 0.232 and 0.714 respectively. Table \ref{tab:fgcBRDT} demonstrates all the values of the metrics in detail.
\begin{table}[h] %[hb!]
    %\resizebox{\textwidth}{!}{%
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \begin{tabular}{L{1.5cm} c ccc | ccc | ccc }
        \toprule
         \multirow{2}{*}{\textbf{Config}} &  \multirow{2}{*}{\textbf{Rationale}} & \multicolumn{3}{c}{\textbf{Lucene}} & \multicolumn{3}{c}{\textbf{Thunderbird}} & \multicolumn{3}{c}{\textbf{Ubuntu}}\\
        \cmidrule(l){3-5} \cmidrule(l){6-8} \cmidrule(l){9-11}
          &  & \textbf{Pr} &  \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} \\
        \midrule
        & issue         & 0.571 & 0.031 & 0.060 & 0.526 & 0.229 & 0.368 & 0.553 & 0.320 & 0.474 \\
        & alternative   & 0.618 & 0.473 & 0.608 & 0.436 & 0.134 & 0.236 & 0.471 & 0.100 & 0.181 \\
        & pro-argument  & 0.693 & 0.333 & 0.495 & 0.438 & 0.031 & 0.061 & \textbf{0.583} & 0.074 & 0.138 \\
        & con-argument  & 0.391 & 0.088 & 0.162 & 0.188 & 0.013 & 0.026 & 0.250 & 0.020 & 0.039 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 1 \\  Config 1 \\ Config 1 \\Config 1  \\ Config 1 } \end{minipage}}
        & decision      & \textbf{0.852} & \textbf{0.502} & 0.667 & 0.917 & 0.138 & 0.242 & 0.897 & 0.521 & 0.685 \\
        \midrule
        & issue         & 0.571 & 0.031 & 0.060 & 0.526 & 0.229 & 0.368 & 0.553 & 0.320 & 0.474 \\
        & alternative   & 0.618 & 0.473 & 0.608 & 0.436 & 0.134 & 0.236 & 0.471 & 0.100 & 0.181 \\
        & pro-argument  & 0.693 & 0.333 & 0.495 & 0.438 & 0.031 & 0.061 & 0.583 & 0.074 & 0.138 \\
        & con-argument  & 0.391 & 0.088 & \textbf{0.162} & 0.188 & 0.013 & 0.026 & 0.250 & 0.020 & 0.039 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 2 \\  Config 2 \\ Config 2 \\Config 2  \\ Config 2 } \end{minipage}}
        & decision      & 0.852 & 0.502 & \textbf{0.667} & 0.917 & 0.138 & 0.242 & 0.897 & 0.521 & 0.685 \\
        \midrule
        & issue         & 0.412 & 0.027 & 0.053 & 0.524 & 0.260 & 0.406 & 0.540 & 0.328 & 0.481 \\
        & alternative   & 0.623 & 0.452 & 0.592 & 0.446 & \textbf{0.145} & \textbf{0.252} & 0.455 & 0.085 & 0.157 \\
        & pro-argument  & 0.696 & 0.337 & 0.499 & 0.438 & 0.031 & 0.061 & 0.425 & \textbf{0.090} & \textbf{0.165} \\
        & con-argument  & 0.426 & 0.081 & 0.150 & 0.227 & \textbf{0.022} & \textbf{0.043} & 0.333 & 0.026 & 0.051 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 3 \\  Config 3 \\ Config 3 \\Config 3  \\ Config 3 } \end{minipage}}
        & decision      & 0.851 & 0.498 & 0.663 & \textbf{1.000} & \textbf{0.163} & 0.280 & \textbf{0.901} & 0.547 & 0.707 \\
        \midrule
        & issue         & 0.474 & \textbf{0.035} & \textbf{0.067} & \textbf{0.571} & \textbf{0.265} & \textbf{0.413} & 0.556 & \textbf{0.354} & \textbf{0.509} \\
        & alternative   & \textbf{0.630} & \textbf{0.507} & \textbf{0.635} & 0.488 & 0.124 & 0.220 & \textbf{0.613} & 0.112 & 0.202 \\
        & pro-argument  & \textbf{0.717} & \textbf{0.355} & \textbf{0.519} & \textbf{0.600} & \textbf{0.040} & \textbf{0.077} & 0.421 & 0.042 & 0.081 \\
        & con-argument  & \textbf{0.500} & 0.018 & 0.035 & 0.143 & 0.004 & 0.009 & \textbf{0.857} & \textbf{0.039} & \textbf{0.076} \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 4 \\  Config 4 \\ Config 4 \\Config 4  \\ Config 4 } \end{minipage}}
        & decision      & 0.813 & 0.440 & 0.609 & 0.929 & 0.163 & \textbf{0.280} & 0.887 & 0.438 & 0.699 \\
        \midrule
        & issue         & 0.474 & 0.035 & 0.067 & 0.571 & 0.265 & 0.413 & 0.556 & 0.354 & 0.509 \\
        & alternative   & 0.630 & 0.507 & 0.635 & 0.488 & 0.124 & 0.220 & 0.613 & 0.112 & 0.202 \\
        & pro-argument  & 0.717 & 0.355 & 0.519 & 0.600 & 0.040 & 0.077 & 0.421 & 0.042 & 0.081 \\
        & con-argument  & 0.500 & 0.018 & 0.035 & 0.143 & 0.004 & 0.009 & 0.857 & 0.039 & 0.076 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 5 \\  Config 5 \\ Config 5 \\Config 5  \\ Config 5 } \end{minipage}}
        & decision      & 0.813 & 0.440 & 0.609 & 0.929 & 0.163 & 0.280 & 0.887 & 0.438 & 0.699 \\
        \midrule
        & issue         & \textbf{0.636} & 0.027 & 0.053 & 0.513 & 0.245 & 0.387 & \textbf{0.560} & 0.265 & 0.413 \\
        & alternative   & 0.599 & 0.475 & 0.606 & \textbf{0.523} & 0.140 & 0.246 & 0.500 & \textbf{0.132} & \textbf{0.232} \\
        & pro-argument  & 0.668 & 0.326 & 0.486 & 0.200 & 0.004 & 0.009 & 0.550 & 0.058 & 0.110 \\
        & con-argument  & 0.453 & \textbf{0.085} & 0.156 & \textbf{0.667} & 0.018 & 0.034 & 0.333 & 0.026 & 0.051 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 6 \\  Config 6 \\ Config 6 \\Config 6  \\ Config 6 } \end{minipage}}
        & decision      & 0.735 & 0.469 & 0.635 & 0.800 & 0.150 & 0.261 & 0.890 & \textbf{0.556} & \textbf{0.714} \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{BR transformation method with DT classifier and 10-fold CV}
    \label{tab:fgcBRDT}
\end{table}

\subsubsection{Label Powerset}
Config 2 gives an F1 score of 0.350 for classiying issue on the dataset of Apache Lucene. Config 4 gives scores of 0.480 and 0.758 in the case of pro-argument and decision while Config 6 gives scores of 0.670 and 0.235 with regards to alternative and con-argument on the Apache Lucene dataset. The best recall and F1 scores on the Mozilla Thunderbird dataset are obtained for issue, alternative and con-argument. The F1 scores are 0.378, 0.267 and 0.100 respectively while Config 1 gives an F1 score of 0.077 for pro-argument and Config 6 gives a score of 0.367 for decision. For the Ubuntu dataset, Config 1 performs the best in the case of issue, pro-argument and decision with F1 scores of 0.533, 0.138 and 0.706 while Config 2 helps with a score of 0.507 for con-argument and Config 4 helps with a score of 0.269 for alternative. Table\ref{tab:fgcLPDT} summarises all the metrics and its values.
\begin{table}[h] %[hb!]
    %\resizebox{\textwidth}{!}{%
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \begin{tabular}{L{1.5cm} c ccc | ccc | ccc }
        \toprule
         \multirow{2}{*}{\textbf{Config}} &  \multirow{2}{*}{\textbf{Rationale}} & \multicolumn{3}{c}{\textbf{Lucene}} & \multicolumn{3}{c}{\textbf{Thunderbird}} & \multicolumn{3}{c}{\textbf{Ubuntu}}\\
        \cmidrule(l){3-5} \cmidrule(l){6-8} \cmidrule(l){9-11}
          &  & \textbf{Pr} &  \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} \\
        \midrule
        & issue         & 0.243 & 0.212 & 0.345 & 0.403 & \textbf{0.257} & 0.298 & 0.440 & \textbf{0.392} & \textbf{0.533} \\
        & alternative   & 0.522 & 0.635 & 0.667 & 0.442 & 0.143 & 0.248 & 0.476 & 0.122 & 0.217 \\
        & pro-argument  & 0.541 & 0.230 & 0.370 & 0.333 & \textbf{0.040} & \textbf{0.077} & \textbf{0.350} & \textbf{0.074} & \textbf{0.138} \\
        & con-argument  & 0.321 & 0.120 & 0.213 & 0.105 & 0.009 & 0.017 & 0.400 & 0.053 & 0.100 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 1 \\  Config 1 \\ Config 1 \\Config 1  \\ Config 1 } \end{minipage}}
        & decision      & \textbf{0.876} & 0.512 & 0.676 & 0.583 & 0.175 & 0.298 & 0.877 & 0.547 & \textbf{0.706} \\
        \midrule
        & issue         & 0.247 & \textbf{0.216} & \textbf{0.350} & 0.403 & 0.257 & 0.298 & 0.440 & 0.392 & 0.533 \\
        & alternative   & 0.513 & 0.617 & 0.656 & 0.442 & 0.143 & 0.248 & 0.476 & 0.122 & 0.217 \\
        & pro-argument  & 0.517 & 0.223 & 0.360 & \textbf{0.333} & 0.040 & 0.077 & 0.350 & 0.074 & 0.138 \\
        & con-argument  & 0.275 & 0.127 & 0.224 & 0.105 & 0.009 & 0.017 & \textbf{0.448} & 0.342 & \textbf{0.507} \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 2 \\  Config 2 \\ Config 2 \\Config 2  \\ Config 2 } \end{minipage}}
        & decision      & 0.858 & 0.527 & 0.688 & 0.583 & 0.175 & 0.298 & \textbf{0.877} & 0.547 & 0.706 \\
        \midrule
        & issue         & 0.247 & 0.216 & 0.350 & 0.403 & 0.257 & 0.298 & 0.440 & 0.392 & 0.533 \\
        & alternative   & 0.513 & 0.617 & 0.656 & 0.442 & 0.143 & 0.248 & 0.476 & 0.122 & 0.217 \\
        & pro-argument  & 0.517 & 0.223 & 0.360 & 0.333 & 0.040 & 0.077 & 0.350 & 0.074 & 0.138 \\
        & con-argument  & 0.275 & 0.127 & 0.224 & 0.105 & 0.009 & 0.017 & 0.448 & \textbf{0.342} & 0.507 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 3 \\  Config 3 \\ Config 3 \\Config 3  \\ Config 3 } \end{minipage}}
        & decision      & 0.858 & 0.527 & 0.688 & 0.583 & 0.175 & 0.298 & 0.877 & \textbf{0.547} & 0.706 \\
        \midrule
        & issue         & \textbf{0.297} & 0.104 & 0.188 & \textbf{0.478} & 0.238 & \textbf{0.378} & 0.470 & 0.298 & 0.447 \\
        & alternative   & \textbf{0.613} & 0.478 & 0.611 & \textbf{0.466} & \textbf{0.155} & \textbf{0.267} & 0.478 & \textbf{0.156} & \textbf{0.269} \\
        & pro-argument  & \textbf{0.680} & \textbf{0.320} & \textbf{0.480} & 0.226 & 0.031 & 0.061 & 0.245 & 0.063 & 0.119 \\
        & con-argument  & 0.289 & 0.085 & 0.156 & \textbf{0.387} & \textbf{0.053} & \textbf{0.100} & 0.400 & 0.066 & 0.123 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 4 \\  Config 4 \\ Config 4 \\Config 4  \\ Config 4 } \end{minipage}}
        & decision      & 0.736 & \textbf{0.618} & \textbf{0.758} & 0.484 & 0.188 & 0.316 & 0.863 & 0.538 & 0.699 \\
        \midrule
        & issue         & 0.297 & 0.104 & 0.188 & 0.478 & 0.238 & 0.378 & 0.470 & 0.298 & 0.447 \\
        & alternative   & 0.613 & 0.478 & 0.611 & 0.466 & 0.155 & 0.267 & 0.478 & 0.156 & 0.269 \\
        & pro-argument  & 0.680 & 0.320 & 0.480 & 0.226 & 0.031 & 0.061 & 0.245 & 0.063 & 0.119 \\
        & con-argument  & 0.289 & 0.085 & 0.156 & 0.387 & 0.053 & 0.100 & 0.400 & 0.066 & 0.123 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 5 \\  Config 5 \\ Config 5 \\Config 5  \\ Config 5 } \end{minipage}}
        & decision      & 0.736 & 0.618 & 0.758 & 0.484 & 0.188 & 0.316 & 0.863 & 0.538 & 0.699 \\
        \midrule
        & issue         & 0.216 & 0.178 & 0.298 & 0.396 & 0.238 & 0.375 & \textbf{0.475} & 0.367 & 0.516 \\
        & alternative   & 0.525 & \textbf{0.639} & \textbf{0.670} & 0.445 & 0.126 & 0.223 & \textbf{0.561} & 0.112 & 0.201 \\
        & pro-argument  & 0.531 & 0.252 & 0.398 & 0.114 & 0.018 & 0.035 & 0.238 & 0.026 & 0.052 \\
        & con-argument  & \textbf{0.355} & \textbf{0.134} & \textbf{0.235} & 0.162 & 0.026 & 0.051 & 0.258 & 0.053 & 0.100 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 6 \\  Config 6 \\ Config 6 \\Config 6  \\ Config 6 } \end{minipage}}
        & decision      & 0.355 & 0.488 & 0.654 & \textbf{0.621} & \textbf{0.225} & \textbf{0.367} & 0.847 & 0.521 & 0.684 \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{LP transformation method with DT classifier and 10-fold CV}
    \label{tab:fgcLPDT}
\end{table}

\subsection{Random Forest}

\subsubsection{Binary Relevance}
For all three datasets, precision of 1.000 was achieved using different configurations for rationale elements such as issue, and pro-argument. In the case of Lucene dataset, the best recall scores were all attained using Config 4. In addition, Config 4 also helped in obtaining the best F1 scores for all elements but alternative which was obtained using Config 3. The scores are 0.289, 0.725, 0.653, 0.323 and 0.775 for issue, alternative, pro-argument, con-argument and decision. In the case of Mozilla Thunderbird dataset, top F1 scores of 0.474, 0.500 and 0.243 for issue, alternative and pro-argument were achieved using Config 4. However, for classifying decision and con-argument, Config 2 and Config 3 performed the best with scores of 0.462 and 0.286. For the Ubuntu dataset, for all rationale elements, top F1 scores were achieved using Config 4 with the scores being 0.643, 0.470, 0.217, 0.292 and 0.761 for issue, alternative, pro-argument, con-argument and decision. Table \ref{tab:fgcBRRF} presents all the values in detail.
\begin{table}[h] %[hb!]
    %\resizebox{\textwidth}{!}{%
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \begin{tabular}{L{1.5cm} c ccc | ccc | ccc }
        \toprule
         \multirow{2}{*}{\textbf{Config}} &  \multirow{2}{*}{\textbf{Rationale}} & \multicolumn{3}{c}{\textbf{Lucene}} & \multicolumn{3}{c}{\textbf{Thunderbird}} & \multicolumn{3}{c}{\textbf{Ubuntu}}\\
        \cmidrule(l){3-5} \cmidrule(l){6-8} \cmidrule(l){9-11}
          &  & \textbf{Pr} &  \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} \\
        \midrule
        & issue         & \textbf{1.000} & 0.093 & 0.170 & 0.526 & 0.229 & 0.368 & 0.882 & 0.326 & 0.490 \\
        & alternative   & 0.824 & 0.507 & 0.660 & 0.436 & 0.134 & 0.236 & \textbf{0.976} & 0.195 & 0.326 \\
        & pro-argument  & \textbf{0.920} & 0.298 & 0.459 & 0.438 & 0.031 & 0.061 & \textbf{1.000} & 0.116 & 0.209 \\
        & con-argument  & 0.911 & 0.144 & 0.252 & 0.188 & 0.013 & 0.026 & 0.852 & 0.151 & 0.263 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 1 \\  Config 1 \\ Config 1 \\Config 1  \\ Config 1 } \end{minipage}}
        & decision      & \textbf{0.965} & 0.536 & 0.698 & 0.917 & 0.138 & 0.242 & \textbf{0.947} & 0.607 & 0.755 \\
        \midrule
        & issue         & 1.000 & 0.097 & 0.176 & \textbf{0.892} & 0.187 & 0.315 & \textbf{0.909} & 0.319 & 0.482 \\
        & alternative   & \textbf{0.831} & 0.523 & 0.673 & \textbf{0.935} & 0.178 & 0.302 & 0.976 & 0.198 & 0.330 \\
        & pro-argument  & 0.911 & 0.300 & 0.461 & \textbf{0.879} & 0.129 & 0.229 & 1.000 & 0.116 & 0.209 \\
        & con-argument  & 0.911 & 0.144 & 0.252 & 0.921 & 0.154 & 0.266 & 0.857 & 0.158 & 0.273 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 2 \\  Config 2 \\ Config 2 \\Config 2  \\ Config 2 } \end{minipage}}
        & decision      & 0.947 & 0.517 & 0.681 & \textbf{1.000} & \textbf{0.300} & \textbf{0.462} & 0.947 & 0.607 & 0.755 \\
        \midrule
        & issue         & 0.960 & 0.093 & 0.170 & 0.859 & 0.236 & 0.380 & 0.812 & 0.389 & 0.555 \\
        & alternative   & 0.772 & 0.603 & \textbf{0.725} & 0.919 & 0.188 & 0.316 & 0.933 & 0.205 & 0.340 \\
        & pro-argument  & 0.882 & 0.343 & 0.509 & 0.806 & 0.112 & 0.201 & 1.000 & 0.106 & 0.191 \\
        & con-argument  & 0.915 & 0.151 & 0.263 & \textbf{0.950} & 0.167 & \textbf{0.286} & \textbf{0.862} & 0.164 & 0.282 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 3 \\  Config 3 \\ Config 3 \\Config 3  \\ Config 3 } \end{minipage}}
        & decision      & 0.946 & 0.507 & 0.672 & 1.000 & 0.300 & 0.462 & 0.923 & \textbf{0.615} & 0.761 \\
        \midrule
        & issue         & 0.463 & \textbf{0.170} & \textbf{0.289} & 0.589 & \textbf{0.319} & \textbf{0.474} & 0.690 & \textbf{0.492} & \textbf{0.643} \\
        & alternative   & 0.690 & \textbf{0.622} & 0.721 & 0.697 & \textbf{0.337} & \textbf{0.500} & 0.676 & \textbf{0.310} & \textbf{0.470} \\
        & pro-argument  & 0.699 & \textbf{0.501} & \textbf{0.653} & 0.525 & \textbf{0.138} & \textbf{0.243} & 0.561 &  \textbf{0.122} & \textbf{0.217} \\
        & con-argument  & 0.509 & \textbf{0.194} & \textbf{0.323} & 0.667 & \textbf{0.167} & 0.285 & 0.650 & \textbf{0.171} & \textbf{0.292} \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 4 \\  Config 4 \\ Config 4 \\Config 4  \\ Config 4 } \end{minipage}}
        & decision      & 0.820 & \textbf{0.638} & \textbf{0.775} & 0.957 & 0.275 & 0.431 & 0.911 & 0.615 & \textbf{0.761} \\
        \midrule
        & issue         & 0.463 & 0.170 & 0.289 & 0.589 & 0.319 & 0.474 & 0.690 & 0.492 & 0.643 \\
        & alternative   & 0.690 & 0.622 & 0.721 & 0.697 & 0.337 & 0.500 & 0.676 & 0.310 & 0.470 \\
        & pro-argument  & 0.699 & 0.501 & 0.653 & 0.525 & 0.138 & 0.243 & 0.561 & 0.122 & 0.217 \\
        & con-argument  & 0.509 & 0.194 & 0.323 & 0.667 & 0.167 & 0.285 & 0.650 & 0.171 & 0.292 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 5 \\  Config 5 \\ Config 5 \\Config 5  \\ Config 5 } \end{minipage}}
        & decision      & 0.820 & 0.638 & 0.775 & 0.957 & 0.275 & 0.431 & 0.911 & 0.615 & 0.761 \\
        \midrule
        & issue         & 1.000 & 0.089 & 0.163 & 0.867 & 0.210 & 0.347 & 0.818 & 0.367 & 0.533 \\
        & alternative   & 0.752 & 0.622 & 0.734 & 0.913 & 0.174 & 0.296 & 0.945 & 0.210 & 0.347 \\
        & pro-argument  & 0.865 & 0.354 & 0.520 & 0.800 & 0.107 & 0.194 & 1.000 & 0.106 & 0.191 \\
        & con-argument  & \textbf{0.917} & 0.155 & 0.268 & 0.944 & 0.149 & 0.260 & 0.857 & 0.158 & 0.273 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 6 \\  Config 6 \\ Config 6 \\Config 6  \\ Config 6 } \end{minipage}}
        & decision      & 0.955 & 0.512 & 0.677 & 1.000 & 0.263 & 0.416 & 0.947 & 0.607 & 0.755 \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{BR transformation method with RF classifier and 10-fold CV}
    \label{tab:fgcBRRF}
\end{table}

\subsubsection{Label Powerset}
Precision of 1.000 was achieved but in the case of decision and pro-argument only for Mozilla Thunderbird and Ubuntu dataset with Config 1 and Config 2 respectively. Config 1 helps achieving the best F1 score of 0.775 and 0.357 in the case of Apache Lucene dataset. However, Config 4 performs the best for other rationale elements with scores of 0.363, 0.603 and 0.807 for issue, pro-argument and decision. For Mozilla Thunderbird dataset, once again Config 1 does well with F1 scores of 0.467 and 0.491 but for issue and decision unlike in the case of Apache Lucene dataset. Similarly, Config 4 performs the best for all the other rationale elements with scores of 0.455, 0.263 and 0.317 for alternative, pro-argument and con-argument. In the case of Ubuntu dataset, Config 2 helps classifying issue the best with an F1 score of 0.662 while Config 4 has scores of 0.432, 0.250, 0.301 and 0.774 for alternative, pro-argument, con-argument and decision respectively. Table \ref{tab:fgcLPRF} presents all the metrics and its values in detail.
\begin{table}[h] %[hb!]
    %\resizebox{\textwidth}{!}{%
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \begin{tabular}{L{1.5cm} c ccc | ccc | ccc }
        \toprule
         \multirow{2}{*}{\textbf{Config}} &  \multirow{2}{*}{\textbf{Rationale}} & \multicolumn{3}{c}{\textbf{Lucene}} & \multicolumn{3}{c}{\textbf{Thunderbird}} & \multicolumn{3}{c}{\textbf{Ubuntu}}\\
        \cmidrule(l){3-5} \cmidrule(l){6-8} \cmidrule(l){9-11}
          &  & \textbf{Pr} &  \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} & \textbf{Pr} & \textbf{Re} & \textbf{F1} \\
        \midrule
        & issue         & 0.489 & 0.170 & 0.290 & \textbf{0.681} & 0.309 & \textbf{0.467} & 0.648 & 0.514 & 0.656 \\
        & alternative   & 0.630 & 0.786 & \textbf{0.775} & \textbf{0.946} & 0.182 & 0.308 & \textbf{0.943} & 0.200 & 0.333 \\
        & pro-argument  & 0.731 & 0.370 & 0.534 & \textbf{0.879} & 0.129 & 0.229 & 0.952 & 0.106 & 0.191 \\
        & con-argument  & 0.674 & \textbf{0.218} & \textbf{0.357} & 0.907 & 0.171 & 0.292 & 0.828 & 0.158 & 0.273 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 1 \\  Config 1 \\ Config 1 \\Config 1  \\ Config 1 } \end{minipage}}
        & decision      & 0.842 & 0.565 & 0.720 & \textbf{1.000} & \textbf{0.325} & \textbf{0.491} & 0.913 & 0.624 & 0.768 \\
        \midrule
        & issue         & 0.538 & 0.135 & 0.238 & 0.680 & 0.307 & 0.464 & 0.664 & \textbf{0.520} & \textbf{0.662} \\
        & alternative   & 0.611 & \textbf{0.790} & 0.765 & 0.935 & 0.178 & 0.302 & 0.933 & 0.205 & 0.340 \\
        & pro-argument  & \textbf{0.758} & 0.368 & 0.533 & 0.879 & 0.129 & 0.229 & \textbf{1.000} & 0.111 & 0.200 \\
        & con-argument  & \textbf{0.729} & 0.180 & 0.304 & 0.905 & 0.167 & 0.286 & \textbf{0.839} & 0.171 & 0.292 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 2 \\  Config 2 \\ Config 2 \\Config 2  \\ Config 2 } \end{minipage}}
        & decision      & 0.870 & 0.580 & 0.732 & 1.000 & 0.325 & 0.491 & 0.913 & 0.624 & 0.768 \\
        \midrule
        & issue         & 0.538 & 0.135 & 0.238 & 0.680 & 0.307 & 0.464 & 0.664 & 0.520 & 0.662 \\
        & alternative   & 0.611 & 0.790 & 0.765 & 0.935 & 0.178 & 0.302 & 0.933 & 0.205 & 0.340 \\
        & pro-argument  & 0.758 & 0.368 & 0.533 & 0.879 & 0.129 & 0.229 & 1.000 & 0.111 & 0.200 \\
        & con-argument  & 0.729 & 0.180 & 0.304 & 0.905 & 0.167 & 0.286 & 0.839 & 0.171 & 0.292 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 3 \\  Config 3 \\ Config 3 \\Config 3  \\ Config 3 } \end{minipage}}
        & decision      & 0.870 & 0.580 & 0.732 & 1.000 & 0.325 & 0.491 & 0.913 & 0.624 & 0.768 \\
        \midrule
        & issue         & 0.367 & \textbf{0.224} & \textbf{0.363} & 0.559 & \textbf{0.312} & 0.466 & 0.631 & 0.491 & 0.636 \\
        & alternative   & \textbf{0.688} & 0.621 & 0.720 & 0.649 & \textbf{0.298} & \textbf{0.455} & 0.637 & 0.278 & \textbf{0.432} \\
        & pro-argument  & 0.679 & \textbf{0.444} & \textbf{0.603} & 0.486 & \textbf{0.152} & \textbf{0.263} & 0.458 & 0.143 & \textbf{0.250} \\
        & con-argument  & 0.430 & 0.204 & 0.337 & 0.652 & \textbf{0.189} & \textbf{0.317} & 0.500 & 0.178 & \textbf{0.301} \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 4 \\  Config 4 \\ Config 4 \\Config 4  \\ Config 4 } \end{minipage}}
        & decision      & 0.759 & \textbf{0.686} & \textbf{0.807} & 0.920 & 0.288 & 0.447 & 0.871 & 0.632 & \textbf{0.774} \\
        \midrule
        & issue         & 0.367 & 0.224 & 0.363 & 0.559 & 0.312 & 0.466 & 0.631 & 0.491 & 0.636 \\
        & alternative   & 0.688 & 0.621 & 0.720 & 0.649 & 0.298 & 0.455 & 0.637 & \textbf{0.278} & 0.432 \\
        & pro-argument  & 0.679 & 0.444 & 0.603 & 0.486 & 0.152 & 0.263 & 0.458 & \textbf{0.143} & 0.250 \\
        & con-argument  & 0.430 & 0.204 & 0.337 & 0.652 & 0.189 & 0.317 & 0.500 & \textbf{0.178} & 0.301 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 5 \\  Config 5 \\ Config 5 \\Config 5  \\ Config 5 } \end{minipage}}
        & decision      & 0.759 & 0.686 & 0.807 & 0.920 & 0.288 & 0.447 & 0.871 & \textbf{0.632} & 0.774 \\
        \midrule
        & issue         & \textbf{0.554} & 0.139 & 0.244 & 0.642 & 0.293 & 0.448 & \textbf{0.676} & 0.501 & 0.649 \\
        & alternative   & 0.607 & 0.789 & 0.763 & 0.940 & 0.163 & 0.281 & 0.854 & 0.200 & 0.333 \\
        & pro-argument  & 0.731 & 0.390 & 0.555 & 0.871 & 0.121 & 0.215 & 0.955 & 0.111 & 0.220 \\
        & con-argument  & 0.683 & 0.197 & 0.329 & \textbf{0.925} & 0.162 & 0.279 & 0.833 & 0.164 & 0.282 \\
        \multirow{-5}{*}{\begin{minipage}{4cm}{\scriptsize  Config 6 \\  Config 6 \\ Config 6 \\Config 6  \\ Config 6 } \end{minipage}}
        & decision      & \textbf{0.905} & 0.551 & 0.709 & 1.000 & 0.275 & 0.431 & \textbf{0.948} & 0.624 & 0.768 \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{LP transformation method with RF classifier and 10-fold CV}
    \label{tab:fgcLPRF}
\end{table}

\subsection{Summary}
This section presents the best configurations, classifiers and transformation methods along with their respective F1 scores as shown in Table \ref{tab:summaryFGC}. For the Apache Lucene dataset, MNB is the best classifier and BR is the ideal transformation method in predicting any kind of rationale element. Config 4 is suitable to classify issue and decision with F1 scores of 0.525 and 0.860, Config 1 is suitable for classifying alternative with a score of 0.768 and Config 6 is the best for any kind of arguments with scores of 0.750 and 0.664 for pro-argument and con-argument respectively. MNB turns out to be the best classifier for predicting any rationale element even in the case of Mozilla Thunderbird. BR is the most suitable transformation method for all cases except issue for which LP happens to be the best. Config 4 gives F1 scores of 0.619, 0.644 abd 0.648 for pro-argument, con-argument and decision while Config 1 gives 0.690 for issue and Config 6 gives 0.703 for alternative. A slight change is observed in the case of Ubuntu dataset where classifying decision turns out to be the best using Config 1, SVM and LP with an F1 score of 0.821. For all the other rationale elements, MNB once again turns out be the top performing classifier. LP is yet again the ideal transformation method with Config 1 and an F1 score of 0.771 to classify issue in a sentence. BR with Config 2 gives a score of 0.712 while Config 4 again is the suitable one for pro-argument and con-arugment with scores of 0.622 and 0.664 respectively. 
\begin{table} %[hb!]
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \def\arraystretch{1} % 1 is the default, change whatever you need (line spacing)
    \begin{tabular}{p{4cm} p{3cm} p{2cm} p{2cm} p{3cm} p{3cm}}
        \toprule
        \textbf{Dataset} & \textbf{Rationale} & \textbf{Config} & \textbf{Classifier} & \textbf{Transformation} & \textbf{F1 Score}\\
        \midrule
			Apache Lucene & issue & Config 4 & MNB & BR & 0.525 \\
			Apache Lucene & alternative & Config 1 & MNB & BR & 0.768 \\
			Apache Lucene & pro-argument & Config 6 & MNB & BR & 0.750 \\
			Apache Lucene & con-argument & Config 6 & MNB & BR & 0.664 \\
			Apache Lucene & decision & Config 4 & MNB & BR & 0.860 \\
		\midrule
			Mozilla Thunderbird & issue & Config 1 & MNB & LP & 0.690 \\ 
			Mozilla Thunderbird & alternative & Config 6 & MNB & BR & 0.703 \\ 
			Mozilla Thunderbird & pro-argument & Config 4 & MNB & BR & 0.619 \\ 
			Mozilla Thunderbird & con-argument & Config 4 & MNB & BR & 0.644 \\ 			
			Mozilla Thunderbird & decision & Config 4 & MNB & BR & 0.648 \\ 
		\midrule
			Ubuntu & issue & Config 1 & MNB & LP & 0.771 \\
			Ubuntu & alternative & Config 2 & MNB & BR & 0.712 \\
			Ubuntu & pro-argument & Config 4 & MNB & BR & 0.622 \\
			Ubuntu & con-argument & Config 4 & MNB & BR & 0.664 \\
			Ubuntu & decision & Config 1 & SVM & LP & 0.821 \\
        \midrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Summary of fine grained classification}
    \label{tab:summaryFGC}
\end{table}

\section{Topic Modeling}
In this section, the results of topic modeling applied on each of the dataset of issue trackers, namely, Apache Lucene, Mozilla Thunderbird and Ubuntu are discussed in detail. The experiments were conducted using Gensim libary for Python. The best results were obtained using Config 5. The optimum number of topics to be generated was experimented with values of 5, 10, 15 and 20. While the number of topics when limited to 5 gave too less insights, 10, 15 and 20 seemed ideal. However, the optimum number was 10 compared to 15 or 20 since they all produced similar results but when the number of topics to be generated is lower, the program gives results much faster.

\subsubsection{Apache Lucene} 
Given that Apache Lucene is an information retrieval library, majority of the topics revolved around indexing, parsing and file formats which form the backbone of information retrieval mechanisms. Bytes Reference\footnote{\url{https://lucene.apache.org/core/4_2_0/core/org/apache/lucene/util/BytesRef.html}}, or BytesRef, is a Java class used by Lucene to represent terms using a particular character encoding format such as UTF8. Lucene 7.0\footnote{\url{https://lucene.apache.org/core/7_1_0/benchmark/org/apache/lucene/benchmark/byTask/package-summary.html}} is an indexing file format used by Lucene itself. Another topic ByTask Benchmarking\footnote{\url{https://lucene.apache.org/core/7_1_0/benchmark/org/apache/lucene/benchmark/byTask/package-summary.html}} revolves around a package that provides mechanisms to perform task based benchmarking of Lucene. Pulsing\footnote{\url{https://lucene.apache.org/core/4_2_0/codecs/org/apache/lucene/codecs/pulsing/package-summary.html}}, the fourth topic, is a technique that helps inlining terms of low frequency and its pertinent postings into terms dictionary. Compared to others, one of the most unique topics encountered was that of Robert Muir\footnote{\url{https://github.com/rmuir}}, an active developer of Apache Lucene. The sixth topic, Nexus Indexer\footnote{\url{https://repository.sonatype.org/nexus-indexer-lucene-plugin/default/docs/index.html}} is an API based on REST model to provide access through a fixed set of operations to a set of resources. One of the most important topics, presumably predictable, was that of Query Parser\footnote{\url{http://lucene.apache.org/core/6_6_2/queryparser/org/apache/lucene/queryparser/classic/QueryParser.html}}. The eighth and ninth topics deal with factory constructors\footnote{\url{https://lucene.apache.org/core/6_1_0/analyzers-common/org/apache/lucene/analysis/util/AbstractAnalysisFactory.html}} required by Lucene whereas the final topic focuses on spatial search using parameters such as latitude and longitude\footnote{\url{https://lucene.apache.org/solr/guide/6_6/spatial-search.html}}. Table \ref{tab:tmLucene} presents all the topics, its keywords and probabilities associated with it. 

\begin{table} %[hb!]
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \def\arraystretch{1} % 1 is the default, change whatever you need (line spacing)
    \begin{tabular}{p{3cm} p{12cm}}
        \toprule
        \textbf{Topic} & \textbf{Keywords with Probabilities}\\
        \midrule
			Bytes Reference & 0.023*"code" + 0.017*"check" + 0.016*"bytesref" + 0.010*"index" + 0.010*"call" + 0.009*"end" + 0.008*"correctly" + 0.008*"backport" + 0.008*"case" + 0.008*"extra" \\
			\midrule 
			Lucene 7.0 File Format & 0.026*"docvaluesformat" + 0.019*"close" + 0.016*"release" + 0.016*"junit4" + 0.012*"lucene70" + 0.012*"jenkins" + 0.011*"dtests" + 0.009*"java" + 0.009*"repository" + 0.008*"thread" \\ 
			\midrule 
			Benchmarking Lucene By Tasks & 0.177*"forbidden" + 0.126*"java" + 0.118*"apis" + 0.060*"lang" + 0.059*"system" + 0.057*"field" + 0.056*"access" + 0.024*"benchmark" + 0.015*"bytask" + 0.013*"checkindex" \\
			\midrule 
			Pulsing Codec & 0.025*"doc" + 0.024*"pulsing" + 0.019*"id" + 0.012*"term" + 0.012*"junit" + 0.010*"query" + 0.010*"deleted" + 0.009*"pas" + 0.008*"docid" + 0.008*"bit" \\
			\midrule 
			Robert Muir & 0.040*"branch" + 0.022*"http" + 0.019*"dev" + 0.019*"snapshot" + 0.013*"case" + 0.008*"added" + 0.007*"muir" + 0.007*"remove" + 0.006*"block" + 0.006*"mccandless" \\
			\midrule 
			Nexus Indexer REST API & 0.016*"revision" + 0.016*"nexus" + 0.014*"collection" + 0.013*"http" + 0.010*"access" + 0.010*"value" + 0.010*"file" + 0.009*"back" + 0.008*"code" + 0.007*"case" \\
			\midrule 
			Query Parser & 0.032*"branch" + 0.023*"http" + 0.020*"dev" + 0.014*"mccandless" + 0.011*"rate" + 0.010*"search" + 0.010*"artifact" + 0.009*"queryparser" + 0.009*"pom" + 0.008*"postingshighlighter" \\
			\midrule 
			Abstract Analysis Factory Class & 0.023*"param" + 0.021*"term" + 0.018*"method" + 0.012*"time" + 0.010*"class" + 0.009*"rule" + 0.009*"reason" + 0.009*"question" + 0.008*"example" + 0.008*"abstractanalysisfactory" \\
			\midrule 
			Factory Constructor & 0.014*"factory" + 0.012*"constructor" + 0.011*"add" + 0.010*"look" + 0.009*"buffer" + 0.008*"dataset" + 0.007*"term" + 0.007*"make" + 0.007*"rate" + 0.007*"passed" \\
			\midrule 
			Spatial Search & 0.031*"lat" + 0.023*"point" + 0.020*"planetmodel" + 0.012*"mean" + 0.010*"hole" + 0.010*"junit4" + 0.010*"internaledges" + 0.010*"wgs84" + 0.009*"within" + 0.009*"let" \\
        \midrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Topic modeling of Apache Lucene dataset}
    \label{tab:tmLucene}
\end{table} 

\subsubsection{Mozilla Thunderbird}
The topics in the case of Mozilla Thunderbird comprised of layout engine, settings, testing tools, to mention a few. Global database, or Gloda\footnote{\url{https://developer.mozilla.org/en-US/docs/Mozilla/Thunderbird/gloda}} as termed by Mozilla, is the database used to perform indexing and searching. Given that Thunderbird is an email client, encountering topics along the lines of calendar, IMAP and authentication settings is not surprising. Gecko\footnote{\url{https://developer.mozilla.org/en-US/docs/Mozilla/Gecko}} is a layout engine developed by Mozilla and is also used in their other products such as Firefox. An extension of Thunderbird for Chrome web browser was another topic unearthed from the dataset. MozMill\footnote{\url{https://developer.mozilla.org/en-US/docs/Mozilla/Projects/Mozmill}} is a testing tool and framework to perform automated tests on applications based on Gecko. However, Mozmill is currenly deprecated and has been replaced by Marionette. Content Tabs\footnote{\url{https://developer.mozilla.org/en-US/docs/Mozilla/Thunderbird/Content_Tabs}} is a feature introduced in Thunderbird to enable users to browse remote contents in a tab similar to that of a web browser. Packages for Debian based systems were one amongst the many other topics as well. Fixes for numerous DLL files seemed to be source of worry for Thunderbird developers. Table \ref{tab:tmThunderbird} presents all the topics, its keywords and probabilities associated with it. 
\begin{table} %[hb!]
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \def\arraystretch{1} % 1 is the default, change whatever you need (line spacing)
    \begin{tabular}{p{3cm} p{12cm}}
        \toprule
        \textbf{Topic} & \textbf{Keywords with Probabilities}\\
        \midrule
			Global Database & 0.026*"mode" + 0.016*"window" + 0.016*"safe" + 0.014*"attachment" + 0.010*"gloda" + 0.009*"happens" + 0.009*"setting" + 0.009*"eml" + 0.008*"archive" + 0.008*"add" \\
			\midrule 
			Calendar & 0.011*"book" + 0.011*"time" + 0.010*"manager" + 0.010*"build" + 0.009*"server" + 0.009*"let" + 0.007*"cpp" + 0.007*"calendar" + 0.007*"new" + 0.007*"52" \\ 
			\midrule 
			Gecko Layout Engine & 0.011*"service" + 0.010*"sending" + 0.009*"information" + 0.009*"dll" + 0.008*"however" + 0.008*"wonder" + 0.008*"place" + 0.007*"gecko" + 0.007*"current" + 0.007*"latest" \\
			\midrule 
			Chrome Extension & 0.014*"central" + 0.014*"content" + 0.013*"http" + 0.011*"function" + 0.010*"chrome" + 0.008*"space" + 0.008*"offline" + 0.007*"source" + 0.007*"request" + 0.007*"messenger" \\
			\midrule 
			IMAP Settings & 0.014*"folder" + 0.014*"file" + 0.011*"time" + 0.009*"port" + 0.009*"source" + 0.009*"field" + 0.008*"imap" + 0.007*"account" + 0.007*"global" + 0.007*"setting" \\
			\midrule 
			Mozmill Testing Tool & 0.029*"j" + 0.018*"mozmill" + 0.017*"account" + 0.012*"server" + 0.010*"display" + 0.010*"button" + 0.010*"setting" + 0.010*"header" + 0.010*"calendar" + 0.008*"folder" \\
			\midrule 
			Content Tab & 0.019*"wizard" + 0.015*"server" + 0.013*"tabmail" + 0.012*"ssl" + 0.011*"de" + 0.011*"exception" + 0.010*"zfn" + 0.009*"attachment" + 0.009*"fail" + 0.009*"j" \\
			\midrule 
			Debian Package & 0.011*"line" + 0.010*"debian" + 0.009*"reproduce" + 0.009*"string" + 0.008*"text" + 0.008*"display" + 0.007*"source" + 0.006*"stack" + 0.006*"bit" + 0.006*"build" \\
			\midrule 
			DLL Fix & 0.018*"duplicate" + 0.016*"attachment" + 0.015*"marked" + 0.009*"re" + 0.008*"http" + 0.008*"screenshot" + 0.007*"dll" + 0.007*"id" + 0.007*"line" + 0.006*"font" \\
			\midrule 
			Authentication & 0.030*"visible" + 0.026*"ordinal" + 0.014*"client" + 0.009*"u" + 0.008*"07" + 0.008*"default" + 0.008*"sign" + 0.007*"number" + 0.006*"restart" + 0.006*"authentication" \\
        \midrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Topic modeling of Mozilla Thunderbird dataset}
    \label{tab:tmThunderbird}
\end{table} 

\subsubsection{Ubuntu}
Ubuntu is an operating system and the most spoken topics were predictably about various drivers and graphics. IEEE-1275\footnote{\url{https://standards.ieee.org/findstds/standard/1275-1994.html}} along with GRUB\footnote{\url{https://www.gnu.org/software/grub/}} shows that the first discussed topic was about boot firmware. Topics such as Gecko, Mir\footnote{\url{https://wiki.ubuntu.com/Mir/Spec}} and cx18\footnote{\url{https://linuxtv.org/downloads/v4l-dvb-apis/v4l-drivers/cx18.html}} reveals that graphical displays were one of the majorly spoken about topics for Ubuntu developers. Another topic of discussion was Phablet Tools\footnote{\url{https://packages.ubuntu.com/trusty/admin/phablet-tools}}, which is package for Ubuntu based touch operating system. Since operating systems are prone to crashes, a crash reporter named Apport\footnote{\url{https://wiki.ubuntu.com/Apport}} also caught the attention of many developers. Other topics from the Ubuntu dataset includes USB PCI card, RAID management utility and cloud services. Table \ref{tab:tmUbuntu} presents all the topics, its keywords and probabilities associated with it. 
\begin{table} %[hb!]
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \def\arraystretch{1} % 1 is the default, change whatever you need (line spacing)
    \begin{tabular}{p{3cm} p{12cm}}
        \toprule
        \textbf{Topic} & \textbf{Keywords with Probabilities}\\
        \midrule
			Boot Firmware & 0.016*"grub" + 0.014*"install" + 0.013*"lib" + 0.011*"info" + 0.011*"boot" + 0.010*"icon" + 0.010*"ieee1275" + 0.009*"symbolic" + 0.009*"powerpc" + 0.009*"mod" \\
			\midrule 
			Gecko Driver & 0.017*"mozilla" + 0.013*"script" + 0.010*"debian" + 0.010*"state" + 0.009*"http" + 0.009*"conf" + 0.009*"turn" + 0.008*"icon" + 0.008*"driver" + 0.007*"home" \\ 
			\midrule 
			Mir Display Supply & 0.015*"file" + 0.014*"http" + 0.010*"indicator" + 0.007*"new" + 0.007*"message" + 0.007*"xmir" + 0.007*"id" + 0.006*"xorg" + 0.006*"commit" + 0.006*"time" \\
			\midrule 
			Ubuntu Touch Operating System & 0.033*"kernel" + 0.023*"upstream" + 0.019*"http" + 0.010*"phablet" + 0.009*"following" + 0.008*"upstart" + 0.008*"developer" + 0.008*"comment" + 0.008*"launchpad" + 0.008*"net" \\
			\midrule 
			USB PCI Card & 0.020*"controller" + 0.018*"device" + 0.017*"intel" + 0.017*"rev" + 0.015*"menu" + 0.015*"corporation" + 0.013*"pci" + 0.012*"usb" + 0.010*"event" + 0.009*"bus" \\
			\midrule 
			RAID Management Utility & 0.027*"dev" + 0.018*"mdadm" + 0.016*"byte" + 0.013*"sudo" + 0.010*"setting" + 0.010*"application" + 0.009*"device" + 0.009*"registered" + 0.008*"medium" + 0.008*"trinitronx" \\
			\midrule 
			Cloud Services & 0.020*"lp" + 0.009*"update" + 0.009*"aws" + 0.008*"warning" + 0.008*"2017" + 0.007*"gke" + 0.007*"xenial" + 0.007*"ext4" + 0.007*"group" + 0.007*"cloud" \\
			\midrule 
			Display & 0.011*"line" + 0.010*"debian" + 0.009*"reproduce" + 0.009*"string" + 0.008*"text" + 0.008*"display" + 0.007*"source" + 0.006*"stack" + 0.006*"bit" + 0.006*"build" \\
			\midrule 
			Apport Crash Reporter & 0.033*"firefox" + 0.031*"window" + 0.022*"information" + 0.019*"miral" + 0.018*"apport" + 0.010*"name" + 0.009*"restored" + 0.009*"type" + 0.008*"4294967295" + 0.008*"outputid" \\
			\midrule 
			CX18 Video Card Driver & 0.032*"cx18" + 0.020*"setting" + 0.015*"affect" + 0.014*"confirmed" + 0.013*"multiple" + 0.011*"tveeprom" + 0.010*"kb" + 0.009*"18" + 0.009*"system" + 0.007*"hauppauge" \\
        \midrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Topic modeling of Ubuntu dataset}
    \label{tab:tmUbuntu}
\end{table} 

\section{Linking}
In this section, the results of linking comments from ITS and messages from IRC are analysed. Keywords were extracted using topic modeling applied with Config 5 from comments of ITS as well as messages of IRC. The keywords of each comment from ITS and each message of IRC were compared and checked for atleast fifty percent similarity using a string matching library. Table \ref{tab:topicLinking} shows the results of how many messages and comments were linked for each dataset. 
\newline \newline
Each of the three datasets had 100 issues and 2,500 IRC messages. However, since most of the IRC messages did not have any rationale and predominantly consisted of greetings and salutions when introspected manually, only those with rationale were considered to perform the experiment. Around 83 issues out of 100 spanning 255 comments could be linked to 316 IRC messages for the dataset of Apache Lucene. As high as 100 percent similarity was attained. For the Mozilla Thunderbird dataset, 81 issues spanning 209 comments were linked to 143 IRC messages; almost half as compared to that of messages from Apache Lucene or Ubuntu. In addition, the highest similarity attained was 78 percent. Ubuntu had the maximum number of issues with 94 of them spanning 318 comments linked to 318 IRC messages. However, the highest similarity achieved on this dataset was only 71 percent, which was the least when compared to the other datasets of Apache Lucene and Mozilla Thunderbird. 
\begin{table} %[hb!]
    \centering
    \begin{adjustbox}{max width=\columnwidth}
    \def\arraystretch{1} % 1 is the default, change whatever you need (line spacing)
    \begin{tabular}{p{4cm} p{3cm} p{3cm} p{4cm} p{4cm}}
        \toprule
        \textbf{Dataset} & \textbf{Issues} & \textbf{Comments} & \textbf{Messages (IRC)} & \textbf{Highest Similarity}\\
        \midrule
			Apache Lucene & 83 & 255 & 316 & 100 \\
			Mozilla Thunderbird & 81 & 209 & 143 & 78 \\ 
			Ubuntu & 94 & 318 & 318 & 71 \\
        \midrule
    \end{tabular}
    \end{adjustbox}
    \captionof{table}{Linking based on similarity}
    \label{tab:topicLinking}
\end{table}

%------- chapter 6 -------

\chapter{Summary}
In this chapter, the results of this thesis are summarized. The hypotheses formulated earlier are revisited for validation. Next, all the limitations encountered during different phases of the research are discussed. Later, conclusions are inferred from the insights and finally, possible research that can be carried out in the future are suggested.

\section{Contribution}
This thesis examines the frequency with which rationale occurs in the comments of ITS from developers. It also explores ways in which rationale elements can be retrieved automatically. To do this, more than 250,000 comments spanning 40,000 issues were scraped from the issue trackers of three OSS projects: Apache Lucene, Mozilla Thunderbird and Ubuntu. Random Stratified Sampling was applied to extract 100 issues from each OSS project. Comments from these issues were decomposed into individual sentences and were labeled manually. Those containing rationale were further categorized into five types: issues, alternative, pro-arguments, con-arguments and decisions. These manual labelings acted as ground truth for training the ML algorithms to extract rationale and classify them accordingly. 
\bigbreak
Besides ML, topic modeling was also performed on each of the dataset to get insights about various kinds of discussions taking place and which topics from each dataset attracted lots of attention. In addition, keywords were extracted comments of ITS and messages of IRC using topic modeling and similarity between them was computed to link certain issues and their counterpart IRC messages. In order to review the results, the hypotheses formulated earlier are revisited:

\begin{itemize}
\item[\textbf{RH1}] Messages from ITS of OSS projects contain rationale.
\item[\textbf{RH2}] Rationale can be captured automatically from ITS.
\item[\textbf{RH3}] Mutual issues exist in IRC and ITS.
\end{itemize}

The first hypothesis RH1 can be validated by introspecting the results of manual annotation of comments. From the Apache Lucene dataset, 2,446 sentences spanning 963 comments were checked and 73\% of them were found to contain rationale in them. Although not as high as Apache Lucene, datasets of Mozilla Thunderbird and Ubuntu also showed a healthy percentage of rationale occuring in the comments of their ITS. Of the 3,086 sentences spanning 987 comments, 51\% of them contained rationale in the Mozilla Thunderbird dataset while in the case of Ubuntu dataset, 48\% of 2,782 sentences spanning 813 comments contained rationale in them. It is also to be noted that around 56\% of the sentences across all the datasets contained rationale. On analyzing the rationale elements at an individual level, it can be seen that most of the discussions centered around issues, suggesting alternatives and arguments to support the proposals. Only in the case of Apache Lucene, the number of issues (11\%) were far less compared to alternatives (34\%). However, for all three datasets, decision occured the least followed by con-arguments. 
\bigbreak
The second hypothesis RH2 proves to be feasible. Sentences manually annotated were trained for the ML algorithms to extract rationale and classify them into the most suitable one using various preprocessing methods. Different classifiers coupled with different preprocessing methods fared well. In the case of binary classification, LR and SVM performed the best on most occasions while RF came out at the top on one particular instance. The ideal preprocessing methods for binary classification turned out to be BOW model or the POS tagging technique on all occasions involving LR or SVM. In the case of fine grained classification, MNB remained the top classifier in almost all cases except one with numerous preprocessing methods and its combinations. Similarly, BR transformation method with MNB classifier seemed to be the most ideal approach for majority cases when compared to LP. 
\bigbreak
The third hypothesis RH1 can be endorsed by observing the results after having linked comments from ITS to messages from IRC. More than 80 out of 100 issues spanning more than 700 comments from all datasets had keywords extracted from comments that could be linked with keywords extracted from IRC messages. In the case of Apache Lucene dataset, some keywords from both the ends matched completely there by attaining a similarity of 100\% while the highest similarity attained in the case of Mozilla Thunderbird and Ubuntu datasets are 78\% and 71\% respectively. This proves there exists mutual topics of discussion that takes place in multiple communication media; in this case, ITS and IRC. 

\section{Limitations}
During different phases of this thesis, various challenges and limitations were encountered. In this section, these limitations and how they were addressed and overcome are discussed. 
\bigbreak
The selection of the OSS projects were questionable, initially. Commercial projects could have been chosen but OSS ones were opted for based on certain reasons. To eliminate bias towards one particular field of software engineering, projects from different domains were chosen. In addition, it was required to have projects that have been actively developed for a long time, typically more than five years, and has a vibrant community of developers and users even today. In addition, for the comments from ITS to be linked to messages from IRC, same projects with identical time frame had to be chosen. In this case, datasets for messages from IRC were already readily available for the three selected OSS projects; thereby also leading to significant savings of time and effort. 
\bigbreak
While scraping, another issue encountered was that the layout of HTML, the names of the classes and its attributes were not consistent and kept changing over the course of entire period for which the data had to be scraped. Hence, every time the scraper failed to gather data, the reason behind it was introspected. On certain occasions, there were downlinks for which nothing could be done but on other occasions, the code for scraping was modified to accommodate any changes in the HTML code. In addition, since requests to fetch data were frequently made and the possibility of getting blacklisted was looming, fake user agents were generated every time while making requests in order to overcome the aforementioned limitation. 
\bigbreak
In the manual labeling phase, a conundrum cropped up about how large should the sample size be in order for the ML algorithms to be trained. However, it turns out the sample size chosen seemed to be sufficient given that similar projects more or less had similar number \cite{Alkadhi2017}, \cite{Nonnenmacher2017}. Additionally, a healthy proportion of sentences contained rationale in them thereby eliminating the need for deploying balancing techniques.  
\bigbreak
Manual labeling is a task that is prone to human errors. Given the nature of the project, some messages were abstract and difficult to comprehend. Keeping the nature of project aside, language skills may also vary from human to human as they could interpret and perceive a given statement in different ways with valid reasoning and arguments to justify their stand. However, in order to overcome this scenario, a labeling guide was created prior to beginning the labeling task. In addition, two annotators were involved in this process. Despite following the labeling guide, there were certain disagreements that were discussed and resolved in person constructively and amicably to come to a mutual conclusion on all the labels. 
\bigbreak
During the automatic classification phase, it was difficult to guess which preprocessing methods and classifiers would give the best results. Hence, more than 400 experiments were carried out using different combinations to arrive at the best results. Another problem faced during this task was that, scikit-learn and scikit-multilearn yielded poor results for fine grained classification compared to binary classification and therefore, MEKA was chosen to perform the experiments in the case of fine grained classification. This problem was encountered in the early stages of fine grained classification. Additionally, MEKA gave much better results compared to scikit-learn or scikit-multilearn. 
\bigbreak
MEKA also had its share of limitations. For example, MEKA lacked inbuilt preprocessing methods for POS tagging. Hence, the data was preprocessed with POS tagging initially before being fed into MEKA for classification. The data was preprocessed using a Python library named SpaCy which has been said to perform better than NLTK, another popular counterpart to perform POS tagging. 
\bigbreak
Besides binary and fine grained classification, carrying out LDA based experiments to unearth topics also threw certain challenges. Stopwords used from the Python libraries did not suffice as such and hence custom stopword lists had to be created to extract more meaningful topics. Single alphabets and numbers were added to stopword lists. In addition, commonly occurring terms in the domain of software engineering such as \textit{branch, merge, bugs, patches, and problems}, were also added to create custom stopword lists. 
\bigbreak
To compare similarity between keywords of comments from ITS and messages from IRC, a string matching approach had to be employed. Keywords were extracted using LDA and custom stopords lists mentioned earlier were used here as well. A Python library, fuzzywuzzy, based on Levenshtein distance function seemed to have been the most appropriate one to achieve this goal. The minimum threshold for similarity to match an issue to an IRC message is debatable. However, choosing a threshold of 50\% seemed ideal considering that two of the projects were able to attain highest similarity in the 70-80\% range. 

\section{Conclusion}

\textit{Note: Recap shortly which problem you solved in your thesis and discuss your \textbf{contributions} here.}

\section{Future Work}

\textit{Note: Tell us the next steps  (that you would do if you have more time. be creative, visionary and open-minded here.}



\appendix

\chapter{Annotation Guide}
This study aims at examining the type of rationale elements that are present in the messages of the issue tracking systems.
\bigbreak 
As part of the annotating task, you will read messages of developers extracted from issue tracking systems of three opern sourced projects: Apache Lucene, Mozilla Thunderbird and Ubuntu. Your task is to label and classify these messages as those that contain rationale and those that do not contain any rationale. In addition, those messages that contain any rationale need to be further labeled as the type of rationale element it contains. 
\bigbreak
This guide describes the instructions you need to follow to successfully conduct the task. To do so, you can use any spreadsheet application such as Microsoft Excel, Libre Office Excel or Google Sheets. It is strongly recommended to use this guide as a reference during the entire duration of annotating task. 
\bigbreak
Your task would be to read the messages from the issue tracking systems assigned to you. For each of these messages, you are required to identify rationale elements present in them and classify them accordingly. Each of these rationale elements are explained later in this guide. 
\bigbreak
Should you have any queries or doubts that arise during the labeling task, please contact the other project members. 
\subsubsection{Classify the Issue Tracker Messages}
A message may contain more than a sentence. You are required to annotate each of these sentences, which will hereby be referred to as a message itself. If the message contains any rationale element, highlight the part of the sentence containing the same and label them appropriately. A message may also be written in a way such that it may contain multiple rationale elements. In such a case, you are required to label all the possible rationale elements that are hidden in the message. The rationale elements are as follows:
\newline \newline
You can assign more than one rationale element for each message. The rationale elements are: 
\newline \newline
\textbf{Issue:} A problem to be solved. Issues are typically resolved through discussions and negotiation, and are usually phrased as questions. Examples are:
\newline \newline
\textit{"I think you had a good question about difficulty level - whether it's for all recipes or for particular ones."}
\newline \newline
\textit{"How soon should a dispatcher be notified of a train delay?"}
\newline \newline
\textit{"How should persistent data be stored?"}
\newline \newline
\textit{"Which technology presents the most risk?"}
\newline \newline
\textbf{Alternative:} A possible solution that could address the issue under consideration. Examples are:
\newline \newline
\textit{"Just my thoughts, but what do you think of making the "cost" be for the whole dish, instead of next to each individual ingredient?"}
\newline \newline
\textit{"The interface for the dispatcher could be realized with a point-and-click interface."}
\newline \newline
\textit{"The display used by the dispatcher can be a text-only display with graphic characters to represent track segments."}
\newline \newline
\textbf{Pro-argument:} A reason supporting an alternative. A pro-argument is usually phrased as a positive statement. In addition, when a developer responds to an alternative with a subjective opinion it should be marked as a pro-argument.  Examples are:
\newline \newline
\textit{"Text-based interfaces are easier to implement and test than Point-and-click interfaces."}
\newline \newline
\textit{"I like it."}
\newline \newline
\textit{"I totally agree with you!"}
\newline \newline
\textit{"I feel it is good"}
\newline \newline
\textit{"+1"}
\newline \newline
\textbf{Con-argument:} A reason against an alternative. A con-argument is usually phrased as a negative statement. Examples are:
\newline \newline
\textit{"This screen has no real useful functionality."}
\newline \newline
\textit{"Point-and-click interfaces are much more complex to implement than text-based interfaces."}
\newline \newline
\textit{"The point-and-click interface risks introducing fatal errors in the system that would offset any usability benefit the interface would provide."}
\newline \newline
\textbf{Decision:} A decision that were made to resolve the issue. Examples are:
\newline \newline
\textit{"We decided that we will rank our recipes based on frequency of use."}
\newline \newline 
\textit{"We select a text-based display and a keyboard input for the traffic control user interface."}

\subsubsection{What not to classify?}
Messages that must not be labeled as those containing rationale are listed below. 
\newline \newline
\textbf{Management issues:} Issues that are not discussing the software system being developed. Examples are:
\newline \newline 
\textit{"Should I put the user stories in Confluence and Jira?"}
\newline \newline 
\textbf{General queries and issues:} Issues that are not related to the software system being developed such as questions about the development environment, development processes, programming languages, APIs or software libraries. Examples are:
\newline \newline 
\textit{"How can I log in to confluence?"}
\newline \newline 
\textit{"How can I see the project events on the calendar?"}
\newline \newline 
\textit{"How do I create a new storyboard in Xcode?"}
\newline \newline 
\textit{"I get a crash when I try to open the project workspace."}
\newline \newline 
\textit{"How to sort any object array by dates on Swift?"}
\newline \newline 
\textbf{Social events:} Messages that discuss social aspects of the development teams. For example, arrangement of an icebreaker event or discussing the time and place for a gathering.
\newline \newline 
\textbf{Bugs:} When developers report on bugs/error in the code. Examples are: 
\newline \newline 
\textit{"I got merging conflicts when I commit my code."}
\newline \newline 
\textit{"I got an error when I call this function."}
\newline \newline 
\textbf{Workload:} Prioritization and distribution of workload. Examples are:
\newline \newline 
\textit{"I would do it myself but I’m too afraid to break something. I would be very happy if someone with more knowledge maybe can reset things and create the structure we need."}
\newline \newline 
\textit{"From my end, I would prioritize the work like this: We implement all the design changes listed in the acceptance. Then, when this is all done, we can come back to design again"}
\newline \newline 
\textbf{Non-English messages:} Messages that are in any language other than English. 

\clearpage

\listoffigures
\clearpage

\listoftables
\clearpage

\bibliography{thesis}
\bibliographystyle{alpha}

\end{document}
